{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "kCVUV6aPGRc1",
        "PiMeb-Uq1K5e"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43f8c7446df94572a3cf4551ff9e32cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3285835f321e442496370c269d5687de",
              "IPY_MODEL_c2526f7d6333416293178a4ebf3dd992",
              "IPY_MODEL_f0f9f695f5d143fa822a71149133d757"
            ],
            "layout": "IPY_MODEL_9ae5c5b54fb14903906e30300e7c6876"
          }
        },
        "3285835f321e442496370c269d5687de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abec86e75c6b481aac1fa9b5c8bd946f",
            "placeholder": "​",
            "style": "IPY_MODEL_d497ef6723154fc2afc7cd161cee6479",
            "value": "Loading weights: 100%"
          }
        },
        "c2526f7d6333416293178a4ebf3dd992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e084d9664d74707b80daa28de740ffb",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b3d1780a5c74e70bae4d3134ec9d87e",
            "value": 148
          }
        },
        "f0f9f695f5d143fa822a71149133d757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872b49237a7d49aea131716dad870a38",
            "placeholder": "​",
            "style": "IPY_MODEL_37befbee69764a48a10968e7430125f6",
            "value": " 148/148 [00:00&lt;00:00, 536.15it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "9ae5c5b54fb14903906e30300e7c6876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abec86e75c6b481aac1fa9b5c8bd946f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d497ef6723154fc2afc7cd161cee6479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e084d9664d74707b80daa28de740ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3d1780a5c74e70bae4d3134ec9d87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "872b49237a7d49aea131716dad870a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37befbee69764a48a10968e7430125f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a7de6c240f9457b9307e69393253f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e90524e89afe46b8a1fffb861dc593ca",
              "IPY_MODEL_d68aa47d674f47bca5eb2cf9099b4b9f",
              "IPY_MODEL_c6d02bd08c174f17815eca8f596ea471"
            ],
            "layout": "IPY_MODEL_c9abb736e33c4fa9b4a2668f6b0ed7bd"
          }
        },
        "e90524e89afe46b8a1fffb861dc593ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15303ea2ab454bf68c8aeaee873d3f44",
            "placeholder": "​",
            "style": "IPY_MODEL_c38cc852add34173946a4b0ae036371f",
            "value": "Loading weights: 100%"
          }
        },
        "d68aa47d674f47bca5eb2cf9099b4b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d39e5a0d5945adbe76b9802c154bab",
            "max": 202,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bd1b137443b49909014576d895edb6d",
            "value": 202
          }
        },
        "c6d02bd08c174f17815eca8f596ea471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91ba9f6401945eb875cc4840491360c",
            "placeholder": "​",
            "style": "IPY_MODEL_4607f1628c8a49e2920898a3ef031ee7",
            "value": " 202/202 [00:00&lt;00:00, 625.88it/s, Materializing param=cls.predictions.transform.dense.weight]"
          }
        },
        "c9abb736e33c4fa9b4a2668f6b0ed7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15303ea2ab454bf68c8aeaee873d3f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38cc852add34173946a4b0ae036371f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d39e5a0d5945adbe76b9802c154bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd1b137443b49909014576d895edb6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d91ba9f6401945eb875cc4840491360c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4607f1628c8a49e2920898a3ef031ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9d9b6ae5524e23a139ce7acc8d251a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da93e4a830e547a79fe675d78e32f66f",
              "IPY_MODEL_ebe936b6bb4d41dd90173b4c954036e1",
              "IPY_MODEL_bcd0abcc53cc40c6a4065542ffbb2350"
            ],
            "layout": "IPY_MODEL_4c570f1b9157421999fc8d48bde3e5cb"
          }
        },
        "da93e4a830e547a79fe675d78e32f66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0ebade71c0447ac81731a63551a6fa4",
            "placeholder": "​",
            "style": "IPY_MODEL_36e4a36621f54e69bda43ecc6fc1dce7",
            "value": "Loading weights: 100%"
          }
        },
        "ebe936b6bb4d41dd90173b4c954036e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e49b423dd74f74aea11ff59c9d36c9",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cde741ed6731487c83ad7158a8aecd6f",
            "value": 148
          }
        },
        "bcd0abcc53cc40c6a4065542ffbb2350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d810111d8d4df6b9999d3ad0d7873d",
            "placeholder": "​",
            "style": "IPY_MODEL_f0b851ad4141407089cbd6924d796425",
            "value": " 148/148 [00:00&lt;00:00, 518.65it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "4c570f1b9157421999fc8d48bde3e5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0ebade71c0447ac81731a63551a6fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e4a36621f54e69bda43ecc6fc1dce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9e49b423dd74f74aea11ff59c9d36c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde741ed6731487c83ad7158a8aecd6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75d810111d8d4df6b9999d3ad0d7873d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b851ad4141407089cbd6924d796425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "071e832c04934a5f877850ddeed4bdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b81bcaa076944b9886404ecbfb5e13ae",
              "IPY_MODEL_9d0bf78e375141818b15d9900365ab52",
              "IPY_MODEL_0aa0aa3d263c4be39255e5608061409f"
            ],
            "layout": "IPY_MODEL_89baaa17aaa44994983a3155a3df996a"
          }
        },
        "b81bcaa076944b9886404ecbfb5e13ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_076f3ae4a3a14944995192e783a55cb4",
            "placeholder": "​",
            "style": "IPY_MODEL_1ecf0ef57cf1427a81c7ab3e4ed989c7",
            "value": "Loading weights: 100%"
          }
        },
        "9d0bf78e375141818b15d9900365ab52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_489862a094a7417e8e63826075623cf2",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25eacdb1d9ee490987dd7738cefe08cf",
            "value": 148
          }
        },
        "0aa0aa3d263c4be39255e5608061409f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269e1a2920374787808c0ab297c0f922",
            "placeholder": "​",
            "style": "IPY_MODEL_6734a68e3f234bf184331eea83d04aab",
            "value": " 148/148 [00:00&lt;00:00, 631.07it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "89baaa17aaa44994983a3155a3df996a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076f3ae4a3a14944995192e783a55cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ecf0ef57cf1427a81c7ab3e4ed989c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "489862a094a7417e8e63826075623cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25eacdb1d9ee490987dd7738cefe08cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "269e1a2920374787808c0ab297c0f922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6734a68e3f234bf184331eea83d04aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d89381d4f0224de490be3d599d6b1e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f019b555ad7f4c36bd0323d59407498f",
              "IPY_MODEL_9cbcc73e47b3427e9e13f4067401dafc",
              "IPY_MODEL_343309a38f2047589c05c8b91ebd9b97"
            ],
            "layout": "IPY_MODEL_3ae98a2a6e954d7ba758e4449aa8ff60"
          }
        },
        "f019b555ad7f4c36bd0323d59407498f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df2878caa8e4d6587c5303c8e03bbeb",
            "placeholder": "​",
            "style": "IPY_MODEL_bfbaee2485c94579acc465c3e182a803",
            "value": "Loading weights: 100%"
          }
        },
        "9cbcc73e47b3427e9e13f4067401dafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2406b18e361544188d8a3845402a0294",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff3502418a714f29aa97e137f52912f8",
            "value": 148
          }
        },
        "343309a38f2047589c05c8b91ebd9b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_978c92fad21c47ebb481e216a6a738b3",
            "placeholder": "​",
            "style": "IPY_MODEL_54676a737cbf43acb9b09b218c9b7c21",
            "value": " 148/148 [00:00&lt;00:00, 573.23it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "3ae98a2a6e954d7ba758e4449aa8ff60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df2878caa8e4d6587c5303c8e03bbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbaee2485c94579acc465c3e182a803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2406b18e361544188d8a3845402a0294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3502418a714f29aa97e137f52912f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "978c92fad21c47ebb481e216a6a738b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54676a737cbf43acb9b09b218c9b7c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78c95740b3b4748af0d3222f0ae8426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a64fad1932449af8ac9f98f93c29f04",
              "IPY_MODEL_14151fc65dbe489e890209cfe436ce3e",
              "IPY_MODEL_3fd52fef23444611ad1af480b56f9122"
            ],
            "layout": "IPY_MODEL_0d905703730b49e0b60f42788d48cc73"
          }
        },
        "8a64fad1932449af8ac9f98f93c29f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6560e1ff0e24bc9b068a0518b335417",
            "placeholder": "​",
            "style": "IPY_MODEL_a1d50dbe755e42fcab2c78af99c122df",
            "value": "Loading weights: 100%"
          }
        },
        "14151fc65dbe489e890209cfe436ce3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e4d08e087d84eb99fd1d9f5d475fdb4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e66814d95aa45eba8a28584b0fc6f8d",
            "value": 190
          }
        },
        "3fd52fef23444611ad1af480b56f9122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2988cfeec56140f19f237d665ff38029",
            "placeholder": "​",
            "style": "IPY_MODEL_2997d8373bc74f1ead3ecedb3484eacc",
            "value": " 190/190 [00:00&lt;00:00, 570.29it/s, Materializing param=shared.weight]"
          }
        },
        "0d905703730b49e0b60f42788d48cc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6560e1ff0e24bc9b068a0518b335417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d50dbe755e42fcab2c78af99c122df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4d08e087d84eb99fd1d9f5d475fdb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e66814d95aa45eba8a28584b0fc6f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2988cfeec56140f19f237d665ff38029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2997d8373bc74f1ead3ecedb3484eacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f7d4f78c3d4455bb42efdc1c16620f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5e6b9a791f446e3a05eb028a9f68e96",
              "IPY_MODEL_687ec52e5bd448d48ccfe271a34216ae",
              "IPY_MODEL_fe101f24976249ceac7e8c7dcbf3aee5"
            ],
            "layout": "IPY_MODEL_a49fbd012e2a429d8f646a17d599c436"
          }
        },
        "d5e6b9a791f446e3a05eb028a9f68e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e57bda74d76a465a9fb9888db8001be3",
            "placeholder": "​",
            "style": "IPY_MODEL_00f7235e698644ccb8f5fd1f78697623",
            "value": "Loading weights: 100%"
          }
        },
        "687ec52e5bd448d48ccfe271a34216ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d83376359c45fd99ba6afa6c9cdfe4",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96e7709fd46747b0a128a79856050dda",
            "value": 148
          }
        },
        "fe101f24976249ceac7e8c7dcbf3aee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ded8848a08394484b585230baf8e5a93",
            "placeholder": "​",
            "style": "IPY_MODEL_7c1cc6061bb14bd5a481f2b202a297e6",
            "value": " 148/148 [00:00&lt;00:00, 552.11it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "a49fbd012e2a429d8f646a17d599c436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57bda74d76a465a9fb9888db8001be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00f7235e698644ccb8f5fd1f78697623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72d83376359c45fd99ba6afa6c9cdfe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e7709fd46747b0a128a79856050dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ded8848a08394484b585230baf8e5a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1cc6061bb14bd5a481f2b202a297e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95f4cacd5cc64930bf8c3fd67e2c7853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0434beee5c2542b8b5f6cc09b858e748",
              "IPY_MODEL_958e63014dee4ad49b2513769c1ab365",
              "IPY_MODEL_444bb958acf4485da6b935de6f990d75"
            ],
            "layout": "IPY_MODEL_f2b9bf9badc14c01a114cbcb3d43c1ae"
          }
        },
        "0434beee5c2542b8b5f6cc09b858e748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68cdd98db23443e2b9f99b77015d6262",
            "placeholder": "​",
            "style": "IPY_MODEL_f44745bde73b4c7b9537b919b79b41f9",
            "value": "Loading weights: 100%"
          }
        },
        "958e63014dee4ad49b2513769c1ab365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac10d17b0cc5468b8f18f3d3709a3696",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d25c6ffdda794f3ca422f608fe157c70",
            "value": 190
          }
        },
        "444bb958acf4485da6b935de6f990d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4de02e69746a49ba90a3feead1d38f96",
            "placeholder": "​",
            "style": "IPY_MODEL_e1187eb1ad30403aa06d98a1f234fdd0",
            "value": " 190/190 [00:00&lt;00:00, 661.92it/s, Materializing param=shared.weight]"
          }
        },
        "f2b9bf9badc14c01a114cbcb3d43c1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68cdd98db23443e2b9f99b77015d6262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44745bde73b4c7b9537b919b79b41f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac10d17b0cc5468b8f18f3d3709a3696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25c6ffdda794f3ca422f608fe157c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4de02e69746a49ba90a3feead1d38f96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1187eb1ad30403aa06d98a1f234fdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35407925d6df4c778da92874610fe44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc38c5757c194030b1f77c9999169a65",
              "IPY_MODEL_81e9270e6bbd41e4a5bb8cd9380ced16",
              "IPY_MODEL_a0bb6ba278d5467194321f48dc7ace5c"
            ],
            "layout": "IPY_MODEL_4555ea839db54287bfaf8a322b251682"
          }
        },
        "bc38c5757c194030b1f77c9999169a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd36e82bdcf405499e9b958304daebf",
            "placeholder": "​",
            "style": "IPY_MODEL_f889963622064f8f8ddfe949cf737c24",
            "value": "Loading weights: 100%"
          }
        },
        "81e9270e6bbd41e4a5bb8cd9380ced16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80918e4d60f34d96bbc24eb15fea312a",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cea73e78c9e64f40be404392ebebd07b",
            "value": 148
          }
        },
        "a0bb6ba278d5467194321f48dc7ace5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f5cda1908746c680fffcec04d15b8e",
            "placeholder": "​",
            "style": "IPY_MODEL_13c82f649e824367973912d796a23b69",
            "value": " 148/148 [00:00&lt;00:00, 507.14it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "4555ea839db54287bfaf8a322b251682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd36e82bdcf405499e9b958304daebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f889963622064f8f8ddfe949cf737c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80918e4d60f34d96bbc24eb15fea312a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea73e78c9e64f40be404392ebebd07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96f5cda1908746c680fffcec04d15b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c82f649e824367973912d796a23b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849d41e6e03148cfacc0ee81c1adc600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29937de6ac0f4e5c98c69792b9952103",
              "IPY_MODEL_afb80760cb784d4e9e52227a779861e2",
              "IPY_MODEL_44f1ac50d4b34927972a362d3a3ce021"
            ],
            "layout": "IPY_MODEL_151bcb9cf104472f88b550c22c67f343"
          }
        },
        "29937de6ac0f4e5c98c69792b9952103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e92be326d1945449a648e71504a0d11",
            "placeholder": "​",
            "style": "IPY_MODEL_7d8dd070ef9f41a9bf9369e8399e1cae",
            "value": "Loading weights: 100%"
          }
        },
        "afb80760cb784d4e9e52227a779861e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d77c38a4763406c81891a63b42e5cf8",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7652f0985a074944b9d3e03259969717",
            "value": 148
          }
        },
        "44f1ac50d4b34927972a362d3a3ce021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac8c89ff606429ba984e600dd581934",
            "placeholder": "​",
            "style": "IPY_MODEL_3af556c1996648e0a68940cd6944527a",
            "value": " 148/148 [00:00&lt;00:00, 438.37it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "151bcb9cf104472f88b550c22c67f343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e92be326d1945449a648e71504a0d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8dd070ef9f41a9bf9369e8399e1cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d77c38a4763406c81891a63b42e5cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7652f0985a074944b9d3e03259969717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ac8c89ff606429ba984e600dd581934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af556c1996648e0a68940cd6944527a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunoleomenezes/MC-CD05/blob/main/02_LNCC_bruno_MC_CD05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Large Language Models - MC-CD05**\n",
        "*Professor: Bruno Menezes e Daniel de Senna (LNCC)*"
      ],
      "metadata": {
        "id": "w3RCbAXJ0bji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Controle e inferência: parâmetros de geração (temperatura, top-p) e gerenciamento de contexto (KV cache, expected-attention, cache merging)."
      ],
      "metadata": {
        "id": "jSj58Zgr4Dl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DIAGRAMAS DIDÁTICOS (Graphviz)\n",
        "# Transformer \"base\"  →  BERT (Encoder)  →  GPT-2 (Decoder)\n",
        "#\n",
        "# Objetivo pedagógico:\n",
        "# - Mostrar que BERT e GPT compartilham o mesmo \"bloco Transformer\"\n",
        "# - O que muda é: máscara de atenção (bidirecional vs causal) e objetivo (entender vs gerar)\n",
        "# ============================================================\n",
        "\n",
        "# 1) Instalamos graphviz (biblioteca de diagramas) no Colab.\n",
        "#    Obs.: Em alguns ambientes pode demorar um pouco na primeira vez.\n",
        "!pip install -q graphviz\n",
        "\n",
        "# 2) Importamos:\n",
        "# - Digraph: cria grafos/diagramas\n",
        "# - display/Markdown: para exibir título e subtítulos no notebook de forma bonita\n",
        "from graphviz import Digraph\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(\"# Comparação Visual: Transformer vs BERT vs GPT-2\"))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Função utilitária: cria um \"canvas\" padrão para os diagramas\n",
        "# Assim os 3 diagramas ficam com estilo consistente\n",
        "# ------------------------------------------------------------\n",
        "def make_base_graph(name: str) -> Digraph:\n",
        "    g = Digraph(name, format=\"png\")\n",
        "    g.attr(rankdir=\"LR\", size=\"10,4\")  # LR = Left-to-Right (melhor para pipelines)\n",
        "    g.attr(\"node\", shape=\"rect\", style=\"rounded,filled\")  # caixas arredondadas e coloridas\n",
        "    return g\n",
        "\n",
        "# ============================================================\n",
        "# 1) TRANSFORMER GENÉRICO (bloco comum)\n",
        "# ============================================================\n",
        "t = make_base_graph(\"Transformer\")\n",
        "\n",
        "# Nós (caixas) do fluxo:\n",
        "# - Embeddings (azul): entrada em forma vetorial\n",
        "# - Atenção/MLP (verde): transformação principal por camadas\n",
        "# - Saída (amarelo): estados ocultos (representações internas)\n",
        "t.node(\"t_in\",  \"Input Tokens\")\n",
        "t.node(\"t_emb\", \"Token + Positional Embedding\", fillcolor=\"#BBDEFB\")\n",
        "t.node(\"t_attn\",\"Self-Attention\",              fillcolor=\"#C8E6C9\")\n",
        "t.node(\"t_ffn\", \"Feed Forward (MLP)\",          fillcolor=\"#C8E6C9\")\n",
        "t.node(\"t_out\", \"Hidden States\",               fillcolor=\"#FFF9C4\")\n",
        "\n",
        "# Conectamos as caixas na ordem do fluxo\n",
        "t.edges([\n",
        "    (\"t_in\", \"t_emb\"),\n",
        "    (\"t_emb\", \"t_attn\"),\n",
        "    (\"t_attn\", \"t_ffn\"),\n",
        "    (\"t_ffn\", \"t_out\"),\n",
        "])\n",
        "\n",
        "display(Markdown(\"## 1. Transformer (bloco base comum)\"))\n",
        "display(Markdown(\n",
        "    \"- **Mesmo bloco** aparece em BERT e GPT.\\n\"\n",
        "    \"- Aqui mostramos o **esqueleto**: entrada → embeddings → atenção → MLP → estados ocultos.\"\n",
        "))\n",
        "display(t)\n",
        "\n",
        "# ============================================================\n",
        "# 2) BERT (ENCODER com atenção bidirecional)\n",
        "# ============================================================\n",
        "b = make_base_graph(\"BERT\")\n",
        "\n",
        "b.node(\"b_in\",  \"Input Tokens\")\n",
        "b.node(\"b_emb\", \"Embedding\", fillcolor=\"#BBDEFB\")\n",
        "\n",
        "# Subgrafo (cluster) só para desenhar o \"miolo\" em uma caixa agrupada\n",
        "# A ideia é comunicar: \"Encoder repetido N vezes\"\n",
        "with b.subgraph(name=\"cluster_enc\") as c:\n",
        "    c.attr(label=\"Encoder x12\\nBidirectional Attention\", style=\"rounded\")\n",
        "    c.node(\"b_attn\", \"Self-Attention\\n(all tokens see all)\", fillcolor=\"#C8E6C9\")\n",
        "    c.node(\"b_ffn\",  \"Feed Forward\",                        fillcolor=\"#C8E6C9\")\n",
        "\n",
        "# Saída típica do BERT: representações contextuais\n",
        "# (ótimo para tarefas de compreensão/classificação/extração)\n",
        "b.node(\"b_out\", \"Contextual Representations\\n(understanding)\", fillcolor=\"#FFF9C4\")\n",
        "\n",
        "b.edges([\n",
        "    (\"b_in\",  \"b_emb\"),\n",
        "    (\"b_emb\", \"b_attn\"),\n",
        "    (\"b_attn\",\"b_ffn\"),\n",
        "    (\"b_ffn\", \"b_out\"),\n",
        "])\n",
        "\n",
        "display(Markdown(\"## 2. BERT (Encoder bidirecional)\"))\n",
        "display(Markdown(\n",
        "    \"- **Bidirecional**: cada token pode olhar para **todos** os outros.\\n\"\n",
        "    \"- Focado em **entender** o texto (representações contextuais), não em gerar.\"\n",
        "))\n",
        "display(b)\n",
        "\n",
        "# ============================================================\n",
        "# 3) GPT-2 (DECODER com atenção causal/mascarada)\n",
        "# ============================================================\n",
        "g = make_base_graph(\"GPT2\")\n",
        "\n",
        "g.node(\"g_in\",  \"Input Tokens\")\n",
        "g.node(\"g_emb\", \"Embedding\", fillcolor=\"#BBDEFB\")\n",
        "\n",
        "# No GPT (decoder causal), há uma máscara:\n",
        "# cada token só pode olhar para o passado (tokens anteriores).\n",
        "# Isso torna possível gerar token a token de forma autoregressiva.\n",
        "with g.subgraph(name=\"cluster_dec\") as c:\n",
        "    c.attr(label=\"Decoder x12\\nCausal Attention\", style=\"rounded\")\n",
        "    c.node(\"g_attn\", \"Masked Self-Attention\\n(past only)\", fillcolor=\"#C8E6C9\")\n",
        "    c.node(\"g_ffn\",  \"Feed Forward\",                     fillcolor=\"#C8E6C9\")\n",
        "\n",
        "# Saída típica do GPT: predição do próximo token (base da geração)\n",
        "g.node(\"g_out\", \"Next Token Prediction\\n(generation)\", fillcolor=\"#FFF9C4\")\n",
        "\n",
        "g.edges([\n",
        "    (\"g_in\",  \"g_emb\"),\n",
        "    (\"g_emb\", \"g_attn\"),\n",
        "    (\"g_attn\",\"g_ffn\"),\n",
        "    (\"g_ffn\", \"g_out\"),\n",
        "])\n",
        "\n",
        "display(Markdown(\"## 3. GPT-2 (Decoder causal)\"))\n",
        "display(Markdown(\n",
        "    \"- **Causal**: cada token olha só para o **passado**.\\n\"\n",
        "    \"- Isso permite **geração autoregressiva**: prever o próximo token e repetir.\"\n",
        "))\n",
        "display(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "K2Co4CpbURmS",
        "outputId": "54cde0b8-8643-4bb7-b2fa-9d4c22393311"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Comparação Visual: Transformer vs BERT vs GPT-2"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## 1. Transformer (bloco base comum)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Mesmo bloco** aparece em BERT e GPT.\n- Aqui mostramos o **esqueleto**: entrada → embeddings → atenção → MLP → estados ocultos."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Transformer Pages: 1 -->\n<svg width=\"720pt\" height=\"42pt\"\n viewBox=\"0.00 0.00 720.00 42.47\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.97 0.97) rotate(0) translate(4 40)\">\n<title>Transformer</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 742,-40 742,4 -4,4\"/>\n<!-- t_in -->\n<g id=\"node1\" class=\"node\">\n<title>t_in</title>\n<path fill=\"lightgrey\" stroke=\"black\" d=\"M75,-36C75,-36 12,-36 12,-36 6,-36 0,-30 0,-24 0,-24 0,-12 0,-12 0,-6 6,0 12,0 12,0 75,0 75,0 81,0 87,-6 87,-12 87,-12 87,-24 87,-24 87,-30 81,-36 75,-36\"/>\n<text text-anchor=\"middle\" x=\"43.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Input Tokens</text>\n</g>\n<!-- t_emb -->\n<g id=\"node2\" class=\"node\">\n<title>t_emb</title>\n<path fill=\"#bbdefb\" stroke=\"black\" d=\"M298,-36C298,-36 135,-36 135,-36 129,-36 123,-30 123,-24 123,-24 123,-12 123,-12 123,-6 129,0 135,0 135,0 298,0 298,0 304,0 310,-6 310,-12 310,-12 310,-24 310,-24 310,-30 304,-36 298,-36\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Token + Positional Embedding</text>\n</g>\n<!-- t_in&#45;&gt;t_emb -->\n<g id=\"edge1\" class=\"edge\">\n<title>t_in&#45;&gt;t_emb</title>\n<path fill=\"none\" stroke=\"black\" d=\"M87.21,-18C95.19,-18 103.84,-18 112.74,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.89,-21.5 122.89,-18 112.89,-14.5 112.89,-21.5\"/>\n</g>\n<!-- t_attn -->\n<g id=\"node3\" class=\"node\">\n<title>t_attn</title>\n<path fill=\"#c8e6c9\" stroke=\"black\" d=\"M428,-36C428,-36 358,-36 358,-36 352,-36 346,-30 346,-24 346,-24 346,-12 346,-12 346,-6 352,0 358,0 358,0 428,0 428,0 434,0 440,-6 440,-12 440,-12 440,-24 440,-24 440,-30 434,-36 428,-36\"/>\n<text text-anchor=\"middle\" x=\"393\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Self&#45;Attention</text>\n</g>\n<!-- t_emb&#45;&gt;t_attn -->\n<g id=\"edge2\" class=\"edge\">\n<title>t_emb&#45;&gt;t_attn</title>\n<path fill=\"none\" stroke=\"black\" d=\"M310.11,-18C318.83,-18 327.48,-18 335.7,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"335.87,-21.5 345.87,-18 335.87,-14.5 335.87,-21.5\"/>\n</g>\n<!-- t_ffn -->\n<g id=\"node4\" class=\"node\">\n<title>t_ffn</title>\n<path fill=\"#c8e6c9\" stroke=\"black\" d=\"M598,-36C598,-36 488,-36 488,-36 482,-36 476,-30 476,-24 476,-24 476,-12 476,-12 476,-6 482,0 488,0 488,0 598,0 598,0 604,0 610,-6 610,-12 610,-12 610,-24 610,-24 610,-30 604,-36 598,-36\"/>\n<text text-anchor=\"middle\" x=\"543\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Feed Forward (MLP)</text>\n</g>\n<!-- t_attn&#45;&gt;t_ffn -->\n<g id=\"edge3\" class=\"edge\">\n<title>t_attn&#45;&gt;t_ffn</title>\n<path fill=\"none\" stroke=\"black\" d=\"M440.02,-18C448.19,-18 456.9,-18 465.65,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"465.91,-21.5 475.91,-18 465.91,-14.5 465.91,-21.5\"/>\n</g>\n<!-- t_out -->\n<g id=\"node5\" class=\"node\">\n<title>t_out</title>\n<path fill=\"#fff9c4\" stroke=\"black\" d=\"M726,-36C726,-36 658,-36 658,-36 652,-36 646,-30 646,-24 646,-24 646,-12 646,-12 646,-6 652,0 658,0 658,0 726,0 726,0 732,0 738,-6 738,-12 738,-12 738,-24 738,-24 738,-30 732,-36 726,-36\"/>\n<text text-anchor=\"middle\" x=\"692\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Hidden States</text>\n</g>\n<!-- t_ffn&#45;&gt;t_out -->\n<g id=\"edge4\" class=\"edge\">\n<title>t_ffn&#45;&gt;t_out</title>\n<path fill=\"none\" stroke=\"black\" d=\"M610.19,-18C618.66,-18 627.25,-18 635.52,-18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"635.79,-21.5 645.79,-18 635.79,-14.5 635.79,-21.5\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x79617eb7e030>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## 2. BERT (Encoder bidirecional)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Bidirecional**: cada token pode olhar para **todos** os outros.\n- Focado em **entender** o texto (representações contextuais), não em gerar."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: BERT Pages: 1 -->\n<svg width=\"693pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 693.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n<title>BERT</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 689,-112 689,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_enc</title>\n<path fill=\"none\" stroke=\"black\" d=\"M243,-8C243,-8 479,-8 479,-8 485,-8 491,-14 491,-20 491,-20 491,-88 491,-88 491,-94 485,-100 479,-100 479,-100 243,-100 243,-100 237,-100 231,-94 231,-88 231,-88 231,-20 231,-20 231,-14 237,-8 243,-8\"/>\n<text text-anchor=\"middle\" x=\"361\" y=\"-84.8\" font-family=\"Times,serif\" font-size=\"14.00\">Encoder x12</text>\n<text text-anchor=\"middle\" x=\"361\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">Bidirectional Attention</text>\n</g>\n<!-- b_in -->\n<g id=\"node1\" class=\"node\">\n<title>b_in</title>\n<path fill=\"lightgrey\" stroke=\"black\" d=\"M75,-53C75,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-29 0,-29 0,-23 6,-17 12,-17 12,-17 75,-17 75,-17 81,-17 87,-23 87,-29 87,-29 87,-41 87,-41 87,-47 81,-53 75,-53\"/>\n<text text-anchor=\"middle\" x=\"43.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Input Tokens</text>\n</g>\n<!-- b_emb -->\n<g id=\"node2\" class=\"node\">\n<title>b_emb</title>\n<path fill=\"#bbdefb\" stroke=\"black\" d=\"M191,-53C191,-53 135,-53 135,-53 129,-53 123,-47 123,-41 123,-41 123,-29 123,-29 123,-23 129,-17 135,-17 135,-17 191,-17 191,-17 197,-17 203,-23 203,-29 203,-29 203,-41 203,-41 203,-47 197,-53 191,-53\"/>\n<text text-anchor=\"middle\" x=\"163\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n</g>\n<!-- b_in&#45;&gt;b_emb -->\n<g id=\"edge1\" class=\"edge\">\n<title>b_in&#45;&gt;b_emb</title>\n<path fill=\"none\" stroke=\"black\" d=\"M87.25,-35C95.56,-35 104.32,-35 112.81,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.99,-38.5 122.99,-35 112.99,-31.5 112.99,-38.5\"/>\n</g>\n<!-- b_attn -->\n<g id=\"node3\" class=\"node\">\n<title>b_attn</title>\n<path fill=\"#c8e6c9\" stroke=\"black\" d=\"M343,-54C343,-54 251,-54 251,-54 245,-54 239,-48 239,-42 239,-42 239,-28 239,-28 239,-22 245,-16 251,-16 251,-16 343,-16 343,-16 349,-16 355,-22 355,-28 355,-28 355,-42 355,-42 355,-48 349,-54 343,-54\"/>\n<text text-anchor=\"middle\" x=\"297\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\">Self&#45;Attention</text>\n<text text-anchor=\"middle\" x=\"297\" y=\"-23.8\" font-family=\"Times,serif\" font-size=\"14.00\">(all tokens see all)</text>\n</g>\n<!-- b_emb&#45;&gt;b_attn -->\n<g id=\"edge2\" class=\"edge\">\n<title>b_emb&#45;&gt;b_attn</title>\n<path fill=\"none\" stroke=\"black\" d=\"M203.25,-35C211.22,-35 219.82,-35 228.46,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"228.58,-38.5 238.58,-35 228.58,-31.5 228.58,-38.5\"/>\n</g>\n<!-- b_ffn -->\n<g id=\"node4\" class=\"node\">\n<title>b_ffn</title>\n<path fill=\"#c8e6c9\" stroke=\"black\" d=\"M471,-53C471,-53 403,-53 403,-53 397,-53 391,-47 391,-41 391,-41 391,-29 391,-29 391,-23 397,-17 403,-17 403,-17 471,-17 471,-17 477,-17 483,-23 483,-29 483,-29 483,-41 483,-41 483,-47 477,-53 471,-53\"/>\n<text text-anchor=\"middle\" x=\"437\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Feed Forward</text>\n</g>\n<!-- b_attn&#45;&gt;b_ffn -->\n<g id=\"edge3\" class=\"edge\">\n<title>b_attn&#45;&gt;b_ffn</title>\n<path fill=\"none\" stroke=\"black\" d=\"M355.33,-35C363.75,-35 372.41,-35 380.79,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"380.84,-38.5 390.84,-35 380.84,-31.5 380.84,-38.5\"/>\n</g>\n<!-- b_out -->\n<g id=\"node5\" class=\"node\">\n<title>b_out</title>\n<path fill=\"#fff9c4\" stroke=\"black\" d=\"M673,-54C673,-54 531,-54 531,-54 525,-54 519,-48 519,-42 519,-42 519,-28 519,-28 519,-22 525,-16 531,-16 531,-16 673,-16 673,-16 679,-16 685,-22 685,-28 685,-28 685,-42 685,-42 685,-48 679,-54 673,-54\"/>\n<text text-anchor=\"middle\" x=\"602\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\">Contextual Representations</text>\n<text text-anchor=\"middle\" x=\"602\" y=\"-23.8\" font-family=\"Times,serif\" font-size=\"14.00\">(understanding)</text>\n</g>\n<!-- b_ffn&#45;&gt;b_out -->\n<g id=\"edge4\" class=\"edge\">\n<title>b_ffn&#45;&gt;b_out</title>\n<path fill=\"none\" stroke=\"black\" d=\"M483.4,-35C491.33,-35 499.82,-35 508.48,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"508.7,-38.5 518.7,-35 508.7,-31.5 508.7,-38.5\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x79617eb452b0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## 3. GPT-2 (Decoder causal)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- **Causal**: cada token olha só para o **passado**.\n- Isso permite **geração autoregressiva**: prever o próximo token e repetir."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: GPT2 Pages: 1 -->\n<svg width=\"691pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 691.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n<title>GPT2</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 687,-112 687,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_dec</title>\n<path fill=\"none\" stroke=\"black\" d=\"M243,-8C243,-8 504,-8 504,-8 510,-8 516,-14 516,-20 516,-20 516,-88 516,-88 516,-94 510,-100 504,-100 504,-100 243,-100 243,-100 237,-100 231,-94 231,-88 231,-88 231,-20 231,-20 231,-14 237,-8 243,-8\"/>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-84.8\" font-family=\"Times,serif\" font-size=\"14.00\">Decoder x12</text>\n<text text-anchor=\"middle\" x=\"373.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">Causal Attention</text>\n</g>\n<!-- g_in -->\n<g id=\"node1\" class=\"node\">\n<title>g_in</title>\n<path fill=\"lightgrey\" stroke=\"black\" d=\"M75,-53C75,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-29 0,-29 0,-23 6,-17 12,-17 12,-17 75,-17 75,-17 81,-17 87,-23 87,-29 87,-29 87,-41 87,-41 87,-47 81,-53 75,-53\"/>\n<text text-anchor=\"middle\" x=\"43.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Input Tokens</text>\n</g>\n<!-- g_emb -->\n<g id=\"node2\" class=\"node\">\n<title>g_emb</title>\n<path fill=\"#bbdefb\" stroke=\"black\" d=\"M191,-53C191,-53 135,-53 135,-53 129,-53 123,-47 123,-41 123,-41 123,-29 123,-29 123,-23 129,-17 135,-17 135,-17 191,-17 191,-17 197,-17 203,-23 203,-29 203,-29 203,-41 203,-41 203,-47 197,-53 191,-53\"/>\n<text text-anchor=\"middle\" x=\"163\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n</g>\n<!-- g_in&#45;&gt;g_emb -->\n<g id=\"edge1\" class=\"edge\">\n<title>g_in&#45;&gt;g_emb</title>\n<path fill=\"none\" stroke=\"black\" d=\"M87.25,-35C95.56,-35 104.32,-35 112.81,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"112.99,-38.5 122.99,-35 112.99,-31.5 112.99,-38.5\"/>\n</g>\n<!-- g_attn -->\n<g id=\"node3\" class=\"node\">\n<title>g_attn</title>\n<path fill=\"#c8e6c9\" stroke=\"black\" d=\"M368,-54C368,-54 251,-54 251,-54 245,-54 239,-48 239,-42 239,-42 239,-28 239,-28 239,-22 245,-16 251,-16 251,-16 368,-16 368,-16 374,-16 380,-22 380,-28 380,-28 380,-42 380,-42 380,-48 374,-54 368,-54\"/>\n<text text-anchor=\"middle\" x=\"309.5\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\">Masked Self&#45;Attention</text>\n<text text-anchor=\"middle\" x=\"309.5\" y=\"-23.8\" font-family=\"Times,serif\" font-size=\"14.00\">(past only)</text>\n</g>\n<!-- g_emb&#45;&gt;g_attn -->\n<g id=\"edge2\" class=\"edge\">\n<title>g_emb&#45;&gt;g_attn</title>\n<path fill=\"none\" stroke=\"black\" d=\"M203.1,-35C211.12,-35 219.83,-35 228.7,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"228.74,-38.5 238.74,-35 228.74,-31.5 228.74,-38.5\"/>\n</g>\n<!-- g_ffn -->\n<g id=\"node4\" class=\"node\">\n<title>g_ffn</title>\n<path fill=\"#c8e6c9\" stroke=\"black\" d=\"M496,-53C496,-53 428,-53 428,-53 422,-53 416,-47 416,-41 416,-41 416,-29 416,-29 416,-23 422,-17 428,-17 428,-17 496,-17 496,-17 502,-17 508,-23 508,-29 508,-29 508,-41 508,-41 508,-47 502,-53 496,-53\"/>\n<text text-anchor=\"middle\" x=\"462\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Feed Forward</text>\n</g>\n<!-- g_attn&#45;&gt;g_ffn -->\n<g id=\"edge3\" class=\"edge\">\n<title>g_attn&#45;&gt;g_ffn</title>\n<path fill=\"none\" stroke=\"black\" d=\"M380.02,-35C388.67,-35 397.43,-35 405.82,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"405.85,-38.5 415.85,-35 405.85,-31.5 405.85,-38.5\"/>\n</g>\n<!-- g_out -->\n<g id=\"node5\" class=\"node\">\n<title>g_out</title>\n<path fill=\"#fff9c4\" stroke=\"black\" d=\"M671,-54C671,-54 556,-54 556,-54 550,-54 544,-48 544,-42 544,-42 544,-28 544,-28 544,-22 550,-16 556,-16 556,-16 671,-16 671,-16 677,-16 683,-22 683,-28 683,-28 683,-42 683,-42 683,-48 677,-54 671,-54\"/>\n<text text-anchor=\"middle\" x=\"613.5\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\">Next Token Prediction</text>\n<text text-anchor=\"middle\" x=\"613.5\" y=\"-23.8\" font-family=\"Times,serif\" font-size=\"14.00\">(generation)</text>\n</g>\n<!-- g_ffn&#45;&gt;g_out -->\n<g id=\"edge4\" class=\"edge\">\n<title>g_ffn&#45;&gt;g_out</title>\n<path fill=\"none\" stroke=\"black\" d=\"M508.26,-35C516.35,-35 524.99,-35 533.71,-35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"533.94,-38.5 543.94,-35 533.94,-31.5 533.94,-38.5\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x79617ecd5280>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SETUP DO AMBIENTE (Colab)\n",
        "# Instalação de dependências + imports\n",
        "#\n",
        "# Objetivo:\n",
        "# - Garantir que temos as bibliotecas necessárias para:\n",
        "#   (1) carregar modelos Hugging Face (transformers)\n",
        "#   (2) inspecionar arquitetura e nº de parâmetros (torchinfo)\n",
        "#   (3) imprimir output bonito no notebook (rich)\n",
        "# ============================================================\n",
        "\n",
        "# 1) Instala bibliotecas (normalmente basta rodar 1 vez por sessão Colab)\n",
        "# -q = \"quiet\": reduz o spam de logs\n",
        "!pip install -q rich torchinfo transformers\n",
        "\n",
        "# 2) Imports principais\n",
        "import torch\n",
        "\n",
        "# Rich: prints mais legíveis no notebook (cores, caixas, etc.)\n",
        "from rich import print\n",
        "from rich.panel import Panel\n",
        "from rich.syntax import Syntax\n",
        "\n",
        "# Torchinfo: resumo estruturado da arquitetura (camadas, shapes, params)\n",
        "from torchinfo import summary\n",
        "\n",
        "# Display/Markdown: títulos e texto formatado no notebook\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Transformers: carregamento de modelos/tokenizers via Hugging Face Hub\n",
        "# - AutoTokenizer: escolhe o tokenizador correto automaticamente\n",
        "# - AutoModelForCausalLM: modelos geradores (tipo GPT) → prevê próximo token\n",
        "# - AutoModelForMaskedLM: modelos de \"mask filling\" (tipo BERT) → prevê token mascarado\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForMaskedLM,\n",
        ")\n",
        "\n",
        "# 3) (Opcional, mas útil) Checagem rápida de hardware\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "display(Markdown(f\"**Device detectado:** `{device}`\"))\n",
        "if device == \"cuda\":\n",
        "    display(Markdown(f\"**GPU:** `{torch.cuda.get_device_name(0)}`\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "j9wiInIYUhsA",
        "outputId": "dc797636-7805-49a4-d54b-c4984525e79f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Device detectado:** `cuda`"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**GPU:** `Tesla T4`"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CARREGAMENTO DE MODELOS + DEVICE (GPT-2 e BERT)\n",
        "#\n",
        "# Objetivo pedagógico:\n",
        "# - Ter 2 modelos com \"papéis\" diferentes para comparar:\n",
        "#   (1) GPT-2  -> modelo CAUSAL (gera texto prevendo o próximo token)\n",
        "#   (2) BERT   -> modelo MASKED (preenche tokens mascarados; não é gerador autoregressivo)\n",
        "#\n",
        "# Por que isso existe no notebook?\n",
        "# - Para evitar NameError: precisamos criar gpt_model / bert_model antes de usar depois.\n",
        "# - Para garantir que tudo roda no mesmo device (CPU ou GPU).\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForMaskedLM\n",
        "\n",
        "# 1) Detecta o device disponível\n",
        "# - cuda = GPU NVIDIA (bem mais rápido)\n",
        "# - cpu  = fallback (mais lento, mas roda em qualquer lugar)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"[INFO] Device detectado: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) GPT-2 (modelo causal → geração de texto)\n",
        "# ------------------------------------------------------------\n",
        "gpt_name = \"gpt2\"\n",
        "\n",
        "# Tokenizer: texto <-> tokens\n",
        "gpt_tokenizer = AutoTokenizer.from_pretrained(gpt_name)\n",
        "\n",
        "# Modelo: CausalLM (prevê próximo token e suporta model.generate)\n",
        "gpt_model = AutoModelForCausalLM.from_pretrained(gpt_name).to(device)\n",
        "\n",
        "# Modo avaliação:\n",
        "# - desativa dropout e outras fontes de aleatoriedade do treino\n",
        "# - ideal para inferência (resultados mais estáveis)\n",
        "gpt_model.eval()\n",
        "\n",
        "print(f\"[OK] GPT-2 carregado: {gpt_name}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) BERT (modelo masked → \"fill-mask\", compreensão)\n",
        "# ------------------------------------------------------------\n",
        "bert_name = \"bert-base-uncased\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
        "\n",
        "# BERT não é CausalLM; o head correto para a tarefa clássica é MaskedLM\n",
        "# (prever tokens ocultos em posições [MASK])\n",
        "bert_model = AutoModelForMaskedLM.from_pretrained(bert_name).to(device)\n",
        "bert_model.eval()\n",
        "\n",
        "print(f\"[OK] BERT carregado: {bert_name}\")\n",
        "\n",
        "# (Opcional) Reforço didático curto:\n",
        "print(\"\\n[Resumo]\")\n",
        "print(\"- GPT-2: geração autoregressiva (próximo token) → bom para text generation\")\n",
        "print(\"- BERT : predição de token mascarado (fill-mask) → bom para compreensão/extração\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "43f8c7446df94572a3cf4551ff9e32cb",
            "3285835f321e442496370c269d5687de",
            "c2526f7d6333416293178a4ebf3dd992",
            "f0f9f695f5d143fa822a71149133d757",
            "9ae5c5b54fb14903906e30300e7c6876",
            "abec86e75c6b481aac1fa9b5c8bd946f",
            "d497ef6723154fc2afc7cd161cee6479",
            "4e084d9664d74707b80daa28de740ffb",
            "7b3d1780a5c74e70bae4d3134ec9d87e",
            "872b49237a7d49aea131716dad870a38",
            "37befbee69764a48a10968e7430125f6",
            "0a7de6c240f9457b9307e69393253f06",
            "e90524e89afe46b8a1fffb861dc593ca",
            "d68aa47d674f47bca5eb2cf9099b4b9f",
            "c6d02bd08c174f17815eca8f596ea471",
            "c9abb736e33c4fa9b4a2668f6b0ed7bd",
            "15303ea2ab454bf68c8aeaee873d3f44",
            "c38cc852add34173946a4b0ae036371f",
            "16d39e5a0d5945adbe76b9802c154bab",
            "6bd1b137443b49909014576d895edb6d",
            "d91ba9f6401945eb875cc4840491360c",
            "4607f1628c8a49e2920898a3ef031ee7"
          ]
        },
        "id": "cVKK3FNcUq9E",
        "outputId": "a93284f8-2ebe-40dc-9a89-da67d6b312b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Device detectado: cuda\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Device detectado: cuda\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m GPU: Tesla T4\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> GPU: Tesla T4\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43f8c7446df94572a3cf4551ff9e32cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m GPT-\u001b[1;36m2\u001b[0m carregado: gpt2\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> carregado: gpt2\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/202 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a7de6c240f9457b9307e69393253f06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForMaskedLM LOAD REPORT from: bert-base-uncased\n",
            "Key                         | Status     |  | \n",
            "----------------------------+------------+--+-\n",
            "cls.seq_relationship.bias   | UNEXPECTED |  | \n",
            "cls.seq_relationship.weight | UNEXPECTED |  | \n",
            "bert.pooler.dense.weight    | UNEXPECTED |  | \n",
            "bert.pooler.dense.bias      | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m BERT carregado: bert-base-uncased\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> BERT carregado: bert-base-uncased\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mResumo\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Resumo<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- GPT-\u001b[1;36m2\u001b[0m: geração autoregressiva \u001b[1m(\u001b[0mpróximo token\u001b[1m)\u001b[0m → bom para text generation\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: geração autoregressiva <span style=\"font-weight: bold\">(</span>próximo token<span style=\"font-weight: bold\">)</span> → bom para text generation\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- BERT : predição de token mascarado \u001b[1m(\u001b[0mfill-mask\u001b[1m)\u001b[0m → bom para compreensão/extração\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- BERT : predição de token mascarado <span style=\"font-weight: bold\">(</span>fill-mask<span style=\"font-weight: bold\">)</span> → bom para compreensão/extração\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# INSPEÇÃO DE ARQUITETURA: GPT-2 vs BERT\n",
        "#\n",
        "# Objetivo pedagógico:\n",
        "# - \"Abrir a caixa-preta\" e ver como o modelo é organizado em módulos\n",
        "# - Conectar os nomes vistos no diagrama (embeddings, atenção, MLP) com PyTorch\n",
        "# - Usar torchinfo.summary para ter:\n",
        "#   * shapes das tensões\n",
        "#   * nº de parâmetros\n",
        "#   * profundidade (quantas camadas)\n",
        "# ============================================================\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "from rich.panel import Panel\n",
        "from rich.syntax import Syntax\n",
        "from torchinfo import summary\n",
        "import torch\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Título no notebook\n",
        "# ------------------------------------------------------------\n",
        "display(Markdown(\"# Arquitetura GPT-2 e BERT — Visão Geral\"))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Visualização textual do GPT-2 (print do módulo PyTorch)\n",
        "# ------------------------------------------------------------\n",
        "print(Panel.fit(\"ARQUITETURA GPT-2 — VISÃO GERAL\", border_style=\"cyan\"))\n",
        "\n",
        "# `str(gpt_model)` imprime a árvore de módulos: embeddings, blocos, atenção, MLP, etc.\n",
        "# Isso ajuda a ver \"o que existe\" dentro do modelo.\n",
        "syntax = Syntax(str(gpt_model), \"python\", theme=\"monokai\", line_numbers=False)\n",
        "print(syntax)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Config do BERT (hiperparâmetros do modelo)\n",
        "# ------------------------------------------------------------\n",
        "print(Panel.fit(\"BERT — ENCODER BIDIRECIONAL (CONFIG)\", border_style=\"green\"))\n",
        "\n",
        "# `bert_model.config` é um objeto com informações como:\n",
        "# - número de camadas, heads, dimensão hidden, vocab size, etc.\n",
        "print(bert_model.config)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Torchinfo: resumo estruturado (shapes + params)\n",
        "#\n",
        "# Vamos criar uma entrada \"dummy\" (falsa) apenas para o summary\n",
        "# (não é para \"fazer a tarefa\"; é só para o modelo rodar um forward)\n",
        "# ------------------------------------------------------------\n",
        "seq_len = 128\n",
        "batch_size = 1\n",
        "\n",
        "# input_ids: ids de tokens (inteiros) no intervalo [0, vocab_size)\n",
        "dummy_input_ids = torch.zeros((batch_size, seq_len), dtype=torch.long, device=device)\n",
        "\n",
        "# attention_mask: 1 para tokens válidos, 0 para padding\n",
        "# Aqui colocamos tudo 1 (sem padding), que é o caso mais simples.\n",
        "dummy_attention_mask = torch.ones((batch_size, seq_len), dtype=torch.long, device=device)\n",
        "\n",
        "# token_type_ids: usado em BERT para \"segmento A/B\" (ex.: pergunta/resposta).\n",
        "# Muitos casos usam tudo zero.\n",
        "dummy_token_type_ids = torch.zeros((batch_size, seq_len), dtype=torch.long, device=device)\n",
        "\n",
        "print(Panel.fit(\"TORCHINFO — BERT (MaskedLM head)\", border_style=\"green\"))\n",
        "summary(\n",
        "    bert_model,\n",
        "    input_data={\n",
        "        \"input_ids\": dummy_input_ids,\n",
        "        \"attention_mask\": dummy_attention_mask,\n",
        "        \"token_type_ids\": dummy_token_type_ids,\n",
        "    },\n",
        "    device=str(device),\n",
        ")\n",
        "\n",
        "print(Panel.fit(\"TORCHINFO — GPT-2 (CausalLM)\", border_style=\"cyan\"))\n",
        "summary(\n",
        "    gpt_model,\n",
        "    input_data={\"input_ids\": dummy_input_ids},\n",
        "    device=str(device),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jVTvieiB_DnR",
        "outputId": "d5ee084b-87c2-4a90-dba6-59bcb4c8e02e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Arquitetura GPT-2 e BERT — Visão Geral"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m╭─────────────────────────────────╮\u001b[0m\n",
              "\u001b[36m│\u001b[0m ARQUITETURA GPT-2 — VISÃO GERAL \u001b[36m│\u001b[0m\n",
              "\u001b[36m╰─────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭─────────────────────────────────╮</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> ARQUITETURA GPT-2 — VISÃO GERAL <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;248;248;242;48;2;39;40;34mGPT2LMHeadModel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtransformer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mGPT2Model\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwte\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mEmbedding\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m50257\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwpe\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mEmbedding\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1024\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                    \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdrop\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDropout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0.1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minplace\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mFalse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mh\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mModuleList\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m11\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m12\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mx\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mGPT2Block\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mln_1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLayerNorm\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34meps\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1e-05\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34melementwise_affine\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mTrue\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mGPT2Attention\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                     \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mc_attn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mConv1D\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnf\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2304\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnx\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mc_proj\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mConv1D\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnf\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnx\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                         \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattn_dropout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDropout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0.1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minplace\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mFalse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                            \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresid_dropout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDropout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0.1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minplace\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mFalse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mln_2\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLayerNorm\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34meps\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1e-05\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34melementwise_affine\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mTrue\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmlp\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mGPT2MLP\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mc_fc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mConv1D\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnf\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m3072\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnx\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mc_proj\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mConv1D\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnf\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnx\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m3072\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mact\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mNewGELUActivation\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                               \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m          \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdropout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDropout\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0.1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minplace\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mFalse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m      \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mln_f\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLayerNorm\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34meps\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1e-05\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34melementwise_affine\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mTrue\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlm_head\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLinear\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34min_features\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m768\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mout_features\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m50257\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbias\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mFalse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m\n",
              "\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                  \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">GPT2LMHeadModel(</span><span style=\"background-color: #272822\">                                                                                                   </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  (transformer): GPT2Model(</span><span style=\"background-color: #272822\">                                                                                        </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    (wte): Embedding(</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">50257</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                   </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    (wpe): Embedding(</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1024</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                    </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    (drop): Dropout(p</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0.1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, inplace</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">False</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                          </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    (h): ModuleList(</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      (</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">11</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">): </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">12</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> x GPT2Block(</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        (ln_1): LayerNorm((</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,), eps</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1e-05</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, elementwise_affine</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">True</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                              </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        (attn): GPT2Attention(</span><span style=\"background-color: #272822\">                                                                                     </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (c_attn): Conv1D(nf</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2304</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, nx</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                        </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (c_proj): Conv1D(nf</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, nx</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                         </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (attn_dropout): Dropout(p</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0.1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, inplace</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">False</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                            </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (resid_dropout): Dropout(p</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0.1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, inplace</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">False</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                           </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        )</span><span style=\"background-color: #272822\">                                                                                                          </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        (ln_2): LayerNorm((</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,), eps</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1e-05</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, elementwise_affine</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">True</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                              </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        (mlp): GPT2MLP(</span><span style=\"background-color: #272822\">                                                                                            </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (c_fc): Conv1D(nf</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">3072</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, nx</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                          </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (c_proj): Conv1D(nf</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, nx</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">3072</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                        </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (act): NewGELUActivation()</span><span style=\"background-color: #272822\">                                                                               </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">          (dropout): Dropout(p</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0.1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, inplace</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">False</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                 </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        )</span><span style=\"background-color: #272822\">                                                                                                          </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">      )</span><span style=\"background-color: #272822\">                                                                                                            </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    )</span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    (ln_f): LayerNorm((</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,), eps</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1e-05</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, elementwise_affine</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">True</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                  </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  )</span><span style=\"background-color: #272822\">                                                                                                                </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  (lm_head): Linear(in_features</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">768</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, out_features</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">50257</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, bias</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">False</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                               </span>\n",
              "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                                                  </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭──────────────────────────────────────╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m BERT — ENCODER BIDIRECIONAL (CONFIG) \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰──────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> BERT — ENCODER BIDIRECIONAL (CONFIG) <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "BertConfig \u001b[1m{\u001b[0m\n",
              "  \u001b[32m\"add_cross_attention\"\u001b[0m: false,\n",
              "  \u001b[32m\"architectures\"\u001b[0m: \u001b[1m[\u001b[0m\n",
              "    \u001b[32m\"BertForMaskedLM\"\u001b[0m\n",
              "  \u001b[1m]\u001b[0m,\n",
              "  \u001b[32m\"attention_probs_dropout_prob\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
              "  \u001b[32m\"bos_token_id\"\u001b[0m: null,\n",
              "  \u001b[32m\"classifier_dropout\"\u001b[0m: null,\n",
              "  \u001b[32m\"dtype\"\u001b[0m: \u001b[32m\"float32\"\u001b[0m,\n",
              "  \u001b[32m\"eos_token_id\"\u001b[0m: null,\n",
              "  \u001b[32m\"gradient_checkpointing\"\u001b[0m: false,\n",
              "  \u001b[32m\"hidden_act\"\u001b[0m: \u001b[32m\"gelu\"\u001b[0m,\n",
              "  \u001b[32m\"hidden_dropout_prob\"\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
              "  \u001b[32m\"hidden_size\"\u001b[0m: \u001b[1;36m768\u001b[0m,\n",
              "  \u001b[32m\"initializer_range\"\u001b[0m: \u001b[1;36m0.02\u001b[0m,\n",
              "  \u001b[32m\"intermediate_size\"\u001b[0m: \u001b[1;36m3072\u001b[0m,\n",
              "  \u001b[32m\"is_decoder\"\u001b[0m: false,\n",
              "  \u001b[32m\"layer_norm_eps\"\u001b[0m: \u001b[1;36m1e-12\u001b[0m,\n",
              "  \u001b[32m\"max_position_embeddings\"\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
              "  \u001b[32m\"model_type\"\u001b[0m: \u001b[32m\"bert\"\u001b[0m,\n",
              "  \u001b[32m\"num_attention_heads\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
              "  \u001b[32m\"num_hidden_layers\"\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
              "  \u001b[32m\"pad_token_id\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "  \u001b[32m\"position_embedding_type\"\u001b[0m: \u001b[32m\"absolute\"\u001b[0m,\n",
              "  \u001b[32m\"tie_word_embeddings\"\u001b[0m: true,\n",
              "  \u001b[32m\"transformers_version\"\u001b[0m: \u001b[32m\"5.0.0\"\u001b[0m,\n",
              "  \u001b[32m\"type_vocab_size\"\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
              "  \u001b[32m\"use_cache\"\u001b[0m: true,\n",
              "  \u001b[32m\"vocab_size\"\u001b[0m: \u001b[1;36m30522\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">BertConfig <span style=\"font-weight: bold\">{</span>\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"add_cross_attention\"</span>: false,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"architectures\"</span>: <span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"BertForMaskedLM\"</span>\n",
              "  <span style=\"font-weight: bold\">]</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"attention_probs_dropout_prob\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"bos_token_id\"</span>: null,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"classifier_dropout\"</span>: null,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"dtype\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"float32\"</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"eos_token_id\"</span>: null,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"gradient_checkpointing\"</span>: false,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_act\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"gelu\"</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_dropout_prob\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"hidden_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"initializer_range\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"intermediate_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"is_decoder\"</span>: false,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"layer_norm_eps\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-12</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"max_position_embeddings\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"model_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"bert\"</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"num_attention_heads\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"num_hidden_layers\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"pad_token_id\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"position_embedding_type\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"absolute\"</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"tie_word_embeddings\"</span>: true,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"transformers_version\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"5.0.0\"</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"type_vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"use_cache\"</span>: true,\n",
              "  <span style=\"color: #008000; text-decoration-color: #008000\">\"vocab_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30522</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m╭──────────────────────────────────╮\u001b[0m\n",
              "\u001b[32m│\u001b[0m TORCHINFO — BERT (MaskedLM head) \u001b[32m│\u001b[0m\n",
              "\u001b[32m╰──────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────╮</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">│</span> TORCHINFO — BERT (MaskedLM head) <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">╰──────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m╭──────────────────────────────╮\u001b[0m\n",
              "\u001b[36m│\u001b[0m TORCHINFO — GPT-2 (CausalLM) \u001b[36m│\u001b[0m\n",
              "\u001b[36m╰──────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────╮</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> TORCHINFO — GPT-2 (CausalLM) <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">╰──────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "GPT2LMHeadModel                                    --                        --\n",
              "├─GPT2Model: 1-1                                   --                        --\n",
              "│    └─Embedding: 2-1                              [1, 128, 768]             38,597,376\n",
              "│    └─Embedding: 2-2                              [1, 128, 768]             786,432\n",
              "│    └─Dropout: 2-3                                [1, 128, 768]             --\n",
              "│    └─ModuleList: 2-4                             --                        --\n",
              "│    │    └─GPT2Block: 3-1                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-2                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-3                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-4                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-5                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-6                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-7                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-8                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-9                         [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-10                        [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-11                        [1, 128, 768]             7,087,872\n",
              "│    │    └─GPT2Block: 3-12                        [1, 128, 768]             7,087,872\n",
              "│    └─LayerNorm: 2-5                              [1, 128, 768]             1,536\n",
              "├─Linear: 1-2                                      [1, 128, 50257]           38,597,376\n",
              "====================================================================================================\n",
              "Total params: 163,037,184\n",
              "Trainable params: 163,037,184\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 163.34\n",
              "====================================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 157.63\n",
              "Params size (MB): 652.15\n",
              "Estimated Total Size (MB): 809.78\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "# INFERÊNCIA (GERAÇÃO) COM MODELO CAUSAL (GPT-2)\n",
        "#"
      ],
      "metadata": {
        "id": "mkxRXdNXWezv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Controle: temperatura, top-p e KV cache\n",
        "# ============================================================\n",
        "\n",
        "import time # Import the time module"
      ],
      "metadata": {
        "id": "bJvKdNhBVF-I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# CÉLULA 25 — Carregar modelo causal (GPT-2)\n",
        "# -----------------------------\n",
        "gpt_name = \"gpt2\"                                              # Modelo causal leve e didático\n",
        "gpt_tokenizer = AutoTokenizer.from_pretrained(gpt_name)        # Tokenizer BPE do GPT-2\n",
        "gpt_model = AutoModelForCausalLM.from_pretrained(gpt_name)     # Modelo causal para geração\n",
        "gpt_model.to(device)                                           # Move para GPU/CPU\n",
        "gpt_model.eval()                                               # Modo avaliação\n",
        "\n",
        "print(\"\\n[GPT] Modelo carregado:\", gpt_name)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"[ARQUITETURA GPT-2 — VISÃO GERAL]\")\n",
        "print(\"==============================\")\n",
        "print(gpt_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667,
          "referenced_widgets": [
            "1b9d9b6ae5524e23a139ce7acc8d251a",
            "da93e4a830e547a79fe675d78e32f66f",
            "ebe936b6bb4d41dd90173b4c954036e1",
            "bcd0abcc53cc40c6a4065542ffbb2350",
            "4c570f1b9157421999fc8d48bde3e5cb",
            "e0ebade71c0447ac81731a63551a6fa4",
            "36e4a36621f54e69bda43ecc6fc1dce7",
            "f9e49b423dd74f74aea11ff59c9d36c9",
            "cde741ed6731487c83ad7158a8aecd6f",
            "75d810111d8d4df6b9999d3ad0d7873d",
            "f0b851ad4141407089cbd6924d796425"
          ]
        },
        "id": "rEVrlfZ7VKGt",
        "outputId": "77409e28-863c-4b07-9ade-e8a00d22b7ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b9d9b6ae5524e23a139ce7acc8d251a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mGPT\u001b[1m]\u001b[0m Modelo carregado: gpt2\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>GPT<span style=\"font-weight: bold\">]</span> Modelo carregado: gpt2\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "==============================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "==============================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mARQUITETURA GPT-\u001b[1;36m2\u001b[0m — VISÃO GERAL\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>ARQUITETURA GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> — VISÃO GERAL<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "==============================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==============================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mGPT2LMHeadModel\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mtransformer\u001b[1m)\u001b[0m: \u001b[1;35mGPT2Model\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mwte\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m50257\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mwpe\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1024\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mh\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m12\u001b[0m x \u001b[1;35mGPT2Block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mln_1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mGPT2Attention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_attn\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m2304\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mattn_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mln_2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mGPT2MLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_fc\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m3072\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mln_f\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mlm_head\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m50257\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2LMHeadModel</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>transformer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Model</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>wte<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>wpe<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>h<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>ln_1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Attention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2304</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>attn_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>ln_2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_fc<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "          <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>ln_f<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>lm_head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Carregar modelo causal (GPT-2)\n",
        "# -----------------------------\n",
        "# Objetivo: carregar um modelo \"decoder-only\" simples (GPT-2) para demonstrar geração.\n",
        "# GPT-2 é um modelo CAUSAL: ele prevê o próximo token dado um prefixo.\n",
        "# Isso é a base do mecanismo autoregressivo: gerar token a token.\n",
        "\n",
        "gpt_name = \"gpt2\"  # checkpoint no Hugging Face Hub (leve e didático)\n",
        "\n",
        "# 1) Tokenizer: converte texto <-> tokens (ids)\n",
        "#    GPT-2 usa BPE, então ele quebra texto em subpalavras.\n",
        "gpt_tokenizer = AutoTokenizer.from_pretrained(gpt_name)\n",
        "\n",
        "# (Opcional) GPT-2 não define pad_token por padrão.\n",
        "# Isso pode causar warnings em algumas chamadas de generate com padding.\n",
        "# Aqui setamos pad_token como eos_token, que é uma prática comum para GPT-2.\n",
        "if gpt_tokenizer.pad_token is None:\n",
        "    gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
        "\n",
        "# 2) Modelo: AutoModelForCausalLM = modelo com \"head\" de linguagem causal,\n",
        "#    ou seja, pronto para model.generate() e predição do próximo token.\n",
        "gpt_model = AutoModelForCausalLM.from_pretrained(gpt_name).to(device)\n",
        "\n",
        "# 3) Modo avaliação:\n",
        "#    - desativa dropout\n",
        "#    - deixa a inferência mais estável/reprodutível\n",
        "gpt_model.eval()\n",
        "\n",
        "print(f\"\\n[GPT] Modelo carregado: {gpt_name}\")\n",
        "print(f\"[GPT] Device: {next(gpt_model.parameters()).device}\")\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"[ARQUITETURA GPT-2 — VISÃO GERAL]\")\n",
        "print(\"==============================\")\n",
        "\n",
        "# 4) Imprime a \"árvore\" de módulos do PyTorch (embeddings, blocos, atenção, MLP etc.)\n",
        "print(gpt_model)\n",
        "\n",
        "# (Dica opcional para a aula)\n",
        "# Para inferência, você pode usar:\n",
        "# with torch.inference_mode():\n",
        "#     ... model.generate(...)\n",
        "# Isso reduz overhead e pode ser um pouco mais rápido."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683,
          "referenced_widgets": [
            "071e832c04934a5f877850ddeed4bdac",
            "b81bcaa076944b9886404ecbfb5e13ae",
            "9d0bf78e375141818b15d9900365ab52",
            "0aa0aa3d263c4be39255e5608061409f",
            "89baaa17aaa44994983a3155a3df996a",
            "076f3ae4a3a14944995192e783a55cb4",
            "1ecf0ef57cf1427a81c7ab3e4ed989c7",
            "489862a094a7417e8e63826075623cf2",
            "25eacdb1d9ee490987dd7738cefe08cf",
            "269e1a2920374787808c0ab297c0f922",
            "6734a68e3f234bf184331eea83d04aab"
          ]
        },
        "id": "vEmd2dpjVWaU",
        "outputId": "4513da7a-5096-4813-fe67-6b0e50e744e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "071e832c04934a5f877850ddeed4bdac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mGPT\u001b[1m]\u001b[0m Modelo carregado: gpt2\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>GPT<span style=\"font-weight: bold\">]</span> Modelo carregado: gpt2\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mGPT\u001b[1m]\u001b[0m Device: cu\u001b[1;92mda:0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>GPT<span style=\"font-weight: bold\">]</span> Device: cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "==============================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "==============================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mARQUITETURA GPT-\u001b[1;36m2\u001b[0m — VISÃO GERAL\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>ARQUITETURA GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> — VISÃO GERAL<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "==============================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==============================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mGPT2LMHeadModel\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mtransformer\u001b[1m)\u001b[0m: \u001b[1;35mGPT2Model\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mwte\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m50257\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mwpe\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1024\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mh\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m12\u001b[0m x \u001b[1;35mGPT2Block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mln_1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mGPT2Attention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_attn\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m2304\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mattn_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mln_2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mGPT2MLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_fc\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m3072\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mln_f\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mlm_head\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m50257\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2LMHeadModel</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>transformer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Model</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>wte<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>wpe<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>h<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>ln_1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Attention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2304</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>attn_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>ln_2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_fc<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "          <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>ln_f<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>lm_head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Função de geração controlada (temperatura, top-p, KV cache)\n",
        "# -----------------------------\n",
        "# Objetivo pedagógico:\n",
        "# - Encapsular uma chamada de geração (model.generate)\n",
        "# - Permitir comparar rapidamente diferentes estratégias de decoding:\n",
        "#   * temperature (aleatoriedade)\n",
        "#   * top-p (nucleus sampling)\n",
        "#   * use_cache (KV cache: acelera geração em prompts longos)\n",
        "def generate_text(\n",
        "    prompt: str,\n",
        "    max_new_tokens: int = 80,\n",
        "    temperature: float = 1.0,\n",
        "    top_p: float = 1.0,\n",
        "    use_cache: bool = True,\n",
        "    do_sample: bool = True,\n",
        "):\n",
        "    # 1) Tokenização: transforma texto em tensores (input_ids, attention_mask)\n",
        "    #    e envia os tensores para o mesmo device do modelo (CPU/GPU).\n",
        "    inputs = gpt_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # 2) Inferência: não precisamos de gradientes (não estamos treinando).\n",
        "    #    inference_mode é uma opção eficiente para esse caso.\n",
        "    with torch.inference_mode():\n",
        "        output_ids = gpt_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,   # número de tokens *novos* além do prompt\n",
        "            do_sample=do_sample,             # True = sampling; False = greedy/beam (mais determinístico)\n",
        "            temperature=temperature,         # >1.0 mais diverso; <1.0 mais conservador\n",
        "            top_p=top_p,                     # nucleus sampling (massa de probabilidade)\n",
        "            use_cache=use_cache,             # KV cache: acelera geração passo-a-passo\n",
        "            pad_token_id=gpt_tokenizer.eos_token_id,  # evita warnings em modelos sem pad_token\n",
        "        )\n",
        "\n",
        "    # 3) Decodificação: transforma ids de tokens de volta em texto.\n",
        "    #    output_ids[0] porque o batch aqui tem tamanho 1.\n",
        "    text = gpt_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return text"
      ],
      "metadata": {
        "id": "F-N5MR6wVcLA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Teste base de geração (sanity check)\n",
        "# -----------------------------\n",
        "# Objetivo pedagógico:\n",
        "# - Confirmar que o modelo está carregado e conseguindo gerar texto\n",
        "# - Estabelecer uma \"linha de base\" antes de comparar temperatura/top-p/caching\n",
        "\n",
        "prompt = \"Transformers are models that\"\n",
        "\n",
        "print(\"\\n[PROMPT]\")\n",
        "print(prompt)\n",
        "\n",
        "print(\"\\n[GERAÇÃO BASE] (temperature=0.7, top_p=0.9)\")\n",
        "print(generate_text(prompt, temperature=0.7, top_p=0.9))\n",
        "\n",
        "# (Opcional) Se quiser mostrar variabilidade do sampling:\n",
        "print(\"\\n[GERAÇÃO BASE — segunda execução] (pode mudar por causa do sampling)\")\n",
        "print(generate_text(prompt, temperature=0.7, top_p=0.9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "YOZSXC44VqQB",
        "outputId": "2a723752-0d52-40bb-adf6-f42bd155fecc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mPROMPT\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>PROMPT<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mGERAÇÃO BASE\u001b[1m]\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7\u001b[0m, \u001b[33mtop_p\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>GERAÇÃO BASE<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>, <span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that can be used to modify the appearance of objects.\n",
              "\n",
              "To create a new model, you must use the following syntax:\n",
              "\n",
              "import \u001b[1m{\u001b[0m model \u001b[1m}\u001b[0m from \u001b[32m'../models/model'\u001b[0m;\n",
              "\n",
              "Note that you must use the model class in the constructor to add it to your model. You can also use the model class\n",
              "in the constructor to create a new object that is used to modify the appearance\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that can be used to modify the appearance of objects.\n",
              "\n",
              "To create a new model, you must use the following syntax:\n",
              "\n",
              "import <span style=\"font-weight: bold\">{</span> model <span style=\"font-weight: bold\">}</span> from <span style=\"color: #008000; text-decoration-color: #008000\">'../models/model'</span>;\n",
              "\n",
              "Note that you must use the model class in the constructor to add it to your model. You can also use the model class\n",
              "in the constructor to create a new object that is used to modify the appearance\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mGERAÇÃO BASE — segunda execução\u001b[1m]\u001b[0m \u001b[1m(\u001b[0mpode mudar por causa do sampling\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>GERAÇÃO BASE — segunda execução<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">(</span>pode mudar por causa do sampling<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used to create and manipulate objects. These models are often referred to as \n",
              "\u001b[32m\"models\"\u001b[0m by the user. They are often used to create a 3D model of a character.\n",
              "\n",
              "A character is a piece of information that is attached to a character. Characters can be created using any other \n",
              "character.\n",
              "\n",
              "A character's name can be used to refer to a character.\n",
              "\n",
              "The names\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used to create and manipulate objects. These models are often referred to as \n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">\"models\"</span> by the user. They are often used to create a 3D model of a character.\n",
              "\n",
              "A character is a piece of information that is attached to a character. Characters can be created using any other \n",
              "character.\n",
              "\n",
              "A character's name can be used to refer to a character.\n",
              "\n",
              "The names\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Experimento: efeito da TEMPERATURA\n",
        "# -----------------------------\n",
        "# Intuição:\n",
        "# - temperatura baixa  -> distribuição mais \"concentrada\" -> respostas mais previsíveis/estáveis\n",
        "# - temperatura alta   -> distribuição mais \"espalhada\"   -> respostas mais diversas (e às vezes mais erráticas)\n",
        "#\n",
        "# Mantemos top_p fixo para isolar o efeito da temperatura.\n",
        "temps = [0.2, 0.7, 1.0]\n",
        "top_p_fixed = 0.9\n",
        "\n",
        "for temp in temps:\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(f\"[EXPERIMENTO] TEMPERATURA = {temp} (top_p={top_p_fixed})\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Rodamos 2 amostras para ver variabilidade (sampling).\n",
        "    for i in range(2):\n",
        "        print(f\"\\n[Amostra {i+1}]\")\n",
        "        print(generate_text(prompt, temperature=temp, top_p=top_p_fixed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lO3kHP8sV0_x",
        "outputId": "63f328c1-9416-41cc-ff76-0df301c5a819"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mEXPERIMENTO\u001b[1m]\u001b[0m TEMPERATURA = \u001b[1;36m0.2\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtop_p\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>EXPERIMENTO<span style=\"font-weight: bold\">]</span> TEMPERATURA = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used to represent the physical properties of objects. They are also used to \n",
              "represent the properties of objects in the world.\n",
              "\n",
              "The following table shows the properties of objects in the world.\n",
              "\n",
              "Property Name Description Description \u001b[1;36m1\u001b[0m The object is a cube. \u001b[1;36m2\u001b[0m The object is a cube with a radius of \u001b[1;36m1\u001b[0m. \u001b[1;36m3\u001b[0m The \n",
              "object is a cube with a radius of \u001b[1;36m1\u001b[0m. \u001b[1;36m4\u001b[0m The object is a\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used to represent the physical properties of objects. They are also used to \n",
              "represent the properties of objects in the world.\n",
              "\n",
              "The following table shows the properties of objects in the world.\n",
              "\n",
              "Property Name Description Description <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> The object is a cube. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> The object is a cube with a radius of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> The \n",
              "object is a cube with a radius of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> The object is a\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used to represent the physical properties of objects.\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used to represent the physical properties of objects.\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table lists the properties of the following objects:\n",
              "\n",
              "The following table\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mEXPERIMENTO\u001b[1m]\u001b[0m TEMPERATURA = \u001b[1;36m0.7\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtop_p\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>EXPERIMENTO<span style=\"font-weight: bold\">]</span> TEMPERATURA = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that can be used in conjunction with the default geometry to create the geometry for a \n",
              "given shape.\n",
              "\n",
              "For example, suppose that you have a circle with a square shape. The shape you are looking at is the shape of the \n",
              "circle, and the radius is the radius of the circle. You can also use the radius function to generate the shapes you\n",
              "want.\n",
              "\n",
              "We will define a geometry using the\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that can be used in conjunction with the default geometry to create the geometry for a \n",
              "given shape.\n",
              "\n",
              "For example, suppose that you have a circle with a square shape. The shape you are looking at is the shape of the \n",
              "circle, and the radius is the radius of the circle. You can also use the radius function to generate the shapes you\n",
              "want.\n",
              "\n",
              "We will define a geometry using the\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that can be created by using the following commands:\n",
              "\n",
              "#!\u001b[35m/bin/\u001b[0m\u001b[95mbash\u001b[0m $ python3 $ python3.\u001b[1;36m3\u001b[0m -u\n",
              "\n",
              "Or by using the following command:\n",
              "\n",
              "$ python3 $ python3.\u001b[1;36m3\u001b[0m -u\n",
              "\n",
              "The command you use to create an existing object is:\n",
              "\n",
              "$ python3 create-object -u\n",
              "\n",
              "The -u option lets you specify the\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that can be created by using the following commands:\n",
              "\n",
              "#!<span style=\"color: #800080; text-decoration-color: #800080\">/bin/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">bash</span> $ python3 $ python3.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> -u\n",
              "\n",
              "Or by using the following command:\n",
              "\n",
              "$ python3 $ python3.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> -u\n",
              "\n",
              "The command you use to create an existing object is:\n",
              "\n",
              "$ python3 create-object -u\n",
              "\n",
              "The -u option lets you specify the\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mEXPERIMENTO\u001b[1m]\u001b[0m TEMPERATURA = \u001b[1;36m1.0\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtop_p\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>EXPERIMENTO<span style=\"font-weight: bold\">]</span> TEMPERATURA = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are capable of moving with a single, powerful arm. They can do much more than just \n",
              "lift their arms. They can also drive. They can accelerate and manipulate objects.\n",
              "\n",
              "That means that we can do far more with them. With some technology, we can have them act as vehicles for us. The \n",
              "next time someone tries to drive a car from its position in front of the car, or\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are capable of moving with a single, powerful arm. They can do much more than just \n",
              "lift their arms. They can also drive. They can accelerate and manipulate objects.\n",
              "\n",
              "That means that we can do far more with them. With some technology, we can have them act as vehicles for us. The \n",
              "next time someone tries to drive a car from its position in front of the car, or\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used for rendering the virtual objects in OpenGL. The models that can be applied \n",
              "are defined using the \u001b[32m\"glTexCoordXComposer\"\u001b[0m attribute. OpenGL is the GL coordinate system used to represent all the\n",
              "physical objects on the screen. The actual size of the object on the screen depends on how far away from the object\n",
              "you wish to render. For most applications, the object you're rendering\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used for rendering the virtual objects in OpenGL. The models that can be applied \n",
              "are defined using the <span style=\"color: #008000; text-decoration-color: #008000\">\"glTexCoordXComposer\"</span> attribute. OpenGL is the GL coordinate system used to represent all the\n",
              "physical objects on the screen. The actual size of the object on the screen depends on how far away from the object\n",
              "you wish to render. For most applications, the object you're rendering\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Experimento: efeito do TOP-P (Nucleus Sampling)\n",
        "# -----------------------------\n",
        "# Intuição:\n",
        "# - top_p pequeno (ex.: 0.3)  -> só considera um conjunto bem pequeno de tokens prováveis\n",
        "#                              -> texto mais conservador/repetitivo\n",
        "# - top_p grande  (ex.: 0.9)  -> considera mais candidatos\n",
        "#                              -> mais diversidade (e mais risco de \"viajar\")\n",
        "#\n",
        "# Mantemos temperatura fixa para isolar o efeito do top_p.\n",
        "top_ps = [0.3, 0.6, 0.9]\n",
        "temp_fixed = 0.7\n",
        "\n",
        "for p in top_ps:\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(f\"[EXPERIMENTO] TOP-P = {p} (temperature={temp_fixed})\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Rodamos mais de uma vez para enxergar variabilidade\n",
        "    for i in range(2):\n",
        "        print(f\"\\n[Amostra {i+1}]\")\n",
        "        print(generate_text(prompt, temperature=temp_fixed, top_p=p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "Tndq5X76WF78",
        "outputId": "513aac93-9efa-4e1c-80a0-f5dec1e7c67f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mEXPERIMENTO\u001b[1m]\u001b[0m TOP-P = \u001b[1;36m0.3\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>EXPERIMENTO<span style=\"font-weight: bold\">]</span> TOP-P = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are not part of the game.\n",
              "\n",
              "The following is a list of all the models that are not part of the game.\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are not part of the game.\n",
              "\n",
              "The following is a list of all the models that are not part of the game.\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the game\n",
              "\n",
              "A model that is not part of the\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used to represent the physical properties of objects. They are also used to \n",
              "represent the properties of objects in the world.\n",
              "\n",
              "The following example shows how to use the following model to represent the properties of objects in the world.\n",
              "\n",
              "import math import matplotlib.pyplot as plt import matplotlib.pyplot.pltplot as plt.plt.plt\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used to represent the physical properties of objects. They are also used to \n",
              "represent the properties of objects in the world.\n",
              "\n",
              "The following example shows how to use the following model to represent the properties of objects in the world.\n",
              "\n",
              "import math import matplotlib.pyplot as plt import matplotlib.pyplot.pltplot as plt.plt.plt\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mEXPERIMENTO\u001b[1m]\u001b[0m TOP-P = \u001b[1;36m0.6\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>EXPERIMENTO<span style=\"font-weight: bold\">]</span> TOP-P = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are based on the actual physical world of the character. They are based on the \n",
              "physical world of the character, and are not necessarily the same as the real world.\n",
              "\n",
              "In order to understand the concept of the character, you need to understand how the world works.\n",
              "\n",
              "The world is a collection of things. The world is a collection of things that are not in common, and that are\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are based on the actual physical world of the character. They are based on the \n",
              "physical world of the character, and are not necessarily the same as the real world.\n",
              "\n",
              "In order to understand the concept of the character, you need to understand how the world works.\n",
              "\n",
              "The world is a collection of things. The world is a collection of things that are not in common, and that are\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are designed to be used in a variety of different ways. For example, the model is \n",
              "designed to be used in a variety of different ways, such as as a car or a house. The model can be used in a variety\n",
              "of different ways, such as as a vehicle, a house, or a building.\n",
              "\n",
              "The model can be used in a variety of different ways, such as as\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are designed to be used in a variety of different ways. For example, the model is \n",
              "designed to be used in a variety of different ways, such as as a car or a house. The model can be used in a variety\n",
              "of different ways, such as as a vehicle, a house, or a building.\n",
              "\n",
              "The model can be used in a variety of different ways, such as as\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mEXPERIMENTO\u001b[1m]\u001b[0m TOP-P = \u001b[1;36m0.9\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>EXPERIMENTO<span style=\"font-weight: bold\">]</span> TOP-P = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "========================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">========================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that can be customized to fit the specific needs of your project. In our case, we wanted to\n",
              "have a way to make our existing sprites look like they were made by the same person. To do that, we built an \n",
              "animation system using the Unity 3D engine.\n",
              "\n",
              "The animation system is very simple. It's a collection of sprites that can be animated in a single frame. In this \n",
              "case\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that can be customized to fit the specific needs of your project. In our case, we wanted to\n",
              "have a way to make our existing sprites look like they were made by the same person. To do that, we built an \n",
              "animation system using the Unity 3D engine.\n",
              "\n",
              "The animation system is very simple. It's a collection of sprites that can be animated in a single frame. In this \n",
              "case\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are generated by the graphics processing unit \u001b[1m(\u001b[0mGPU\u001b[1m)\u001b[0m. The graphics processing unit \n",
              "\u001b[1m(\u001b[0mGPU\u001b[1m)\u001b[0m is a small unit that has a fixed resolution and a fixed texture size. In order to have a good image quality, \n",
              "the graphics processing unit must have at least \u001b[1;36m4\u001b[0m texture units. The texture units are arranged in a set of four \n",
              "rows. Each row contains a vertex \u001b[1m(\u001b[0mthe \u001b[32m\"x\"\u001b[0m coordinate\u001b[1m)\u001b[0m. Each row contains\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are generated by the graphics processing unit <span style=\"font-weight: bold\">(</span>GPU<span style=\"font-weight: bold\">)</span>. The graphics processing unit \n",
              "<span style=\"font-weight: bold\">(</span>GPU<span style=\"font-weight: bold\">)</span> is a small unit that has a fixed resolution and a fixed texture size. In order to have a good image quality, \n",
              "the graphics processing unit must have at least <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> texture units. The texture units are arranged in a set of four \n",
              "rows. Each row contains a vertex <span style=\"font-weight: bold\">(</span>the <span style=\"color: #008000; text-decoration-color: #008000\">\"x\"</span> coordinate<span style=\"font-weight: bold\">)</span>. Each row contains\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# KV cache: comparação de tempo (com e sem cache)\n",
        "# -----------------------------\n",
        "# Intuição:\n",
        "# - Sem KV cache: a cada novo token gerado, o modelo \"recalcula\" atenção para toda a sequência.\n",
        "# - Com KV cache: o modelo reaproveita K e V dos tokens passados, economizando compute.\n",
        "#\n",
        "# Importante:\n",
        "# - Medição em Colab tem ruído. Fazemos warm-up e repetimos algumas vezes.\n",
        "\n",
        "import time\n",
        "\n",
        "prompt_kv = \"Large language models rely on attention mechanisms\"\n",
        "\n",
        "def timed_generation(use_cache: bool, n_runs: int = 3) -> float:\n",
        "    \"\"\"Retorna o tempo médio (em segundos) de n_runs gerações.\"\"\"\n",
        "    times = []\n",
        "\n",
        "    # Warm-up: reduz a chance da primeira medição ser um outlier\n",
        "    _ = generate_text(\n",
        "        prompt_kv,\n",
        "        max_new_tokens=120,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        use_cache=use_cache,\n",
        "    )\n",
        "\n",
        "    for _ in range(n_runs):\n",
        "        start = time.time()\n",
        "        _ = generate_text(\n",
        "            prompt_kv,\n",
        "            max_new_tokens=120,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            use_cache=use_cache,\n",
        "        )\n",
        "        times.append(time.time() - start)\n",
        "\n",
        "    return sum(times) / len(times)\n",
        "\n",
        "t_cache = timed_generation(True, n_runs=3)\n",
        "t_no_cache = timed_generation(False, n_runs=3)\n",
        "\n",
        "print(\"\\n[KV CACHE — TEMPO MÉDIO]\")\n",
        "print(f\"Com cache : {t_cache:.4f} s\")\n",
        "print(f\"Sem cache : {t_no_cache:.4f} s\")\n",
        "\n",
        "# Speedup (quanto mais rápido com cache)\n",
        "if t_cache > 0:\n",
        "    print(f\"Speedup  : {t_no_cache / t_cache:.2f}×\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "_SHr332KWR2d",
        "outputId": "94b5c07f-56e1-4d71-910b-42c41b5d6ac3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mKV CACHE — TEMPO MÉDIO\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>KV CACHE — TEMPO MÉDIO<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Com cache : \u001b[1;36m2.2645\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Com cache : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2645</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sem cache : \u001b[1;36m1.2460\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sem cache : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2460</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Speedup  : \u001b[1;36m0.55\u001b[0m×\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Speedup  : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.55</span>×\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "# PRÁTICA 1: INFERÊNCIA INTERATIVA (PROMPTS + VARIAÇÃO)\n",
        "#"
      ],
      "metadata": {
        "id": "G_012xkwWU4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Prompt direto vs \"step by step\" (demonstração didática)\n",
        "# -----------------------------\n",
        "# Ideia:\n",
        "# - O prompt pode mudar o \"modo\" de resposta do modelo.\n",
        "# - \"Step by step\" costuma induzir explicação em etapas (às vezes melhora a qualidade),\n",
        "#   mas NÃO é garantia de acerto — especialmente em modelos pequenos.\n",
        "#\n",
        "# Aqui a meta é comparar:\n",
        "# (1) resposta curta/direta\n",
        "# (2) resposta explicada em etapas\n",
        "# mantendo os mesmos hiperparâmetros de geração.\n",
        "\n",
        "prompt_direct = \"What is 27 + 58?\"\n",
        "prompt_step   = \"Solve step by step: 27 + 58.\"\n",
        "\n",
        "# Mantemos decoding constante para a comparação ser justa\n",
        "TEMP = 0.7\n",
        "TOP_P = 0.9\n",
        "\n",
        "print(\"\\n=== Direto (resposta curta) ===\")\n",
        "print(generate_text(\n",
        "    prompt_direct,\n",
        "    temperature=TEMP,\n",
        "    top_p=TOP_P,\n",
        "    max_new_tokens=40\n",
        "))\n",
        "\n",
        "print(\"\\n=== Step by step (explicado em etapas) ===\")\n",
        "print(generate_text(\n",
        "    prompt_step,\n",
        "    temperature=TEMP,\n",
        "    top_p=TOP_P,\n",
        "    max_new_tokens=80\n",
        "))\n",
        "\n",
        "# (Opcional) Nota didática rápida para a turma:\n",
        "# - Se o modelo errar 27+58, isso é um gancho para discutir:\n",
        "#   \"fluência\" ≠ \"correção\".\n",
        "# - Modelos maiores e/ou métodos como self-consistency costumam ajudar mais."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "XmwdpDTbXFtA",
        "outputId": "3deb782b-6e4f-442e-ccf3-dd0540789468"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "=== Direto \u001b[1m(\u001b[0mresposta curta\u001b[1m)\u001b[0m ===\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "=== Direto <span style=\"font-weight: bold\">(</span>resposta curta<span style=\"font-weight: bold\">)</span> ===\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "What is \u001b[1;36m27\u001b[0m + \u001b[1;36m58\u001b[0m?\n",
              "\n",
              "This is the 27th of the month and the first month of the year.\n",
              "\n",
              "Do you have a question about this question? Please send it to the question form below and I will\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>?\n",
              "\n",
              "This is the 27th of the month and the first month of the year.\n",
              "\n",
              "Do you have a question about this question? Please send it to the question form below and I will\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "=== Step by step \u001b[1m(\u001b[0mexplicado em etapas\u001b[1m)\u001b[0m ===\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "=== Step by step <span style=\"font-weight: bold\">(</span>explicado em etapas<span style=\"font-weight: bold\">)</span> ===\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Solve step by step: \u001b[1;36m27\u001b[0m + \u001b[1;36m58.5\u001b[0m% = \u001b[1;36m29.9\u001b[0m%\n",
              "\n",
              "The most common method of solving this puzzle is by using a series of steps, which are repeated over and over. As \n",
              "you progress, you can see how difficult it is to get all \u001b[1;36m27\u001b[0m steps, which are the same as the first \u001b[1;36m25\u001b[0m.\n",
              "\n",
              "A typical puzzle is this:\n",
              "\n",
              "Step \u001b[1;36m1\u001b[0m:\n",
              "\n",
              "Step \u001b[1;36m2\u001b[0m:\n",
              "\n",
              "Step \u001b[1;36m3\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solve step by step: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.5</span>% = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.9</span>%\n",
              "\n",
              "The most common method of solving this puzzle is by using a series of steps, which are repeated over and over. As \n",
              "you progress, you can see how difficult it is to get all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> steps, which are the same as the first <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>.\n",
              "\n",
              "A typical puzzle is this:\n",
              "\n",
              "Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>:\n",
              "\n",
              "Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>:\n",
              "\n",
              "Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Variabilidade com temperatura mais alta (sampling)\n",
        "# -----------------------------\n",
        "# O que observar:\n",
        "# - Com temperatura/top_p mais altos, a saída tende a variar mais entre execuções\n",
        "# - A estrutura pode mudar (ordem dos passos, detalhes, exemplos), mesmo mantendo a mesma pergunta\n",
        "\n",
        "N_SAMPLES = 3\n",
        "TEMP = 0.9\n",
        "TOP_P = 0.95\n",
        "MAX_TOKENS = 80\n",
        "\n",
        "print(\"\\n[Experimento] Variabilidade com sampling mais 'solto'\")\n",
        "print(f\"Config: temperature={TEMP}, top_p={TOP_P}, max_new_tokens={MAX_TOKENS}\")\n",
        "\n",
        "for i in range(N_SAMPLES):\n",
        "    print(f\"\\n--- Amostra {i+1}/{N_SAMPLES} ---\")\n",
        "\n",
        "    # (Opcional) Seed para reprodutibilidade controlada:\n",
        "    # Descomente se quiser que cada amostra seja sempre a mesma em cada execução do notebook.\n",
        "    # torch.manual_seed(100 + i)\n",
        "\n",
        "    print(generate_text(\n",
        "        prompt_step,\n",
        "        temperature=TEMP,\n",
        "        top_p=TOP_P,\n",
        "        max_new_tokens=MAX_TOKENS\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "9nyHflSAXJ8R",
        "outputId": "cbbf4e7e-0251-47cf-e804-fd2b0ac7dfdb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mExperimento\u001b[1m]\u001b[0m Variabilidade com sampling mais \u001b[32m'solto'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Experimento<span style=\"font-weight: bold\">]</span> Variabilidade com sampling mais <span style=\"color: #008000; text-decoration-color: #008000\">'solto'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Config: \u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9\u001b[0m, \u001b[33mtop_p\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.95\u001b[0m, \u001b[33mmax_new_tokens\u001b[0m=\u001b[1;36m80\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Config: <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_new_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- Amostra \u001b[1;36m1\u001b[0m/\u001b[1;36m3\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Solve step by step: \u001b[1;36m27\u001b[0m + \u001b[1;36m58.6\u001b[0m × \u001b[1;36m3.37\u001b[0m = \u001b[1;36m7\u001b[0m + \u001b[1;36m0.093\u001b[0m × \u001b[1;36m1.19\u001b[0m = \u001b[1;36m6\u001b[0m\n",
              "\n",
              "Step \u001b[1;36m1\u001b[0m: \u001b[1;36m5\u001b[0m × \u001b[1;36m9\u001b[0m = \u001b[1;36m8\u001b[0m + \u001b[1;36m0.093\u001b[0m × \u001b[1;36m1.19\u001b[0m = \u001b[1;36m5\u001b[0m\n",
              "\n",
              "Step \u001b[1;36m2\u001b[0m: \u001b[1;36m8\u001b[0m × \u001b[1;36m9\u001b[0m = \u001b[1;36m7\u001b[0m + \u001b[1;36m0.093\u001b[0m × \u001b[1;36m1.19\u001b[0m = \u001b[1;36m4\u001b[0m\n",
              "\n",
              "Step \u001b[1;36m3\u001b[0m: \u001b[1;36m7\u001b[0m × \u001b[1;36m9\u001b[0m = \u001b[1;36m6\u001b[0m + \u001b[1;36m0.093\u001b[0m × \u001b[1;36m1.19\u001b[0m =\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solve step by step: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.6</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.37</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.093</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.19</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
              "\n",
              "Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.093</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.19</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
              "\n",
              "Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.093</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.19</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
              "\n",
              "Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.093</span> × <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.19</span> =\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- Amostra \u001b[1;36m2\u001b[0m/\u001b[1;36m3\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Solve step by step: \u001b[1;36m27\u001b[0m + \u001b[1;36m58\u001b[0m.\n",
              "\n",
              "This step includes:\n",
              "\n",
              "\u001b[1;36m25\u001b[0m – \u001b[1;36m35\u001b[0m \u001b[1m(\u001b[0mnot in the \u001b[1;36m4\u001b[0m/\u001b[1;36m4\u001b[0m or \u001b[1;36m6\u001b[0m/\u001b[1;36m6\u001b[0m group\u001b[1m)\u001b[0m,\n",
              "\n",
              "\u001b[1;36m50\u001b[0m – \u001b[1;36m75\u001b[0m \u001b[1m(\u001b[0mnot in the \u001b[1;36m5\u001b[0m/\u001b[1;36m7\u001b[0m and \u001b[1;36m6\u001b[0m/\u001b[1;36m8\u001b[0m group\u001b[1m)\u001b[0m,\n",
              "\n",
              "\u001b[1;36m75\u001b[0m – \u001b[1;36m85\u001b[0m \u001b[1m(\u001b[0mnot in the \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m and \u001b[1;36m6\u001b[0m/\u001b[1;36m7\u001b[0m group\u001b[1m)\u001b[0m,\n",
              "\n",
              "\u001b[1;36m90\u001b[0m – \u001b[1;36m95\u001b[0m \u001b[1m(\u001b[0mnot in the \u001b[1;36m6\u001b[0m/\u001b[1;36m5\u001b[0m and \u001b[1;36m6\u001b[0m/\u001b[1;36m8\u001b[0m group\u001b[1m)\u001b[0m,\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solve step by step: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>.\n",
              "\n",
              "This step includes:\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> – <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> <span style=\"font-weight: bold\">(</span>not in the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> group<span style=\"font-weight: bold\">)</span>,\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> – <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span> <span style=\"font-weight: bold\">(</span>not in the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> group<span style=\"font-weight: bold\">)</span>,\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span> – <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span> <span style=\"font-weight: bold\">(</span>not in the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> group<span style=\"font-weight: bold\">)</span>,\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span> – <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span> <span style=\"font-weight: bold\">(</span>not in the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> group<span style=\"font-weight: bold\">)</span>,\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- Amostra \u001b[1;36m3\u001b[0m/\u001b[1;36m3\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Solve step by step: \u001b[1;36m27\u001b[0m + \u001b[1;36m58.5\u001b[0m + \u001b[1;36m30\u001b[0m + \u001b[1;36m61.5\u001b[0m - \u001b[1;36m30\u001b[0m + \u001b[1;36m57.5\u001b[0m + \u001b[1;36m31\u001b[0m + \u001b[1;36m63.5\u001b[0m - \u001b[1;36m34\u001b[0m + \u001b[1;36m62\u001b[0m + \u001b[1;36m33\u001b[0m + \u001b[1;36m67\u001b[0m + \u001b[1;36m37\u001b[0m + \u001b[1;36m64\u001b[0m + \u001b[1;36m35\u001b[0m + \u001b[1;36m70\u001b[0m + \u001b[1;36m37\u001b[0m + \u001b[1;36m67\u001b[0m\n",
              "+ \u001b[1;36m38\u001b[0m + \u001b[1;36m66\u001b[0m + \u001b[1;36m38\u001b[0m + \u001b[1;36m67\u001b[0m + \u001b[1;36m39\u001b[0m + \u001b[1;36m67\u001b[0m + \u001b[1;36m39\u001b[0m + \u001b[1;36m67\u001b[0m + \u001b[1;36m40\u001b[0m + \u001b[1;36m67\u001b[0m + \u001b[1;36m41\u001b[0m + \u001b[1;36m68\u001b[0m + \u001b[1;36m42\u001b[0m + \u001b[1;36m69\u001b[0m + \u001b[1;36m42\u001b[0m + \u001b[1;36m69\u001b[0m + \u001b[1;36m43\u001b[0m + \u001b[1;36m69\u001b[0m + \u001b[1;36m44\u001b[0m + \u001b[1;36m70\u001b[0m +\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solve step by step: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.5</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61.5</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57.5</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63.5</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>\n",
              "+ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span> +\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferência Interativa: experimentação guiada com prompts e parâmetros de geração, explorando variação de temperatura, top-p e raciocínio via chain-of-thought.\n"
      ],
      "metadata": {
        "id": "kCVUV6aPGRc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SETUP —  Inferência Interativa\n",
        "#\n",
        "# Objetivo:\n",
        "# - Instalar dependências mínimas\n",
        "# - Importar bibliotecas\n",
        "# - Detectar o device (GPU/CPU) para rodar inferência de forma eficiente\n",
        "# ============================================================\n",
        "\n",
        "# 1) Instalação (uma vez por sessão Colab)\n",
        "# - transformers: carregar modelos/tokenizers do Hugging Face\n",
        "# - torch: tensores e execução em GPU/CPU\n",
        "# - numpy: utilidades numéricas (às vezes útil para análises simples)\n",
        "!pip -q install transformers torch numpy\n",
        "\n",
        "# 2) Imports\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# 3) Device (GPU se disponível, senão CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"[INFO] Device detectado: {device}\")\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Nota: este notebook é de INFERÊNCIA (não treino).\n",
        "# Em células de geração, prefira usar:\n",
        "#   with torch.inference_mode(): ...\n",
        "# para reduzir overhead e deixar explícito que não há gradientes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NASqDfneXg9n",
        "outputId": "b7ac0795-6259-4c56-9544-53652bc0735e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Device detectado: cuda\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Device detectado: cuda\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m GPU: Tesla T4\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> GPU: Tesla T4\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CARREGAR MODELO CAUSAL (GPT-2)\n",
        "#\n",
        "# Objetivo:\n",
        "# - Carregar um modelo \"decoder-only\" (causal) para geração autoregressiva\n",
        "# - Preparar tokenizer + modelo no mesmo device (CPU/GPU)\n",
        "# ============================================================\n",
        "\n",
        "gpt_name = \"gpt2\"\n",
        "\n",
        "# 1) Tokenizer: texto <-> tokens (ids inteiros)\n",
        "tokenizer = AutoTokenizer.from_pretrained(gpt_name)\n",
        "\n",
        "# GPT-2 normalmente não vem com pad_token definido.\n",
        "# Para evitar warnings em generate (especialmente se houver padding),\n",
        "# definimos pad_token = eos_token (prática comum em GPT-2).\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 2) Modelo causal: pronto para prever próximo token e usar model.generate()\n",
        "model = AutoModelForCausalLM.from_pretrained(gpt_name).to(device)\n",
        "\n",
        "# 3) Modo avaliação: desativa dropout e estabiliza inferência\n",
        "model.eval()\n",
        "\n",
        "print(f\"\\n[OK] Modelo carregado: {gpt_name}\")\n",
        "print(f\"[INFO] Device do modelo: {next(model.parameters()).device}\")\n",
        "\n",
        "# 4) Mostra a \"árvore\" de módulos (embeddings, blocos, atenção, MLP...)\n",
        "print(\"\\n[ARQUITETURA — VISÃO GERAL]\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "d89381d4f0224de490be3d599d6b1e2c",
            "f019b555ad7f4c36bd0323d59407498f",
            "9cbcc73e47b3427e9e13f4067401dafc",
            "343309a38f2047589c05c8b91ebd9b97",
            "3ae98a2a6e954d7ba758e4449aa8ff60",
            "1df2878caa8e4d6587c5303c8e03bbeb",
            "bfbaee2485c94579acc465c3e182a803",
            "2406b18e361544188d8a3845402a0294",
            "ff3502418a714f29aa97e137f52912f8",
            "978c92fad21c47ebb481e216a6a738b3",
            "54676a737cbf43acb9b09b218c9b7c21"
          ]
        },
        "id": "mXUR5P6bYeMe",
        "outputId": "e03f8afd-0ea4-47a7-86df-6931d40d08a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d89381d4f0224de490be3d599d6b1e2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m Modelo carregado: gpt2\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> Modelo carregado: gpt2\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Device do modelo: cu\u001b[1;92mda:0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Device do modelo: cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mARQUITETURA — VISÃO GERAL\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>ARQUITETURA — VISÃO GERAL<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mGPT2LMHeadModel\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mtransformer\u001b[1m)\u001b[0m: \u001b[1;35mGPT2Model\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mwte\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m50257\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mwpe\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1024\u001b[0m, \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mh\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m12\u001b[0m x \u001b[1;35mGPT2Block\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mln_1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mGPT2Attention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_attn\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m2304\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mattn_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mln_2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mGPT2MLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_fc\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mc_proj\u001b[1m)\u001b[0m: \u001b[1;35mConv1D\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnf\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mnx\u001b[0m=\u001b[1;36m3072\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0mln_f\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m768\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mlm_head\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m768\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m50257\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2LMHeadModel</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>transformer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Model</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>wte<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>wpe<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>h<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Block</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>ln_1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2Attention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2304</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>attn_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>ln_2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPT2MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_fc<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>c_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conv1D</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">nf</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">nx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span><span style=\"font-weight: bold\">)</span>\n",
              "          <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "          <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span>ln_f<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>lm_head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FUNÇÃO DE GERAÇÃO CONTROLADA (decoding)\n",
        "# ============================================================\n",
        "# O modelo sempre produz logits (probabilidades do próximo token).\n",
        "# \"Decoding\" é como escolhemos o próximo token a partir dessas probabilidades.\n",
        "#\n",
        "# Parâmetros principais:\n",
        "# - temperature: controla quão \"aberta\" fica a distribuição (diversidade)\n",
        "# - top_p: nucleus sampling (considera só um conjunto de tokens que soma p de prob.)\n",
        "# - do_sample: se False, vira greedy/beam e temperature/top_p podem perder efeito\n",
        "# - use_cache: ativa KV cache (acelera geração em prompts longos)\n",
        "def generate_text(\n",
        "    prompt: str,\n",
        "    temperature: float = 0.7,\n",
        "    top_p: float = 0.9,\n",
        "    max_new_tokens: int = 80,\n",
        "    use_cache: bool = True,\n",
        "    do_sample: bool = True,\n",
        "):\n",
        "    # 1) Tokeniza o prompt e envia para o mesmo device do modelo\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # 2) Inferência (sem gradientes, sem treino)\n",
        "    with torch.inference_mode():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=do_sample,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            use_cache=use_cache,\n",
        "            pad_token_id=tokenizer.eos_token_id,  # evita warnings no GPT-2\n",
        "        )\n",
        "\n",
        "    # 3) Decodifica ids -> texto\n",
        "    return tokenizer.decode(out_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "A2EXSoWpZBx2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TEMPERATURA (τ): controle de aleatoriedade\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VARIAÇÃO DE TEMPERATURA (τ)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Prompt base (curto e neutro para facilitar comparação)\n",
        "prompt = \"Transformers are models that\"\n",
        "\n",
        "# Valores de temperatura para comparação\n",
        "temps = [0.2, 0.7, 1.0]\n",
        "\n",
        "# Guardamos as saídas em um dicionário (útil para comparar depois)\n",
        "outputs_temp = {}\n",
        "\n",
        "print(\"\\nO que observar:\")\n",
        "print(\"- Coerência / fluência\")\n",
        "print(\"- Diversidade de palavras/ideias\")\n",
        "print(\"- Tendência a repetir padrões vs. inventar variações\\n\")\n",
        "\n",
        "# (Opcional) mais de uma amostra por temperatura para evidenciar variabilidade\n",
        "N_SAMPLES = 2\n",
        "\n",
        "for t in temps:\n",
        "    print(\"\\n\" + \"-\"*30)\n",
        "    print(f\"TEMPERATURA = {t}\")\n",
        "    print(\"-\"*30)\n",
        "\n",
        "    outputs_temp[t] = []\n",
        "\n",
        "    for i in range(N_SAMPLES):\n",
        "        text = generate_text(prompt, temperature=t, top_p=0.9, max_new_tokens=80, do_sample=True)\n",
        "        outputs_temp[t].append(text)\n",
        "\n",
        "        print(f\"\\n[Amostra {i+1}]\")\n",
        "        print(text)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPLICAÇÃO — RESUMO\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "- τ = 0.2 (baixa):\n",
        "  Saída mais rígida e previsível. O modelo tende a escolher tokens muito prováveis.\n",
        "  Distribuição efetiva fica mais concentrada → menos diversidade.\n",
        "\n",
        "- τ = 0.7 (média):\n",
        "  Bom equilíbrio: mantém coerência e ainda permite variações úteis.\n",
        "\n",
        "- τ = 1.0 (alta):\n",
        "  Mais diversidade e “criatividade”, mas aumenta o risco de deriva semântica/erros.\n",
        "\n",
        "Conclusão:\n",
        "Temperatura controla a “concentração” da distribuição de escolha do próximo token:\n",
        "τ baixo concentra (mais determinístico); τ alto espalha (mais diverso).\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j-GYESJKYhVE",
        "outputId": "76d3bbc2-d742-4ad9-e5bb-ca263765d7ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VARIAÇÃO DE TEMPERATURA \u001b[1m(\u001b[0mτ\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">VARIAÇÃO DE TEMPERATURA <span style=\"font-weight: bold\">(</span>τ<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "O que observar:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "O que observar:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- Coerência \u001b[35m/\u001b[0m fluência\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Coerência <span style=\"color: #800080; text-decoration-color: #800080\">/</span> fluência\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- Diversidade de palavras/ideias\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Diversidade de palavras/ideias\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- Tendência a repetir padrões vs. inventar variações\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Tendência a repetir padrões vs. inventar variações\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TEMPERATURA = \u001b[1;36m0.2\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEMPERATURA = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used to represent the properties of objects.\n",
              "\n",
              "The following example shows how to create a model that is used to represent the properties of objects.\n",
              "\n",
              "public class Model \u001b[1m{\u001b[0m public static void \u001b[1;35mmain\u001b[0m\u001b[1m(\u001b[0mString\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m args\u001b[1m)\u001b[0m \u001b[1m{\u001b[0m \u001b[1;35mModel.setProperty\u001b[0m\u001b[1m(\u001b[0mnew \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"name\"\u001b[0m, \u001b[32m\"name\"\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m; \u001b[1m}\u001b[0m \u001b[1m}\u001b[0m\n",
              "\n",
              "The following example shows how to create a model that is used to represent the properties\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used to represent the properties of objects.\n",
              "\n",
              "The following example shows how to create a model that is used to represent the properties of objects.\n",
              "\n",
              "public class Model <span style=\"font-weight: bold\">{</span> public static void <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">main</span><span style=\"font-weight: bold\">(</span>String<span style=\"font-weight: bold\">[]</span> args<span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">{</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model.setProperty</span><span style=\"font-weight: bold\">(</span>new <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span><span style=\"font-weight: bold\">))</span>; <span style=\"font-weight: bold\">}</span> <span style=\"font-weight: bold\">}</span>\n",
              "\n",
              "The following example shows how to create a model that is used to represent the properties\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used to represent the properties of objects.\n",
              "\n",
              "The following example shows how to use the following properties to represent the properties of objects.\n",
              "\n",
              "public class Object \u001b[1m{\u001b[0m public static void \u001b[1;35mmain\u001b[0m\u001b[1m(\u001b[0mString\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m args\u001b[1m)\u001b[0m \u001b[1m{\u001b[0m Object object = new \u001b[1;35mObject\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m; Object object = new \n",
              "\u001b[1;35mObject\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m; Object object = new \u001b[1;35mObject\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m; Object object = new \u001b[1;35mObject\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m; Object object = new \u001b[1;35mObject\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m; Object object =\n",
              "new \u001b[1;35mObject\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m;\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used to represent the properties of objects.\n",
              "\n",
              "The following example shows how to use the following properties to represent the properties of objects.\n",
              "\n",
              "public class Object <span style=\"font-weight: bold\">{</span> public static void <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">main</span><span style=\"font-weight: bold\">(</span>String<span style=\"font-weight: bold\">[]</span> args<span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">{</span> Object object = new <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Object</span><span style=\"font-weight: bold\">()</span>; Object object = new \n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Object</span><span style=\"font-weight: bold\">()</span>; Object object = new <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Object</span><span style=\"font-weight: bold\">()</span>; Object object = new <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Object</span><span style=\"font-weight: bold\">()</span>; Object object = new <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Object</span><span style=\"font-weight: bold\">()</span>; Object object =\n",
              "new <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Object</span><span style=\"font-weight: bold\">()</span>;\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TEMPERATURA = \u001b[1;36m0.7\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEMPERATURA = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that can be used to represent objects in the game world. For example, the following is an \n",
              "example of a particle model that represents a player character:\n",
              "\n",
              "\u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Example of particle model for a player character. \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Use this as a model for the player character. \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m The \n",
              "following is an example of a particle model for a player character. \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Use this as a model for the player \n",
              "character. \u001b[35m/\u001b[0m\u001b[35m/\u001b[0m The\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that can be used to represent objects in the game world. For example, the following is an \n",
              "example of a particle model that represents a player character:\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">//</span> Example of particle model for a player character. <span style=\"color: #800080; text-decoration-color: #800080\">//</span> Use this as a model for the player character. <span style=\"color: #800080; text-decoration-color: #800080\">//</span> The \n",
              "following is an example of a particle model for a player character. <span style=\"color: #800080; text-decoration-color: #800080\">//</span> Use this as a model for the player \n",
              "character. <span style=\"color: #800080; text-decoration-color: #800080\">//</span> The\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are created by the AI. It is the case that the AI is able to predict the direction and\n",
              "speed of the player's movement by looking at the data in the data and calculating how long the player is going to \n",
              "be able to move.\n",
              "\n",
              "The player can also calculate the speed of a vehicle by calculating the speed at which it will be moving.\n",
              "\n",
              "To use this information in a game\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are created by the AI. It is the case that the AI is able to predict the direction and\n",
              "speed of the player's movement by looking at the data in the data and calculating how long the player is going to \n",
              "be able to move.\n",
              "\n",
              "The player can also calculate the speed of a vehicle by calculating the speed at which it will be moving.\n",
              "\n",
              "To use this information in a game\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TEMPERATURA = \u001b[1;36m1.0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEMPERATURA = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that can have a default value of null.\n",
              "\n",
              "If you are a creator of an image or texture, that's usually not a problem. A non-default value will give you an \n",
              "error message if the object isn't initialized with the correct value.\n",
              "\n",
              "If you're using a texture you could use the --no-initialize flag.\n",
              "\n",
              "Example\n",
              "\n",
              "use Wolf, Wolf.Color\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that can have a default value of null.\n",
              "\n",
              "If you are a creator of an image or texture, that's usually not a problem. A non-default value will give you an \n",
              "error message if the object isn't initialized with the correct value.\n",
              "\n",
              "If you're using a texture you could use the --no-initialize flag.\n",
              "\n",
              "Example\n",
              "\n",
              "use Wolf, Wolf.Color\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used for all interactions with objects. Objects are defined as a set of variables \n",
              "such as the name, the type of an object and the name of its value. This is the first part of our example.\n",
              "\n",
              "var object = \u001b[1;35mfunction\u001b[0m\u001b[1m(\u001b[0mname, value\u001b[1m)\u001b[0m \u001b[1m{\u001b[0m \u001b[1;35mconsole.log\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"name = \"\u001b[0m + name\u001b[1m)\u001b[0m; \u001b[1m}\u001b[0m\n",
              "\n",
              "The function is simply passed a list of variables, and returns the\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used for all interactions with objects. Objects are defined as a set of variables \n",
              "such as the name, the type of an object and the name of its value. This is the first part of our example.\n",
              "\n",
              "var object = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">function</span><span style=\"font-weight: bold\">(</span>name, value<span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">{</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">console.log</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"name = \"</span> + name<span style=\"font-weight: bold\">)</span>; <span style=\"font-weight: bold\">}</span>\n",
              "\n",
              "The function is simply passed a list of variables, and returns the\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "EXPLICAÇÃO — RESUMO\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">EXPLICAÇÃO — RESUMO\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "- τ = \u001b[1;36m0.2\u001b[0m \u001b[1m(\u001b[0mbaixa\u001b[1m)\u001b[0m:\n",
              "  Saída mais rígida e previsível. O modelo tende a escolher tokens muito prováveis.\n",
              "  Distribuição efetiva fica mais concentrada → menos diversidade.\n",
              "\n",
              "- τ = \u001b[1;36m0.7\u001b[0m \u001b[1m(\u001b[0mmédia\u001b[1m)\u001b[0m:\n",
              "  Bom equilíbrio: mantém coerência e ainda permite variações úteis.\n",
              "\n",
              "- τ = \u001b[1;36m1.0\u001b[0m \u001b[1m(\u001b[0malta\u001b[1m)\u001b[0m:\n",
              "  Mais diversidade e “criatividade”, mas aumenta o risco de deriva semântica/erros.\n",
              "\n",
              "Conclusão:\n",
              "Temperatura controla a “concentração” da distribuição de escolha do próximo token:\n",
              "τ baixo concentra \u001b[1m(\u001b[0mmais determinístico\u001b[1m)\u001b[0m; τ alto espalha \u001b[1m(\u001b[0mmais diverso\u001b[1m)\u001b[0m.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "- τ = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span> <span style=\"font-weight: bold\">(</span>baixa<span style=\"font-weight: bold\">)</span>:\n",
              "  Saída mais rígida e previsível. O modelo tende a escolher tokens muito prováveis.\n",
              "  Distribuição efetiva fica mais concentrada → menos diversidade.\n",
              "\n",
              "- τ = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span> <span style=\"font-weight: bold\">(</span>média<span style=\"font-weight: bold\">)</span>:\n",
              "  Bom equilíbrio: mantém coerência e ainda permite variações úteis.\n",
              "\n",
              "- τ = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span> <span style=\"font-weight: bold\">(</span>alta<span style=\"font-weight: bold\">)</span>:\n",
              "  Mais diversidade e “criatividade”, mas aumenta o risco de deriva semântica/erros.\n",
              "\n",
              "Conclusão:\n",
              "Temperatura controla a “concentração” da distribuição de escolha do próximo token:\n",
              "τ baixo concentra <span style=\"font-weight: bold\">(</span>mais determinístico<span style=\"font-weight: bold\">)</span>; τ alto espalha <span style=\"font-weight: bold\">(</span>mais diverso<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TOP-P (Nucleus Sampling): controla \"quantos candidatos\" entram no sorteio\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VARIAÇÃO DE TOP-P (NUCLEUS SAMPLING)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Mantemos temperatura fixa para isolar o efeito do top-p\n",
        "temp_fixed = 0.7\n",
        "ps = [0.3, 0.6, 0.9]\n",
        "\n",
        "outputs_p = {}\n",
        "\n",
        "print(\"\\nO que observar:\")\n",
        "print(\"- Repetição vs. variedade (lexical/temática)\")\n",
        "print(\"- Coerência do texto\")\n",
        "print(\"- Aparição de ideias inesperadas\\n\")\n",
        "\n",
        "N_SAMPLES = 2\n",
        "\n",
        "for p in ps:\n",
        "    print(\"\\n\" + \"-\"*30)\n",
        "    print(f\"TOP-P = {p} (temperature={temp_fixed})\")\n",
        "    print(\"-\"*30)\n",
        "\n",
        "    outputs_p[p] = []\n",
        "\n",
        "    for i in range(N_SAMPLES):\n",
        "        text = generate_text(\n",
        "            prompt,\n",
        "            temperature=temp_fixed,\n",
        "            top_p=p,\n",
        "            max_new_tokens=80,\n",
        "            do_sample=True\n",
        "        )\n",
        "        outputs_p[p].append(text)\n",
        "\n",
        "        print(f\"\\n[Amostra {i+1}]\")\n",
        "        print(text)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPLICAÇÃO — RESUMO\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "- top-p = 0.3:\n",
        "  Considera apenas um conjunto bem pequeno de tokens muito prováveis.\n",
        "  Tendência a texto mais conservador e repetitivo.\n",
        "\n",
        "- top-p = 0.6:\n",
        "  Abre espaço para variedade moderada, mantendo controle.\n",
        "\n",
        "- top-p = 0.9:\n",
        "  Permite um conjunto maior de candidatos → mais diversidade,\n",
        "  mas pode aumentar o risco de \"deriva\" (sair do trilho).\n",
        "\n",
        "Conclusão:\n",
        "Top-p controla o tamanho efetivo do conjunto de candidatos:\n",
        "baixo = mais conservador; alto = mais exploratório.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sZ_6RmTvYzNB",
        "outputId": "bb55f6b6-5b04-41c5-9050-05c55cfee924"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VARIAÇÃO DE TOP-P \u001b[1m(\u001b[0mNUCLEUS SAMPLING\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">VARIAÇÃO DE TOP-P <span style=\"font-weight: bold\">(</span>NUCLEUS SAMPLING<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "O que observar:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "O que observar:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- Repetição vs. variedade \u001b[1m(\u001b[0mlexical/temática\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Repetição vs. variedade <span style=\"font-weight: bold\">(</span>lexical/temática<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- Coerência do texto\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Coerência do texto\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- Aparição de ideias inesperadas\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Aparição de ideias inesperadas\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TOP-P = \u001b[1;36m0.3\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TOP-P = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are not part of the original game.\n",
              "\n",
              "The game is based on the original Star Wars: The Old Republic, and is based on the original Star Wars: The Old \n",
              "Republic, and is based on the original Star Wars: The Old Republic, and is based on the original Star Wars: The Old\n",
              "Republic, and is based on the original Star Wars: The Old Republic, and is based on\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are not part of the original game.\n",
              "\n",
              "The game is based on the original Star Wars: The Old Republic, and is based on the original Star Wars: The Old \n",
              "Republic, and is based on the original Star Wars: The Old Republic, and is based on the original Star Wars: The Old\n",
              "Republic, and is based on the original Star Wars: The Old Republic, and is based on\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are used to represent the shape of the object.\n",
              "\n",
              "The following example shows how to create a new object with the following properties:\n",
              "\n",
              "public class Object \u001b[1m{\u001b[0m public static void \u001b[1;35mmain\u001b[0m\u001b[1m(\u001b[0mString\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m args\u001b[1m)\u001b[0m \u001b[1m{\u001b[0m Object object = new \u001b[1;35mObject\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m; \u001b[1m}\u001b[0m \u001b[1m}\u001b[0m\n",
              "\n",
              "The following example shows how to create a new object with the following properties:\n",
              "\n",
              "public class Object \u001b[1m{\u001b[0m public static void \u001b[1;35mmain\u001b[0m\u001b[1m(\u001b[0mString\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are used to represent the shape of the object.\n",
              "\n",
              "The following example shows how to create a new object with the following properties:\n",
              "\n",
              "public class Object <span style=\"font-weight: bold\">{</span> public static void <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">main</span><span style=\"font-weight: bold\">(</span>String<span style=\"font-weight: bold\">[]</span> args<span style=\"font-weight: bold\">)</span> <span style=\"font-weight: bold\">{</span> Object object = new <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Object</span><span style=\"font-weight: bold\">()</span>; <span style=\"font-weight: bold\">}</span> <span style=\"font-weight: bold\">}</span>\n",
              "\n",
              "The following example shows how to create a new object with the following properties:\n",
              "\n",
              "public class Object <span style=\"font-weight: bold\">{</span> public static void <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">main</span><span style=\"font-weight: bold\">(</span>String\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TOP-P = \u001b[1;36m0.6\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TOP-P = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are modeled after the human brain. The most common example is the human brain, which \n",
              "has a large number of neurons, but which is often called the \u001b[32m\"brain of the human mind.\"\u001b[0m The human brain is composed\n",
              "of about \u001b[1;36m100\u001b[0m neurons, and each neuron has about \u001b[1;36m50\u001b[0m,\u001b[1;36m000\u001b[0m neurons. The human brain has about \u001b[1;36m4.5\u001b[0m billion neurons, and \n",
              "each neuron has about \u001b[1;36m50\u001b[0m,\u001b[1;36m000\u001b[0m neurons.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are modeled after the human brain. The most common example is the human brain, which \n",
              "has a large number of neurons, but which is often called the <span style=\"color: #008000; text-decoration-color: #008000\">\"brain of the human mind.\"</span> The human brain is composed\n",
              "of about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> neurons, and each neuron has about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> neurons. The human brain has about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.5</span> billion neurons, and \n",
              "each neuron has about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> neurons.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that can be used to simulate the physical environment. The default is a single-dimensional \n",
              "model, but you can create a number of different models to simulate different types of objects.\n",
              "\n",
              "In the following example, we will create a new model that will be used to simulate the physical environment.\n",
              "\n",
              "\u001b[35m/\u001b[0m\u001b[35m/\u001b[0m Create a new model using the new-model-name model.new-model-name = new\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that can be used to simulate the physical environment. The default is a single-dimensional \n",
              "model, but you can create a number of different models to simulate different types of objects.\n",
              "\n",
              "In the following example, we will create a new model that will be used to simulate the physical environment.\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">//</span> Create a new model using the new-model-name model.new-model-name = new\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TOP-P = \u001b[1;36m0.9\u001b[0m \u001b[1m(\u001b[0m\u001b[33mtemperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.7\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TOP-P = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "------------------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are based on the geometry of the target object. In this case, the model is a function \n",
              "that transforms an object into a singleton.\n",
              "\n",
              "The transformers in this class are called transformers for each element in the target object. In other words, they \n",
              "are transformers for each element in the target object.\n",
              "\n",
              "For example, the following example transforms an object by default.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are based on the geometry of the target object. In this case, the model is a function \n",
              "that transforms an object into a singleton.\n",
              "\n",
              "The transformers in this class are called transformers for each element in the target object. In other words, they \n",
              "are transformers for each element in the target object.\n",
              "\n",
              "For example, the following example transforms an object by default.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mAmostra \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Amostra <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformers are models that are the same as those in the movie, but in a different way.\n",
              "\n",
              "So in the movie, the main character is a robot called the \u001b[32m\"Fighter,\"\u001b[0m which is a sort of \u001b[32m\"fighter\"\u001b[0m robot that is \n",
              "used to fight against enemies and others. The robot is armed with an electrical gun and a laser that can kill you \n",
              "if it's hit. In the movie, this robot is\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transformers are models that are the same as those in the movie, but in a different way.\n",
              "\n",
              "So in the movie, the main character is a robot called the <span style=\"color: #008000; text-decoration-color: #008000\">\"Fighter,\"</span> which is a sort of <span style=\"color: #008000; text-decoration-color: #008000\">\"fighter\"</span> robot that is \n",
              "used to fight against enemies and others. The robot is armed with an electrical gun and a laser that can kill you \n",
              "if it's hit. In the movie, this robot is\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "EXPLICAÇÃO — RESUMO\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">EXPLICAÇÃO — RESUMO\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "- top-p = \u001b[1;36m0.3\u001b[0m:\n",
              "  Considera apenas um conjunto bem pequeno de tokens muito prováveis.\n",
              "  Tendência a texto mais conservador e repetitivo.\n",
              "\n",
              "- top-p = \u001b[1;36m0.6\u001b[0m:\n",
              "  Abre espaço para variedade moderada, mantendo controle.\n",
              "\n",
              "- top-p = \u001b[1;36m0.9\u001b[0m:\n",
              "  Permite um conjunto maior de candidatos → mais diversidade,\n",
              "  mas pode aumentar o risco de \u001b[32m\"deriva\"\u001b[0m \u001b[1m(\u001b[0msair do trilho\u001b[1m)\u001b[0m.\n",
              "\n",
              "Conclusão:\n",
              "Top-p controla o tamanho efetivo do conjunto de candidatos:\n",
              "baixo = mais conservador; alto = mais exploratório.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "- top-p = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>:\n",
              "  Considera apenas um conjunto bem pequeno de tokens muito prováveis.\n",
              "  Tendência a texto mais conservador e repetitivo.\n",
              "\n",
              "- top-p = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>:\n",
              "  Abre espaço para variedade moderada, mantendo controle.\n",
              "\n",
              "- top-p = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>:\n",
              "  Permite um conjunto maior de candidatos → mais diversidade,\n",
              "  mas pode aumentar o risco de <span style=\"color: #008000; text-decoration-color: #008000\">\"deriva\"</span> <span style=\"font-weight: bold\">(</span>sair do trilho<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "Conclusão:\n",
              "Top-p controla o tamanho efetivo do conjunto de candidatos:\n",
              "baixo = mais conservador; alto = mais exploratório.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# \"Passo a passo\" (estilo) vs resposta direta\n",
        "# ============================================================\n",
        "# Objetivo pedagógico:\n",
        "# - Mostrar que o prompt muda o ESTILO da resposta (mais curta vs mais explicada)\n",
        "# - Reforçar que \"explicar em passos\" não garante correção (especialmente em modelos pequenos)\n",
        "# - Criar um gancho para a ideia: fluência ≠ acerto\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROMPT DIRETO VS 'EXPLIQUE EM PASSOS'\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Exemplo simples (aritmética curta)\n",
        "prompt_direct = \"What is 27 + 58?\"\n",
        "prompt_steps  = \"Solve step by step: 27 + 58.\"\n",
        "\n",
        "# Mantemos decoding igual para a comparação ser justa\n",
        "TEMP = 0.7\n",
        "TOP_P = 0.9\n",
        "\n",
        "out_direct = generate_text(prompt_direct, temperature=TEMP, top_p=TOP_P, max_new_tokens=40, do_sample=True)\n",
        "out_steps  = generate_text(prompt_steps,  temperature=TEMP, top_p=TOP_P, max_new_tokens=80, do_sample=True)\n",
        "\n",
        "print(\"\\n=== PROMPT DIRETO ===\")\n",
        "print(out_direct)\n",
        "\n",
        "print(\"\\n=== 'EXPLIQUE EM PASSOS' ===\")\n",
        "print(out_steps)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPLICAÇÃO — RESUMO\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "- O modelo pode ser fluente e ainda assim errar aritmética simples.\n",
        "- Pedir \"em passos\" geralmente induz uma resposta mais estruturada/explicativa,\n",
        "  mas isso é um efeito de FORMATAÇÃO do texto, não uma garantia de raciocínio correto.\n",
        "- Se o objetivo é acerto, uma boa prática é pedir também uma verificação\n",
        "  (ou comparar múltiplas amostras — self-consistency).\n",
        "\"\"\")\n",
        "\n",
        "# (Opcional) verificação rápida fora do modelo (gancho didático)\n",
        "print(\"\\n[Checagem] 27 + 58 = 85\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CtSsp0PlY0wL",
        "outputId": "44b2e139-76ac-4b55-c07a-5d8c2be089d1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "PROMPT DIRETO VS \u001b[32m'EXPLIQUE EM PASSOS'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">PROMPT DIRETO VS <span style=\"color: #008000; text-decoration-color: #008000\">'EXPLIQUE EM PASSOS'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "=== PROMPT DIRETO ===\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "=== PROMPT DIRETO ===\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "What is \u001b[1;36m27\u001b[0m + \u001b[1;36m58\u001b[0m?\n",
              "\n",
              "So we have \u001b[1;36m28\u001b[0m plus \u001b[1;36m58\u001b[0m. We have \u001b[1;36m27\u001b[0m plus \u001b[1;36m58\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m \n",
              "plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m plus \u001b[1;36m28\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>?\n",
              "\n",
              "So we have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>. We have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> \n",
              "plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> plus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "=== \u001b[32m'EXPLIQUE EM PASSOS'\u001b[0m ===\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "=== <span style=\"color: #008000; text-decoration-color: #008000\">'EXPLIQUE EM PASSOS'</span> ===\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Solve step by step: \u001b[1;36m27\u001b[0m + \u001b[1;36m58.9\u001b[0m + \u001b[1;36m1.7\u001b[0m + \u001b[1;36m5.4\u001b[0m + \u001b[1;36m2.2\u001b[0m + \u001b[1;36m1.4\u001b[0m\n",
              "\n",
              "How to find the best game\n",
              "\n",
              "The top \u001b[1;36m4\u001b[0m games of the season are available on the official website.\n",
              "\n",
              "\u001b[1;36m1\u001b[0m. League of Legends\n",
              "\n",
              "\u001b[1;36m2\u001b[0m. Dota \u001b[1;36m2\u001b[0m\n",
              "\n",
              "\u001b[1;36m3\u001b[0m. League of Legends\n",
              "\n",
              "\u001b[1;36m4\u001b[0m. Super Smash Bros.\n",
              "\n",
              "\u001b[1;36m5\u001b[0m. Super Smash Bros. Melee\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Solve step by step: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.9</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.4</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4</span>\n",
              "\n",
              "How to find the best game\n",
              "\n",
              "The top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> games of the season are available on the official website.\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. League of Legends\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Dota <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. League of Legends\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Super Smash Bros.\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. Super Smash Bros. Melee\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "EXPLICAÇÃO — RESUMO\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">EXPLICAÇÃO — RESUMO\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "- O modelo pode ser fluente e ainda assim errar aritmética simples.\n",
              "- Pedir \u001b[32m\"em passos\"\u001b[0m geralmente induz uma resposta mais estruturada/explicativa,\n",
              "  mas isso é um efeito de FORMATAÇÃO do texto, não uma garantia de raciocínio correto.\n",
              "- Se o objetivo é acerto, uma boa prática é pedir também uma verificação\n",
              "  \u001b[1m(\u001b[0mou comparar múltiplas amostras — self-consistency\u001b[1m)\u001b[0m.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "- O modelo pode ser fluente e ainda assim errar aritmética simples.\n",
              "- Pedir <span style=\"color: #008000; text-decoration-color: #008000\">\"em passos\"</span> geralmente induz uma resposta mais estruturada/explicativa,\n",
              "  mas isso é um efeito de FORMATAÇÃO do texto, não uma garantia de raciocínio correto.\n",
              "- Se o objetivo é acerto, uma boa prática é pedir também uma verificação\n",
              "  <span style=\"font-weight: bold\">(</span>ou comparar múltiplas amostras — self-consistency<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mChecagem\u001b[1m]\u001b[0m \u001b[1;36m27\u001b[0m + \u001b[1;36m58\u001b[0m = \u001b[1;36m85\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Checagem<span style=\"font-weight: bold\">]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DIAGNÓSTICO DE PARÂMETROS (regras de bolso)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PARTE D — DIAGNÓSTICO: como ajustar quando a saída 'fica ruim'\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "CENÁRIO 1 — Texto repetitivo / preso em loops\n",
        "-------------------------------------------\n",
        "Sintoma: o modelo repete frases, padrões ou fica \"travado\" num formato.\n",
        "\n",
        "Ajuste prioritário:\n",
        "✅ Aumentar TOP-P (ex.: 0.6 -> 0.9)\n",
        "\n",
        "Por quê?\n",
        "- O conjunto de candidatos está pequeno demais.\n",
        "- top-p expande o \"pool\" de tokens possíveis mantendo corte por probabilidade acumulada.\n",
        "- Depois, se ainda estiver muito rígido, aumente um pouco a temperatura.\n",
        "\n",
        "Sugestão prática:\n",
        "- top_p: 0.8–0.95\n",
        "- temperature: 0.7–1.0 (ajuste fino depois)\n",
        "\n",
        "------------------------------------------------------------\n",
        "\n",
        "CENÁRIO 2 — Texto incoerente / \"viajando\"\n",
        "----------------------------------------\n",
        "Sintoma: perde o tema, inventa coisas, fica confuso.\n",
        "\n",
        "Ajuste prioritário:\n",
        "✅ Reduzir TEMPERATURE (ex.: 1.0 -> 0.7)\n",
        "✅ E/ou reduzir TOP-P (ex.: 0.95 -> 0.8)\n",
        "\n",
        "Por quê?\n",
        "- Você está explorando candidatos demais (muita aleatoriedade).\n",
        "- Isso aumenta diversidade, mas também o risco de deriva.\n",
        "\n",
        "------------------------------------------------------------\n",
        "\n",
        "CENÁRIO 3 — Quero estabilidade/reprodutibilidade\n",
        "-----------------------------------------------\n",
        "✅ do_sample = False (greedy)   OU\n",
        "✅ manter do_sample=True mas fixar seed (torch.manual_seed)\n",
        "\n",
        "Resumo:\n",
        "- TOP-P controla \"quantos candidatos entram no sorteio\"\n",
        "- TEMPERATURE controla \"quão aleatório é o sorteio\"\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UYaYXxJqY2Iq",
        "outputId": "7f62f706-dbbe-4305-b49d-3b8d882c4c4b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "PARTE D — DIAGNÓSTICO: como ajustar quando a saída \u001b[32m'fica ruim'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">PARTE D — DIAGNÓSTICO: como ajustar quando a saída <span style=\"color: #008000; text-decoration-color: #008000\">'fica ruim'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "CENÁRIO \u001b[1;36m1\u001b[0m — Texto repetitivo \u001b[35m/\u001b[0m preso em loops\n",
              "-------------------------------------------\n",
              "Sintoma: o modelo repete frases, padrões ou fica \u001b[32m\"travado\"\u001b[0m num formato.\n",
              "\n",
              "Ajuste prioritário:\n",
              "✅ Aumentar TOP-P \u001b[1m(\u001b[0mex.: \u001b[1;36m0.6\u001b[0m -> \u001b[1;36m0.9\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "Por quê?\n",
              "- O conjunto de candidatos está pequeno demais.\n",
              "- top-p expande o \u001b[32m\"pool\"\u001b[0m de tokens possíveis mantendo corte por probabilidade acumulada.\n",
              "- Depois, se ainda estiver muito rígido, aumente um pouco a temperatura.\n",
              "\n",
              "Sugestão prática:\n",
              "- top_p: \u001b[1;36m0.8\u001b[0m–\u001b[1;36m0.95\u001b[0m\n",
              "- temperature: \u001b[1;36m0.7\u001b[0m–\u001b[1;36m1.0\u001b[0m \u001b[1m(\u001b[0majuste fino depois\u001b[1m)\u001b[0m\n",
              "\n",
              "------------------------------------------------------------\n",
              "\n",
              "CENÁRIO \u001b[1;36m2\u001b[0m — Texto incoerente \u001b[35m/\u001b[0m \u001b[32m\"viajando\"\u001b[0m\n",
              "----------------------------------------\n",
              "Sintoma: perde o tema, inventa coisas, fica confuso.\n",
              "\n",
              "Ajuste prioritário:\n",
              "✅ Reduzir TEMPERATURE \u001b[1m(\u001b[0mex.: \u001b[1;36m1.0\u001b[0m -> \u001b[1;36m0.7\u001b[0m\u001b[1m)\u001b[0m\n",
              "✅ E/ou reduzir TOP-P \u001b[1m(\u001b[0mex.: \u001b[1;36m0.95\u001b[0m -> \u001b[1;36m0.8\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "Por quê?\n",
              "- Você está explorando candidatos demais \u001b[1m(\u001b[0mmuita aleatoriedade\u001b[1m)\u001b[0m.\n",
              "- Isso aumenta diversidade, mas também o risco de deriva.\n",
              "\n",
              "------------------------------------------------------------\n",
              "\n",
              "CENÁRIO \u001b[1;36m3\u001b[0m — Quero estabilidade/reprodutibilidade\n",
              "-----------------------------------------------\n",
              "✅ do_sample = \u001b[3;91mFalse\u001b[0m \u001b[1m(\u001b[0mgreedy\u001b[1m)\u001b[0m   OU\n",
              "✅ manter \u001b[33mdo_sample\u001b[0m=\u001b[3;92mTrue\u001b[0m mas fixar seed \u001b[1m(\u001b[0mtorch.manual_seed\u001b[1m)\u001b[0m\n",
              "\n",
              "Resumo:\n",
              "- TOP-P controla \u001b[32m\"quantos candidatos entram no sorteio\"\u001b[0m\n",
              "- TEMPERATURE controla \u001b[32m\"quão aleatório é o sorteio\"\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "CENÁRIO <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> — Texto repetitivo <span style=\"color: #800080; text-decoration-color: #800080\">/</span> preso em loops\n",
              "-------------------------------------------\n",
              "Sintoma: o modelo repete frases, padrões ou fica <span style=\"color: #008000; text-decoration-color: #008000\">\"travado\"</span> num formato.\n",
              "\n",
              "Ajuste prioritário:\n",
              "✅ Aumentar TOP-P <span style=\"font-weight: bold\">(</span>ex.: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span> -&gt; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "Por quê?\n",
              "- O conjunto de candidatos está pequeno demais.\n",
              "- top-p expande o <span style=\"color: #008000; text-decoration-color: #008000\">\"pool\"</span> de tokens possíveis mantendo corte por probabilidade acumulada.\n",
              "- Depois, se ainda estiver muito rígido, aumente um pouco a temperatura.\n",
              "\n",
              "Sugestão prática:\n",
              "- top_p: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>\n",
              "- temperature: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>–<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span> <span style=\"font-weight: bold\">(</span>ajuste fino depois<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "------------------------------------------------------------\n",
              "\n",
              "CENÁRIO <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> — Texto incoerente <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"viajando\"</span>\n",
              "----------------------------------------\n",
              "Sintoma: perde o tema, inventa coisas, fica confuso.\n",
              "\n",
              "Ajuste prioritário:\n",
              "✅ Reduzir TEMPERATURE <span style=\"font-weight: bold\">(</span>ex.: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span> -&gt; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">)</span>\n",
              "✅ E/ou reduzir TOP-P <span style=\"font-weight: bold\">(</span>ex.: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span> -&gt; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "Por quê?\n",
              "- Você está explorando candidatos demais <span style=\"font-weight: bold\">(</span>muita aleatoriedade<span style=\"font-weight: bold\">)</span>.\n",
              "- Isso aumenta diversidade, mas também o risco de deriva.\n",
              "\n",
              "------------------------------------------------------------\n",
              "\n",
              "CENÁRIO <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> — Quero estabilidade/reprodutibilidade\n",
              "-----------------------------------------------\n",
              "✅ do_sample = <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> <span style=\"font-weight: bold\">(</span>greedy<span style=\"font-weight: bold\">)</span>   OU\n",
              "✅ manter <span style=\"color: #808000; text-decoration-color: #808000\">do_sample</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> mas fixar seed <span style=\"font-weight: bold\">(</span>torch.manual_seed<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "Resumo:\n",
              "- TOP-P controla <span style=\"color: #008000; text-decoration-color: #008000\">\"quantos candidatos entram no sorteio\"</span>\n",
              "- TEMPERATURE controla <span style=\"color: #008000; text-decoration-color: #008000\">\"quão aleatório é o sorteio\"</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# KV CACHE (custo computacional)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KV CACHE (tempo de geração)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Ideia:\n",
        "# - KV cache NÃO é treinamento e NÃO melhora \"qualidade\" do texto.\n",
        "# - Ele só economiza computação: reaproveita K e V do prefixo a cada novo token.\n",
        "#\n",
        "# Observação importante:\n",
        "# - Com do_sample=True, o texto pode variar entre execuções.\n",
        "# - Aqui o objetivo é comparar TEMPO (não comparar igualdade do texto).\n",
        "\n",
        "prompt_kv = \"Large language models rely on attention mechanisms\"\n",
        "\n",
        "def timed(use_cache: bool, n_runs: int = 3) -> float:\n",
        "    \"\"\"Tempo médio (segundos) de n_runs gerações com ou sem KV cache.\"\"\"\n",
        "    # Warm-up (primeira chamada pode ser mais lenta)\n",
        "    _ = generate_text(prompt_kv, temperature=0.7, top_p=0.9, max_new_tokens=120, use_cache=use_cache)\n",
        "\n",
        "    times = []\n",
        "    for _ in range(n_runs):\n",
        "        start = time.time()\n",
        "        _ = generate_text(\n",
        "            prompt_kv,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            max_new_tokens=120,\n",
        "            use_cache=use_cache\n",
        "        )\n",
        "        times.append(time.time() - start)\n",
        "\n",
        "    return sum(times) / len(times)\n",
        "\n",
        "t_cache   = timed(True,  n_runs=3)\n",
        "t_no_cache= timed(False, n_runs=3)\n",
        "\n",
        "print(f\"\\nTempo médio com cache : {t_cache:.4f} s\")\n",
        "print(f\"Tempo médio sem cache : {t_no_cache:.4f} s\")\n",
        "print(f\"Speedup (sem/ com)    : {t_no_cache / t_cache:.2f}×\")\n",
        "\n",
        "print(\"\"\"\n",
        "LEITURA:\n",
        "- KV cache NÃO altera o objetivo do modelo nem \"melhora\" o conteúdo do texto.\n",
        "- Ele reduz custo computacional ao evitar recomputar atenção para todo o prefixo a cada token.\n",
        "- Neste demo, a diferença pode ser pequena (GPT-2 é pequeno e o prompt é curto).\n",
        "- Em modelos grandes e/ou prompts longos, o ganho tende a ser muito mais visível.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uGTLB9IiY3fI",
        "outputId": "22eec124-eef4-4a03-dec5-01b967dc5c7d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "KV CACHE \u001b[1m(\u001b[0mtempo de geração\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">KV CACHE <span style=\"font-weight: bold\">(</span>tempo de geração<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Tempo médio com cache : \u001b[1;36m2.5722\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Tempo médio com cache : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.5722</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tempo médio sem cache : \u001b[1;36m1.1159\u001b[0m s\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tempo médio sem cache : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1159</span> s\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Speedup \u001b[1m(\u001b[0msem/ com\u001b[1m)\u001b[0m    : \u001b[1;36m0.43\u001b[0m×\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Speedup <span style=\"font-weight: bold\">(</span>sem/ com<span style=\"font-weight: bold\">)</span>    : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.43</span>×\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "LEITURA:\n",
              "- KV cache NÃO altera o objetivo do modelo nem \u001b[32m\"melhora\"\u001b[0m o conteúdo do texto.\n",
              "- Ele reduz custo computacional ao evitar recomputar atenção para todo o prefixo a cada token.\n",
              "- Neste demo, a diferença pode ser pequena \u001b[1m(\u001b[0mGPT-\u001b[1;36m2\u001b[0m é pequeno e o prompt é curto\u001b[1m)\u001b[0m.\n",
              "- Em modelos grandes e/ou prompts longos, o ganho tende a ser muito mais visível.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "LEITURA:\n",
              "- KV cache NÃO altera o objetivo do modelo nem <span style=\"color: #008000; text-decoration-color: #008000\">\"melhora\"</span> o conteúdo do texto.\n",
              "- Ele reduz custo computacional ao evitar recomputar atenção para todo o prefixo a cada token.\n",
              "- Neste demo, a diferença pode ser pequena <span style=\"font-weight: bold\">(</span>GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> é pequeno e o prompt é curto<span style=\"font-weight: bold\">)</span>.\n",
              "- Em modelos grandes e/ou prompts longos, o ganho tende a ser muito mais visível.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FECHAMENTO — Checklist do aluno (Prática 1)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CHECKLIST FINAL DO ALUNO — Inferência Interativa\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "✅ 1) Temperatura (τ) controla \"quão aleatória\" é a escolha do próximo token\n",
        "   - τ baixo  -> mais determinístico / conservador\n",
        "   - τ alto   -> mais diverso / mais risco de deriva\n",
        "\n",
        "✅ 2) Top-p (nucleus) controla \"quantos candidatos\" entram no sorteio\n",
        "   - top-p baixo -> conjunto pequeno -> mais repetição\n",
        "   - top-p alto  -> conjunto maior   -> mais variedade\n",
        "\n",
        "✅ 3) Prompting muda o CONTEXTO (instrução/estilo), não os PESOS do modelo\n",
        "   - é inferência, não treinamento\n",
        "\n",
        "✅ 4) Chain-of-Thought (CoT) via prompt (\"step by step\") muda o ESTILO da resposta\n",
        "   - pode ajudar a estruturar, mas não garante correção\n",
        "\n",
        "✅ 5) KV cache muda LATÊNCIA (tempo/custo), não \"qualidade\" ou semântica do texto\n",
        "   - acelera reaproveitando K/V do prefixo na geração\n",
        "\n",
        "FIM DO NOTEBOOK-GABARITO.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PU2j-KVKGNAI",
        "outputId": "d8f3ad71-72fa-47b0-c9ad-44b8c1cb0012"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CHECKLIST FINAL DO ALUNO — Inferência Interativa\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CHECKLIST FINAL DO ALUNO — Inferência Interativa\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "✅ \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m Temperatura \u001b[1m(\u001b[0mτ\u001b[1m)\u001b[0m controla \u001b[32m\"quão aleatória\"\u001b[0m é a escolha do próximo token\n",
              "   - τ baixo  -> mais determinístico \u001b[35m/\u001b[0m conservador\n",
              "   - τ alto   -> mais diverso \u001b[35m/\u001b[0m mais risco de deriva\n",
              "\n",
              "✅ \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m Top-p \u001b[1m(\u001b[0mnucleus\u001b[1m)\u001b[0m controla \u001b[32m\"quantos candidatos\"\u001b[0m entram no sorteio\n",
              "   - top-p baixo -> conjunto pequeno -> mais repetição\n",
              "   - top-p alto  -> conjunto maior   -> mais variedade\n",
              "\n",
              "✅ \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m Prompting muda o CONTEXTO \u001b[1m(\u001b[0minstrução/estilo\u001b[1m)\u001b[0m, não os PESOS do modelo\n",
              "   - é inferência, não treinamento\n",
              "\n",
              "✅ \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m Chain-of-Thought \u001b[1m(\u001b[0mCoT\u001b[1m)\u001b[0m via prompt \u001b[1m(\u001b[0m\u001b[32m\"step by step\"\u001b[0m\u001b[1m)\u001b[0m muda o ESTILO da resposta\n",
              "   - pode ajudar a estruturar, mas não garante correção\n",
              "\n",
              "✅ \u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m KV cache muda LATÊNCIA \u001b[1m(\u001b[0mtempo/custo\u001b[1m)\u001b[0m, não \u001b[32m\"qualidade\"\u001b[0m ou semântica do texto\n",
              "   - acelera reaproveitando K/V do prefixo na geração\n",
              "\n",
              "FIM DO NOTEBOOK-GABARITO.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> Temperatura <span style=\"font-weight: bold\">(</span>τ<span style=\"font-weight: bold\">)</span> controla <span style=\"color: #008000; text-decoration-color: #008000\">\"quão aleatória\"</span> é a escolha do próximo token\n",
              "   - τ baixo  -&gt; mais determinístico <span style=\"color: #800080; text-decoration-color: #800080\">/</span> conservador\n",
              "   - τ alto   -&gt; mais diverso <span style=\"color: #800080; text-decoration-color: #800080\">/</span> mais risco de deriva\n",
              "\n",
              "✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> Top-p <span style=\"font-weight: bold\">(</span>nucleus<span style=\"font-weight: bold\">)</span> controla <span style=\"color: #008000; text-decoration-color: #008000\">\"quantos candidatos\"</span> entram no sorteio\n",
              "   - top-p baixo -&gt; conjunto pequeno -&gt; mais repetição\n",
              "   - top-p alto  -&gt; conjunto maior   -&gt; mais variedade\n",
              "\n",
              "✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span> Prompting muda o CONTEXTO <span style=\"font-weight: bold\">(</span>instrução/estilo<span style=\"font-weight: bold\">)</span>, não os PESOS do modelo\n",
              "   - é inferência, não treinamento\n",
              "\n",
              "✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span> Chain-of-Thought <span style=\"font-weight: bold\">(</span>CoT<span style=\"font-weight: bold\">)</span> via prompt <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"step by step\"</span><span style=\"font-weight: bold\">)</span> muda o ESTILO da resposta\n",
              "   - pode ajudar a estruturar, mas não garante correção\n",
              "\n",
              "✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span> KV cache muda LATÊNCIA <span style=\"font-weight: bold\">(</span>tempo/custo<span style=\"font-weight: bold\">)</span>, não <span style=\"color: #008000; text-decoration-color: #008000\">\"qualidade\"</span> ou semântica do texto\n",
              "   - acelera reaproveitando K/V do prefixo na geração\n",
              "\n",
              "FIM DO NOTEBOOK-GABARITO.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prompt engineering e in-context learning: few-shot, self-consistency e limites de contexto.\n"
      ],
      "metadata": {
        "id": "PiMeb-Uq1K5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SETUP — Prompt Engineering & In-Context Learning (few-shot, etc.)\n",
        "# Modelo: FLAN-T5 (seq2seq instruído, leve e rápido)\n",
        "# ============================================================\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# 1) Define o device primeiro (GPU se disponível)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"[INFO] Device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"[INFO] GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# 2) Escolha do modelo\n",
        "# FLAN-T5 é um T5 ajustado para seguir instruções (instruction-tuned).\n",
        "# Ele é do tipo SEQ2SEQ (encoder-decoder): recebe um texto de entrada e gera um texto de saída.\n",
        "t5_name = \"google/flan-t5-small\"\n",
        "\n",
        "# 3) Tokenizer e modelo\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(t5_name)\n",
        "t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
        "\n",
        "# 4) Modo avaliação (inferência): desativa dropout e estabiliza resultados\n",
        "t5_model.eval()\n",
        "\n",
        "print(f\"[OK] Modelo instruído carregado: {t5_name}\")\n",
        "print(f\"[INFO] Device do modelo: {next(t5_model.parameters()).device}\")\n",
        "\n",
        "# Nota para as próximas células:\n",
        "# Use \"with torch.inference_mode():\" ao gerar texto para deixar claro que NÃO há treinamento."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "a78c95740b3b4748af0d3222f0ae8426",
            "8a64fad1932449af8ac9f98f93c29f04",
            "14151fc65dbe489e890209cfe436ce3e",
            "3fd52fef23444611ad1af480b56f9122",
            "0d905703730b49e0b60f42788d48cc73",
            "b6560e1ff0e24bc9b068a0518b335417",
            "a1d50dbe755e42fcab2c78af99c122df",
            "1e4d08e087d84eb99fd1d9f5d475fdb4",
            "3e66814d95aa45eba8a28584b0fc6f8d",
            "2988cfeec56140f19f237d665ff38029",
            "2997d8373bc74f1ead3ecedb3484eacc"
          ]
        },
        "id": "ABHzPaDG1LOm",
        "outputId": "fefb5c31-3158-427c-e18f-82cd6a38e2e2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Device: cuda\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Device: cuda\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m GPU: Tesla T4\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> GPU: Tesla T4\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/190 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a78c95740b3b4748af0d3222f0ae8426"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m Modelo instruído carregado: google/flan-t5-small\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> Modelo instruído carregado: google/flan-t5-small\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Device do modelo: cu\u001b[1;92mda:0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Device do modelo: cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FUNÇÃO DE GERAÇÃO PARA O MODELO INSTRUÍDO (FLAN-T5)\n",
        "# ============================================================\n",
        "# Observação:\n",
        "# - Em modelos Seq2Seq (T5), a geração ainda é token-a-token, mas a arquitetura é encoder-decoder.\n",
        "# - temperature/top_p só têm efeito real quando do_sample=True.\n",
        "# - Para determinismo, prefira do_sample=False e (opcionalmente) num_beams>=1.\n",
        "def generate_t5(\n",
        "    prompt: str,\n",
        "    max_new_tokens: int = 64,\n",
        "    do_sample: bool = True,\n",
        "    temperature: float = 0.7,\n",
        "    top_p: float = 0.9,\n",
        "    num_beams: int = 1,\n",
        "    num_return_sequences: int = 1,\n",
        "):\n",
        "    # 1) Tokeniza e manda para o mesmo device do modelo\n",
        "    inputs = t5_tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True\n",
        "    ).to(device)\n",
        "\n",
        "    # 2) Inferência (sem gradientes)\n",
        "    with torch.inference_mode():\n",
        "        out_ids = t5_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "\n",
        "            # Decoding / sampling:\n",
        "            do_sample=do_sample,\n",
        "            temperature=temperature if do_sample else None,\n",
        "            top_p=top_p if do_sample else None,\n",
        "\n",
        "            # Decoding determinístico (quando do_sample=False, beam search pode ser usado)\n",
        "            num_beams=num_beams,\n",
        "\n",
        "            # Para retornar múltiplas gerações\n",
        "            num_return_sequences=num_return_sequences,\n",
        "        )\n",
        "\n",
        "    # 3) Decodifica ids -> texto\n",
        "    texts = [t5_tokenizer.decode(x, skip_special_tokens=True) for x in out_ids]\n",
        "\n",
        "    return texts if num_return_sequences > 1 else texts[0]"
      ],
      "metadata": {
        "id": "cdHy_AUV2N8B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FEW-SHOT / IN-CONTEXT LEARNING (ICL)\n",
        "# ============================================================\n",
        "# Objetivo didático:\n",
        "# - Mostrar que exemplos NO PROMPT (few-shot) mudam o comportamento\n",
        "# - Reforçar que ICL NÃO muda pesos: é condicionamento pelo contexto\n",
        "# - Mostrar que template/formato é quase tudo\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FEW-SHOT / IN-CONTEXT LEARNING (ICL)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nO que observar:\")\n",
        "print(\"- A resposta segue o rótulo pedido? (POSITIVO/NEGATIVO)\")\n",
        "print(\"- A resposta fica mais estável quando damos exemplos?\")\n",
        "print(\"- O template (Texto -> Sentimento) é seguido?\\n\")\n",
        "\n",
        "task = \"Classifique o sentimento como POSITIVO ou NEGATIVO.\"\n",
        "\n",
        "# ZERO-SHOT: sem demonstrações, só instrução + um exemplo-alvo\n",
        "zero_shot = f\"\"\"{task}\n",
        "\n",
        "Texto: \"Este filme foi um desperdício de tempo.\"\n",
        "Sentimento:\"\"\"\n",
        "\n",
        "# FEW-SHOT: damos demonstrações do formato que queremos (Texto -> Rótulo)\n",
        "few_shot = f\"\"\"{task}\n",
        "\n",
        "Texto: \"Adorei, foi excelente e emocionante.\"\n",
        "Sentimento: POSITIVO\n",
        "\n",
        "Texto: \"Péssimo. Não recomendo para ninguém.\"\n",
        "Sentimento: NEGATIVO\n",
        "\n",
        "Texto: \"Este filme foi um desperdício de tempo.\"\n",
        "Sentimento:\"\"\"\n",
        "\n",
        "print(\"\\n--- ZERO-SHOT (sem exemplos) ---\")\n",
        "print(generate_t5(\n",
        "    zero_shot,\n",
        "    do_sample=False,   # determinístico\n",
        "    num_beams=1,\n",
        "    max_new_tokens=8\n",
        "))\n",
        "\n",
        "print(\"\\n--- FEW-SHOT (com exemplos) ---\")\n",
        "print(generate_t5(\n",
        "    few_shot,\n",
        "    do_sample=False,   # determinístico\n",
        "    num_beams=1,\n",
        "    max_new_tokens=8\n",
        "))\n",
        "\n",
        "print(\"\"\"\n",
        "EXPLICAÇÃO — RESUMO\n",
        "\n",
        "- Zero-shot:\n",
        "  Pode acertar, mas costuma ser mais sensível ao wording e ao formato.\n",
        "\n",
        "- Few-shot:\n",
        "  O modelo \"pega o jeito\" pelo contexto:\n",
        "  ele observa o padrão (Texto -> Sentimento) e imita esse padrão no novo caso.\n",
        "\n",
        "PONTO-CHAVE:\n",
        "In-context learning (ICL) não atualiza pesos.\n",
        "O que \"ensina\" é o template + exemplos (demonstrações) no prompt.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "9WijkEC1dHjY",
        "outputId": "535b1a0e-6344-4cbe-f372-ed386ba4b347"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FEW-SHOT \u001b[35m/\u001b[0m IN-CONTEXT LEARNING \u001b[1m(\u001b[0mICL\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FEW-SHOT <span style=\"color: #800080; text-decoration-color: #800080\">/</span> IN-CONTEXT LEARNING <span style=\"font-weight: bold\">(</span>ICL<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "O que observar:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "O que observar:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- A resposta segue o rótulo pedido? \u001b[1m(\u001b[0mPOSITIVO/NEGATIVO\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- A resposta segue o rótulo pedido? <span style=\"font-weight: bold\">(</span>POSITIVO/NEGATIVO<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- A resposta fica mais estável quando damos exemplos?\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- A resposta fica mais estável quando damos exemplos?\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "- O template \u001b[1m(\u001b[0mTexto -> Sentimento\u001b[1m)\u001b[0m é seguido?\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- O template <span style=\"font-weight: bold\">(</span>Texto -&gt; Sentimento<span style=\"font-weight: bold\">)</span> é seguido?\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- ZERO-SHOT \u001b[1m(\u001b[0msem exemplos\u001b[1m)\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- ZERO-SHOT <span style=\"font-weight: bold\">(</span>sem exemplos<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "POSITIVO\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">POSITIVO\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- FEW-SHOT \u001b[1m(\u001b[0mcom exemplos\u001b[1m)\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- FEW-SHOT <span style=\"font-weight: bold\">(</span>com exemplos<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "POSITIVO\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">POSITIVO\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "EXPLICAÇÃO — RESUMO\n",
              "\n",
              "- Zero-shot:\n",
              "  Pode acertar, mas costuma ser mais sensível ao wording e ao formato.\n",
              "\n",
              "- Few-shot:\n",
              "  O modelo \u001b[32m\"pega o jeito\"\u001b[0m pelo contexto:\n",
              "  ele observa o padrão \u001b[1m(\u001b[0mTexto -> Sentimento\u001b[1m)\u001b[0m e imita esse padrão no novo caso.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "In-context learning \u001b[1m(\u001b[0mICL\u001b[1m)\u001b[0m não atualiza pesos.\n",
              "O que \u001b[32m\"ensina\"\u001b[0m é o template + exemplos \u001b[1m(\u001b[0mdemonstrações\u001b[1m)\u001b[0m no prompt.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "EXPLICAÇÃO — RESUMO\n",
              "\n",
              "- Zero-shot:\n",
              "  Pode acertar, mas costuma ser mais sensível ao wording e ao formato.\n",
              "\n",
              "- Few-shot:\n",
              "  O modelo <span style=\"color: #008000; text-decoration-color: #008000\">\"pega o jeito\"</span> pelo contexto:\n",
              "  ele observa o padrão <span style=\"font-weight: bold\">(</span>Texto -&gt; Sentimento<span style=\"font-weight: bold\">)</span> e imita esse padrão no novo caso.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "In-context learning <span style=\"font-weight: bold\">(</span>ICL<span style=\"font-weight: bold\">)</span> não atualiza pesos.\n",
              "O que <span style=\"color: #008000; text-decoration-color: #008000\">\"ensina\"</span> é o template + exemplos <span style=\"font-weight: bold\">(</span>demonstrações<span style=\"font-weight: bold\">)</span> no prompt.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# \"O TEMPLATE É O MODELO\"\n",
        "# mesma tarefa, template ruim vs template bom\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEMPLATE RUIM vs TEMPLATE BOM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Ideia:\n",
        "# - Mesmo \"problema\", comportamentos diferentes só por mudar o FORMATO do prompt.\n",
        "# - Template bom define claramente:\n",
        "#   (a) o que entra (Texto:)\n",
        "#   (b) o que sai (apenas um rótulo)\n",
        "#   (c) onde o modelo deve colocar a resposta (Sentimento:)\n",
        "\n",
        "template_ruim = f\"\"\"{task}\n",
        "\"Este filme foi um desperdício de tempo.\" ->\"\"\"\n",
        "\n",
        "template_bom = f\"\"\"{task}\n",
        "\n",
        "Responda com UMA ÚNICA palavra: POSITIVO ou NEGATIVO.\n",
        "Não explique. Não escreva mais nada.\n",
        "\n",
        "Texto: \"Este filme foi um desperdício de tempo.\"\n",
        "Sentimento:\"\"\"\n",
        "\n",
        "print(\"\\n--- TEMPLATE RUIM ---\")\n",
        "print(generate_t5(\n",
        "    template_ruim,\n",
        "    do_sample=False,   # determinístico (bom para demo ao vivo)\n",
        "    num_beams=1,\n",
        "    max_new_tokens=16\n",
        "))\n",
        "\n",
        "print(\"\\n--- TEMPLATE BOM ---\")\n",
        "print(generate_t5(\n",
        "    template_bom,\n",
        "    do_sample=False,   # determinístico\n",
        "    num_beams=1,\n",
        "    max_new_tokens=8\n",
        "))\n",
        "\n",
        "print(\"\"\"\n",
        "EXPLICAÇÃO — RESUMO\n",
        "\n",
        "- Template ruim:\n",
        "  O modelo pode responder de forma prolixa, ambígua, ou fora do formato esperado,\n",
        "  porque o \"espaço de saída\" não está bem definido.\n",
        "\n",
        "- Template bom:\n",
        "  Você restringe o espaço de resposta (output space) e reduz ambiguidade:\n",
        "  o modelo sabe exatamente o que deve produzir e em qual formato.\n",
        "\n",
        "PONTO-CHAVE:\n",
        "Prompt engineering = desenhar o TEMPLATE para controlar formato e espaço de resposta.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "crfQk8b12V39",
        "outputId": "1d2616e6-bb0c-4473-d876-1896f0dbd93c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TEMPLATE RUIM vs TEMPLATE BOM\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEMPLATE RUIM vs TEMPLATE BOM\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- TEMPLATE RUIM ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- TEMPLATE RUIM ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "POSITIVO or NEGATIVO. \"This film was \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">POSITIVO or NEGATIVO. \"This film was \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- TEMPLATE BOM ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- TEMPLATE BOM ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"This film was a desper\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"This film was a desper\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "EXPLICAÇÃO — RESUMO\n",
              "\n",
              "- Template ruim:\n",
              "  O modelo pode responder de forma prolixa, ambígua, ou fora do formato esperado,\n",
              "  porque o \u001b[32m\"espaço de saída\"\u001b[0m não está bem definido.\n",
              "\n",
              "- Template bom:\n",
              "  Você restringe o espaço de resposta \u001b[1m(\u001b[0moutput space\u001b[1m)\u001b[0m e reduz ambiguidade:\n",
              "  o modelo sabe exatamente o que deve produzir e em qual formato.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "Prompt engineering = desenhar o TEMPLATE para controlar formato e espaço de resposta.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "EXPLICAÇÃO — RESUMO\n",
              "\n",
              "- Template ruim:\n",
              "  O modelo pode responder de forma prolixa, ambígua, ou fora do formato esperado,\n",
              "  porque o <span style=\"color: #008000; text-decoration-color: #008000\">\"espaço de saída\"</span> não está bem definido.\n",
              "\n",
              "- Template bom:\n",
              "  Você restringe o espaço de resposta <span style=\"font-weight: bold\">(</span>output space<span style=\"font-weight: bold\">)</span> e reduz ambiguidade:\n",
              "  o modelo sabe exatamente o que deve produzir e em qual formato.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "Prompt engineering = desenhar o TEMPLATE para controlar formato e espaço de resposta.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SELF-CONSISTENCY (multi-amostragem + votação)\n",
        "# ============================================================\n",
        "# Objetivo didático:\n",
        "# - Mostrar que amostrar várias vezes e agregar pode melhorar robustez.\n",
        "# - Intuição: reduzir variância (ensemble) quando há ambiguidade.\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SELF-CONSISTENCY (MULTI-AMOSTRAGEM + VOTO)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def extract_label(text: str):\n",
        "    \"\"\"Extrai POSITIVO/NEGATIVO da saída, mesmo se vier com texto extra.\"\"\"\n",
        "    t = text.strip().upper()\n",
        "    m = re.search(r\"\\b(POSITIVO|NEGATIVO)\\b\", t)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "# Caso deliberadamente ambíguo (sinal misto):\n",
        "# \"ótimo atendimento\" (positivo) vs \"produto quebrou\" (negativo).\n",
        "prompt_sc = \"\"\"Classifique o sentimento como POSITIVO ou NEGATIVO.\n",
        "Responda APENAS com POSITIVO ou NEGATIVO.\n",
        "\n",
        "Texto: \"O atendimento foi ótimo, mas o produto quebrou no dia seguinte.\"\n",
        "Sentimento:\"\"\"\n",
        "\n",
        "# 1) Gera múltiplas amostras com sampling (variabilidade proposital)\n",
        "# Observação:\n",
        "# - do_sample=True ativa amostragem estocástica.\n",
        "# - temperature/top_p/top_k controlam diversidade.\n",
        "samples = generate_t5(\n",
        "    prompt_sc,\n",
        "    do_sample=True,\n",
        "    temperature=0.9,\n",
        "    top_p=0.9,\n",
        "    # top_k é opcional, mas ajuda a evitar tokens muito improváveis\n",
        "    # (se sua generate_t5 suportar top_k, vale passar; caso não, remova)\n",
        "    # top_k=50,\n",
        "    num_beams=1,\n",
        "    max_new_tokens=8,\n",
        "    num_return_sequences=15\n",
        ")\n",
        "\n",
        "# 2) Extrai rótulos e contabiliza\n",
        "labels = [extract_label(s) for s in samples]\n",
        "labels_clean = [l for l in labels if l is not None]\n",
        "\n",
        "print(\"\\nAmostras brutas:\")\n",
        "for i, s in enumerate(samples, 1):\n",
        "    print(f\"{i:02d}. {s}\")\n",
        "\n",
        "counts = Counter(labels_clean)\n",
        "print(\"\\nContagem de rótulos (apenas parseados):\", dict(counts))\n",
        "print(f\"Não-parseados (sem rótulo claro): {labels.count(None)} / {len(labels)}\")\n",
        "\n",
        "# 3) Votação simples (maioria)\n",
        "voted = counts.most_common(1)[0][0] if counts else \"INDETERMINADO\"\n",
        "print(\"\\nVOTO FINAL (self-consistency):\", voted)\n",
        "\n",
        "print(\"\"\"\n",
        "EXPLICAÇÃO — RESUMO\n",
        "\n",
        "- As amostras variam porque habilitamos amostragem (temperature/top-p).\n",
        "- Em casos ambíguos, diferentes \"continuações\" são plausíveis.\n",
        "- A votação tende a estabilizar a decisão (redução de variância via ensemble).\n",
        "\n",
        "PONTO-CHAVE:\n",
        "Self-consistency melhora ROBUSTEZ quando há múltiplos caminhos plausíveis.\n",
        "Mas não garante \"verdade\" — só aumenta consistência agregada.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "o5gojYlf2cdr",
        "outputId": "aa794010-8039-43d2-ffc7-19b6e35c4ebd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SELF-CONSISTENCY \u001b[1m(\u001b[0mMULTI-AMOSTRAGEM + VOTO\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SELF-CONSISTENCY <span style=\"font-weight: bold\">(</span>MULTI-AMOSTRAGEM + VOTO<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Amostras brutas:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Amostras brutas:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m01\u001b[0m. Adignantitiv or indicative for N\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>. Adignantitiv or indicative for N\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m02\u001b[0m. NegusionS posiivint\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>. NegusionS posiivint\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m03\u001b[0m. Acrea\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>. Acrea\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m04\u001b[0m. VESCA NELIVSU\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>. VESCA NELIVSU\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m05\u001b[0m. Classitativas postura\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>. Classitativas postura\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m06\u001b[0m. BOPAPSIS\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>. BOPAPSIS\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m07\u001b[0m. FRESA LSDAPIVER\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>. FRESA LSDAPIVER\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m08\u001b[0m. Respondà Un avisativan para ser\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>. Respondà Un avisativan para ser\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m09\u001b[0m. \"Prostitors should respond quickly though\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>. \"Prostitors should respond quickly though\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m10\u001b[0m. \"We may feel we cannot understand what\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>. \"We may feel we cannot understand what\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m11\u001b[0m. Negatorous on top effect \u001b[1m(\u001b[0msuch\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>. Negatorous on top effect <span style=\"font-weight: bold\">(</span>such\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m12\u001b[0m. Accliniconza está ca\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>. Accliniconza está ca\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m13\u001b[0m. \u001b[1m(\u001b[0msublement\u001b[1m)\u001b[0m. Hypose que\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>. <span style=\"font-weight: bold\">(</span>sublement<span style=\"font-weight: bold\">)</span>. Hypose que\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m14\u001b[0m. “Any action needed from our lor\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>. “Any action needed from our lor\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m15\u001b[0m. MAILY: PRONES \u001b[1m(\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>. MAILY: PRONES <span style=\"font-weight: bold\">(</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Contagem de rótulos \u001b[1m(\u001b[0mapenas parseados\u001b[1m)\u001b[0m:\n",
              "\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Contagem de rótulos <span style=\"font-weight: bold\">(</span>apenas parseados<span style=\"font-weight: bold\">)</span>:\n",
              "<span style=\"font-weight: bold\">{}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Não-parseados \u001b[1m(\u001b[0msem rótulo claro\u001b[1m)\u001b[0m: \u001b[1;36m15\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m15\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Não-parseados <span style=\"font-weight: bold\">(</span>sem rótulo claro<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "VOTO FINAL \u001b[1m(\u001b[0mself-consistency\u001b[1m)\u001b[0m: INDETERMINADO\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "VOTO FINAL <span style=\"font-weight: bold\">(</span>self-consistency<span style=\"font-weight: bold\">)</span>: INDETERMINADO\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "EXPLICAÇÃO — RESUMO\n",
              "\n",
              "- As amostras variam porque habilitamos amostragem \u001b[1m(\u001b[0mtemperature/top-p\u001b[1m)\u001b[0m.\n",
              "- Em casos ambíguos, diferentes \u001b[32m\"continuações\"\u001b[0m são plausíveis.\n",
              "- A votação tende a estabilizar a decisão \u001b[1m(\u001b[0mredução de variância via ensemble\u001b[1m)\u001b[0m.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "Self-consistency melhora ROBUSTEZ quando há múltiplos caminhos plausíveis.\n",
              "Mas não garante \u001b[32m\"verdade\"\u001b[0m — só aumenta consistência agregada.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "EXPLICAÇÃO — RESUMO\n",
              "\n",
              "- As amostras variam porque habilitamos amostragem <span style=\"font-weight: bold\">(</span>temperature/top-p<span style=\"font-weight: bold\">)</span>.\n",
              "- Em casos ambíguos, diferentes <span style=\"color: #008000; text-decoration-color: #008000\">\"continuações\"</span> são plausíveis.\n",
              "- A votação tende a estabilizar a decisão <span style=\"font-weight: bold\">(</span>redução de variância via ensemble<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "Self-consistency melhora ROBUSTEZ quando há múltiplos caminhos plausíveis.\n",
              "Mas não garante <span style=\"color: #008000; text-decoration-color: #008000\">\"verdade\"</span> — só aumenta consistência agregada.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SELF-CONSISTENCY EM RESPOSTA NUMÉRICA (com parsing + voto)\n",
        "# Exemplo: problema simples, mas a saída pode vir com \"ruído\" textual.\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SELF-CONSISTENCY EM RESPOSTA NUMÉRICA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def extract_int(text: str):\n",
        "    \"\"\"\n",
        "    Extrai o primeiro inteiro que aparecer na saída do modelo.\n",
        "    Ex.: \"The answer is 85.\" -> 85\n",
        "        \"85\"               -> 85\n",
        "        \"eighty five\"      -> None (não tem dígitos)\n",
        "    \"\"\"\n",
        "    m = re.search(r\"(-?\\d+)\", text.strip())\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "# Instrução forte para reduzir espaço de saída\n",
        "prompt_math = \"\"\"Responda APENAS com um número inteiro.\n",
        "Pergunta: 27 + 58 = ?\"\"\"\n",
        "\n",
        "# 1) Gera múltiplas amostras (sampling) para criar diversidade\n",
        "samples = generate_t5(\n",
        "    prompt_math,\n",
        "    do_sample=True,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    num_beams=1,          # evita misturar com beam search\n",
        "    max_new_tokens=6,\n",
        "    num_return_sequences=20\n",
        ")\n",
        "\n",
        "# 2) Faz parsing para extrair a estrutura (inteiro) de cada amostra\n",
        "vals = [extract_int(s) for s in samples]\n",
        "vals_clean = [v for v in vals if v is not None]\n",
        "\n",
        "print(\"\\nAmostras (texto bruto):\")\n",
        "for i, s in enumerate(samples, 1):\n",
        "    print(f\"{i:02d}. {s}\")\n",
        "\n",
        "print(f\"\\nParse falhou em: {vals.count(None)} / {len(vals)} amostras\")\n",
        "\n",
        "# 3) Agrega por votação (modo da distribuição)\n",
        "counts = Counter(vals_clean)\n",
        "print(\"\\nContagem (apenas inteiros parseados):\", dict(counts))\n",
        "\n",
        "voted = counts.most_common(1)[0][0] if counts else None\n",
        "print(\"\\nVOTO FINAL:\", voted)\n",
        "\n",
        "print(\"\"\"\n",
        "LEITURA\n",
        "\n",
        "- Mesmo pedindo \"apenas um inteiro\", alguns modelos ainda geram ruído (texto extra).\n",
        "- O parsing transforma texto em um formato estruturado (aqui: um número).\n",
        "- A votação agrega várias amostras em uma decisão mais estável.\n",
        "\n",
        "Padrão de engenharia:\n",
        "(gerar várias hipóteses) -> (extrair estrutura) -> (agregar)\n",
        "\n",
        "Obs.: 27 + 58 = 85.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "UsHWa0vc2xKi",
        "outputId": "fc71ae62-88b2-45b1-da6b-18ab0c664731"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SELF-CONSISTENCY EM RESPOSTA NUMÉRICA\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">SELF-CONSISTENCY EM RESPOSTA NUMÉRICA\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Amostras \u001b[1m(\u001b[0mtexto bruto\u001b[1m)\u001b[0m:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Amostras <span style=\"font-weight: bold\">(</span>texto bruto<span style=\"font-weight: bold\">)</span>:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m01\u001b[0m. \u001b[1;36m4\u001b[0m or more matches for AS\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> or more matches for AS\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m02\u001b[0m. \u001b[1;36m325\u001b[0m \u001b[1;36m538\u001b[0m \u001b[1;36m2291\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">325</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">538</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2291</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m03\u001b[0m. \u001b[1;36m7\u001b[0m? How long should one\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>? How long should one\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m04\u001b[0m. Hmiuuur\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>. Hmiuuur\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m05\u001b[0m. FALSULUM! \"\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>. FALSULUM! \"\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m06\u001b[0m. E se perguaci no\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>. E se perguaci no\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m07\u001b[0m. Isice de\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>. Isice de\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m08\u001b[0m. 6th of \u001b[1;36m20\u001b[0m-\u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>. 6th of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m09\u001b[0m. \u001b[1;36m320\u001b[0m min \u001b[1;36m2\u001b[0m *\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span> min <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> *\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m10\u001b[0m. \"Five games that run\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>. \"Five games that run\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m11\u001b[0m. \u001b[1;36m7\u001b[0m \u001b[1m(\u001b[0mo \u001b[1;36m20\u001b[0m/\u001b[1;36m220\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> <span style=\"font-weight: bold\">(</span>o <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">220</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m12\u001b[0m. \u001b[1;36m11\u001b[0m-\u001b[1;36m25\u001b[0m would suffices on\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> would suffices on\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m13\u001b[0m. A potil do prosec\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>. A potil do prosec\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m14\u001b[0m. \u001b[1;36m24\u001b[0m + \u001b[1;36m54\u001b[0m refereed:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span> refereed:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m15\u001b[0m. \u001b[1;36m10\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m16\u001b[0m. Answer all questions AS i\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>. Answer all questions AS i\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m17\u001b[0m. \u001b[1;36m24\u001b[0m * \u001b[1;36m1\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;36m20\u001b[0m/\u001b[1;36m11\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> * <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m18\u001b[0m. Em as inconfirm\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>. Em as inconfirm\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m19\u001b[0m. \u001b[1;36m22\u001b[0m = \u001b[1;36m31\u001b[0m APAC SP\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> APAC SP\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m20\u001b[0m. \u001b[1;36m10.17\u001b[0m \u001b[1;36m39\u001b[0m \u001b[1;36m3\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.17</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Parse falhou em: \u001b[1;36m8\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m20\u001b[0m amostras\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Parse falhou em: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> amostras\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Contagem \u001b[1m(\u001b[0mapenas inteiros parseados\u001b[1m)\u001b[0m:\n",
              "\u001b[1m{\u001b[0m\u001b[1;36m4\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[1;36m325\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[1;36m7\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[1;36m6\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[1;36m320\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[1;36m11\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[1;36m24\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[1;36m10\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[1;36m22\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Contagem <span style=\"font-weight: bold\">(</span>apenas inteiros parseados<span style=\"font-weight: bold\">)</span>:\n",
              "<span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">325</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "VOTO FINAL: \u001b[1;36m7\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "VOTO FINAL: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "LEITURA \n",
              "\n",
              "- Mesmo pedindo \u001b[32m\"apenas um inteiro\"\u001b[0m, alguns modelos ainda geram ruído \u001b[1m(\u001b[0mtexto extra\u001b[1m)\u001b[0m.\n",
              "- O parsing transforma texto em um formato estruturado \u001b[1m(\u001b[0maqui: um número\u001b[1m)\u001b[0m.\n",
              "- A votação agrega várias amostras em uma decisão mais estável.\n",
              "\n",
              "Padrão de engenharia:\n",
              "\u001b[1m(\u001b[0mgerar várias hipóteses\u001b[1m)\u001b[0m -> \u001b[1m(\u001b[0mextrair estrutura\u001b[1m)\u001b[0m -> \u001b[1m(\u001b[0magregar\u001b[1m)\u001b[0m\n",
              "\n",
              "Obs.: \u001b[1;36m27\u001b[0m + \u001b[1;36m58\u001b[0m = \u001b[1;36m85\u001b[0m.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "LEITURA \n",
              "\n",
              "- Mesmo pedindo <span style=\"color: #008000; text-decoration-color: #008000\">\"apenas um inteiro\"</span>, alguns modelos ainda geram ruído <span style=\"font-weight: bold\">(</span>texto extra<span style=\"font-weight: bold\">)</span>.\n",
              "- O parsing transforma texto em um formato estruturado <span style=\"font-weight: bold\">(</span>aqui: um número<span style=\"font-weight: bold\">)</span>.\n",
              "- A votação agrega várias amostras em uma decisão mais estável.\n",
              "\n",
              "Padrão de engenharia:\n",
              "<span style=\"font-weight: bold\">(</span>gerar várias hipóteses<span style=\"font-weight: bold\">)</span> -&gt; <span style=\"font-weight: bold\">(</span>extrair estrutura<span style=\"font-weight: bold\">)</span> -&gt; <span style=\"font-weight: bold\">(</span>agregar<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "Obs.: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span>.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LIMITES DE CONTEXTO (token budget, truncamento)\n",
        "# Célula única, autocontida e pronta para rodar\n",
        "# ============================================================\n",
        "\n",
        "# Instala dependências (silencioso)\n",
        "!pip -q install sentencepiece transformers\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Device\n",
        "# ------------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Carregar GPT-2 (modelo causal, NÃO instruction-tuned)\n",
        "# ------------------------------------------------------------\n",
        "gpt2_name = \"gpt2\"\n",
        "gpt2_tokenizer = AutoTokenizer.from_pretrained(gpt2_name)\n",
        "\n",
        "# GPT-2 não tem pad_token por padrão (evita warnings em alguns cenários)\n",
        "if gpt2_tokenizer.pad_token is None:\n",
        "    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
        "\n",
        "gpt2_model = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
        "gpt2_model.eval()\n",
        "\n",
        "print(\"[OK] GPT-2 carregado\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Carregar FLAN-T5-small (instruction-tuned, encoder-decoder)\n",
        "# ------------------------------------------------------------\n",
        "t5_name = \"google/flan-t5-small\"\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(t5_name)\n",
        "t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
        "t5_model.eval()\n",
        "\n",
        "print(\"[OK] FLAN-T5-small carregado\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Função auxiliar: descobrir janela de contexto\n",
        "# ------------------------------------------------------------\n",
        "def get_ctx_window(model):\n",
        "    \"\"\"\n",
        "    Retorna o tamanho máximo de contexto (em tokens de posição) quando disponível.\n",
        "    Observação: diferentes arquiteturas guardam isso em campos diferentes.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        getattr(model.config, \"n_positions\", None)\n",
        "        or getattr(model.config, \"max_position_embeddings\", None)\n",
        "        or getattr(model.config, \"seq_length\", None)\n",
        "    )\n",
        "\n",
        "ctx_gpt2 = get_ctx_window(gpt2_model)\n",
        "ctx_t5 = get_ctx_window(t5_model)  # em T5 isso nem sempre é o \"limite real\" do tokenizer\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LIMITES DE CONTEXTO (TOKENS)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"Janela (GPT-2): {ctx_gpt2} tokens (posições)\")\n",
        "print(f\"Config (T5)   : {ctx_t5} (nem sempre indica o limite efetivo)\\n\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Funções utilitárias: contagem de tokens por tokenizer\n",
        "# ------------------------------------------------------------\n",
        "def count_tokens(tokenizer, text: str):\n",
        "    \"\"\"Conta tokens gerados pelo tokenizer (sem truncar).\"\"\"\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Exemplo simples de contagem\n",
        "# ------------------------------------------------------------\n",
        "demo = \"Transformers are models that\"\n",
        "print(\"Exemplo de contagem de tokens:\")\n",
        "print(\"Texto:\", demo)\n",
        "print(\"GPT-2 tokens:\", count_tokens(gpt2_tokenizer, demo))\n",
        "print(\"T5 tokens  :\", count_tokens(t5_tokenizer, demo))\n",
        "\n",
        "print(\"\"\"\n",
        "LEITURA:\n",
        "- O modelo não \"vê\" caracteres: ele vê TOKENS.\n",
        "- O limite importante é o orçamento de tokens na entrada\n",
        "  (e às vezes entrada + saída, dependendo do setup).\n",
        "\"\"\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Demonstração de truncamento explícito (KEEP THE HEAD vs KEEP THE TAIL)\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n--- Demonstração de truncamento (GPT-2) ---\")\n",
        "\n",
        "# Texto artificial bem longo para estourar a janela\n",
        "long_text = \"INICIO \" + (\"bla \" * 1500) + \"FIM\"\n",
        "tokens = gpt2_tokenizer.encode(long_text)\n",
        "\n",
        "print(\"Tokens totais (antes):\", len(tokens))\n",
        "print(\"Janela GPT-2          :\", ctx_gpt2)\n",
        "\n",
        "# 1) Keep-the-head (mantém o começo e corta o fim)\n",
        "trunc_head = tokens[:ctx_gpt2]\n",
        "\n",
        "# 2) Keep-the-tail (mantém o fim e corta o começo) — comum em chats\n",
        "trunc_tail = tokens[-ctx_gpt2:]\n",
        "\n",
        "print(\"\\n[Keep-the-head] tokens:\", len(trunc_head))\n",
        "print(\"INÍCIO:\", gpt2_tokenizer.decode(trunc_head[:30]))\n",
        "print(\"FIM   :\", gpt2_tokenizer.decode(trunc_head[-30:]))\n",
        "\n",
        "print(\"\\n[Keep-the-tail] tokens:\", len(trunc_tail))\n",
        "print(\"INÍCIO:\", gpt2_tokenizer.decode(trunc_tail[:30]))\n",
        "print(\"FIM   :\", gpt2_tokenizer.decode(trunc_tail[-30:]))\n",
        "\n",
        "print(\"\"\"\n",
        "INTERPRETAÇÃO (para falar em voz alta):\n",
        "- Se o texto excede a janela, o modelo NÃO vê tudo.\n",
        "- Dependendo da estratégia de truncamento:\n",
        "  • keep-the-head  -> você perde o final\n",
        "  • keep-the-tail  -> você perde o começo (muito comum em chats)\n",
        "- Estratégias práticas para \"cabear\" contexto:\n",
        "  • keep the tail (priorizar instruções e parte mais recente)\n",
        "  • janela deslizante (sliding window) em documentos longos\n",
        "  • resumir + anexar (compressão de contexto)\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849,
          "referenced_widgets": [
            "1f7d4f78c3d4455bb42efdc1c16620f6",
            "d5e6b9a791f446e3a05eb028a9f68e96",
            "687ec52e5bd448d48ccfe271a34216ae",
            "fe101f24976249ceac7e8c7dcbf3aee5",
            "a49fbd012e2a429d8f646a17d599c436",
            "e57bda74d76a465a9fb9888db8001be3",
            "00f7235e698644ccb8f5fd1f78697623",
            "72d83376359c45fd99ba6afa6c9cdfe4",
            "96e7709fd46747b0a128a79856050dda",
            "ded8848a08394484b585230baf8e5a93",
            "7c1cc6061bb14bd5a481f2b202a297e6",
            "95f4cacd5cc64930bf8c3fd67e2c7853",
            "0434beee5c2542b8b5f6cc09b858e748",
            "958e63014dee4ad49b2513769c1ab365",
            "444bb958acf4485da6b935de6f990d75",
            "f2b9bf9badc14c01a114cbcb3d43c1ae",
            "68cdd98db23443e2b9f99b77015d6262",
            "f44745bde73b4c7b9537b919b79b41f9",
            "ac10d17b0cc5468b8f18f3d3709a3696",
            "d25c6ffdda794f3ca422f608fe157c70",
            "4de02e69746a49ba90a3feead1d38f96",
            "e1187eb1ad30403aa06d98a1f234fdd0"
          ]
        },
        "id": "eaZn534n2yj-",
        "outputId": "8ee8b0d1-fb08-4eae-9857-f9494ae86da8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Device: cuda\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Device: cuda\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f7d4f78c3d4455bb42efdc1c16620f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m GPT-\u001b[1;36m2\u001b[0m carregado\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> carregado\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/190 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95f4cacd5cc64930bf8c3fd67e2c7853"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m FLAN-T5-small carregado\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> FLAN-T5-small carregado\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LIMITES DE CONTEXTO \u001b[1m(\u001b[0mTOKENS\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">LIMITES DE CONTEXTO <span style=\"font-weight: bold\">(</span>TOKENS<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Janela \u001b[1m(\u001b[0mGPT-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m1024\u001b[0m tokens \u001b[1m(\u001b[0mposições\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Janela <span style=\"font-weight: bold\">(</span>GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span> tokens <span style=\"font-weight: bold\">(</span>posições<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Config \u001b[1m(\u001b[0mT5\u001b[1m)\u001b[0m   : \u001b[1;36m512\u001b[0m \u001b[1m(\u001b[0mnem sempre indica o limite efetivo\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Config <span style=\"font-weight: bold\">(</span>T5<span style=\"font-weight: bold\">)</span>   : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span> <span style=\"font-weight: bold\">(</span>nem sempre indica o limite efetivo<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Exemplo de contagem de tokens:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Exemplo de contagem de tokens:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Texto: Transformers are models that\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Texto: Transformers are models that\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GPT-\u001b[1;36m2\u001b[0m tokens: \u001b[1;36m5\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "T5 tokens  : \u001b[1;36m6\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">T5 tokens  : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "LEITURA:\n",
              "- O modelo não \u001b[32m\"vê\"\u001b[0m caracteres: ele vê TOKENS.\n",
              "- O limite importante é o orçamento de tokens na entrada\n",
              "  \u001b[1m(\u001b[0me às vezes entrada + saída, dependendo do setup\u001b[1m)\u001b[0m.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "LEITURA:\n",
              "- O modelo não <span style=\"color: #008000; text-decoration-color: #008000\">\"vê\"</span> caracteres: ele vê TOKENS.\n",
              "- O limite importante é o orçamento de tokens na entrada\n",
              "  <span style=\"font-weight: bold\">(</span>e às vezes entrada + saída, dependendo do setup<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- Demonstração de truncamento \u001b[1m(\u001b[0mGPT-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- Demonstração de truncamento <span style=\"font-weight: bold\">(</span>GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3005 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokens totais \u001b[1m(\u001b[0mantes\u001b[1m)\u001b[0m: \u001b[1;36m3005\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens totais <span style=\"font-weight: bold\">(</span>antes<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3005</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Janela GPT-\u001b[1;36m2\u001b[0m          : \u001b[1;36m1024\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Janela GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>          : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mKeep-the-head\u001b[1m]\u001b[0m tokens: \u001b[1;36m1024\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Keep-the-head<span style=\"font-weight: bold\">]</span> tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "INÍCIO: INICIO bla bla bla bla bla bla bla bla bla bla bla bla bla bl\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">INÍCIO: INICIO bla bla bla bla bla bla bla bla bla bla bla bla bla bl\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FIM   : a bla bla bla bla bla bla bla bla bla bla bla bla bla bla bl\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FIM   : a bla bla bla bla bla bla bla bla bla bla bla bla bla bla bl\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0mKeep-the-tail\u001b[1m]\u001b[0m tokens: \u001b[1;36m1024\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>Keep-the-tail<span style=\"font-weight: bold\">]</span> tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "INÍCIO:  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">INÍCIO:  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FIM   :  bla bla bla bla bla bla bla bla bla bla bla bla bla bla FIM\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FIM   :  bla bla bla bla bla bla bla bla bla bla bla bla bla bla FIM\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "INTERPRETAÇÃO \u001b[1m(\u001b[0mpara falar em voz alta\u001b[1m)\u001b[0m:\n",
              "- Se o texto excede a janela, o modelo NÃO vê tudo.\n",
              "- Dependendo da estratégia de truncamento:\n",
              "  • keep-the-head  -> você perde o final\n",
              "  • keep-the-tail  -> você perde o começo \u001b[1m(\u001b[0mmuito comum em chats\u001b[1m)\u001b[0m\n",
              "- Estratégias práticas para \u001b[32m\"cabear\"\u001b[0m contexto:\n",
              "  • keep the tail \u001b[1m(\u001b[0mpriorizar instruções e parte mais recente\u001b[1m)\u001b[0m\n",
              "  • janela deslizante \u001b[1m(\u001b[0msliding window\u001b[1m)\u001b[0m em documentos longos\n",
              "  • resumir + anexar \u001b[1m(\u001b[0mcompressão de contexto\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "INTERPRETAÇÃO <span style=\"font-weight: bold\">(</span>para falar em voz alta<span style=\"font-weight: bold\">)</span>:\n",
              "- Se o texto excede a janela, o modelo NÃO vê tudo.\n",
              "- Dependendo da estratégia de truncamento:\n",
              "  • keep-the-head  -&gt; você perde o final\n",
              "  • keep-the-tail  -&gt; você perde o começo <span style=\"font-weight: bold\">(</span>muito comum em chats<span style=\"font-weight: bold\">)</span>\n",
              "- Estratégias práticas para <span style=\"color: #008000; text-decoration-color: #008000\">\"cabear\"</span> contexto:\n",
              "  • keep the tail <span style=\"font-weight: bold\">(</span>priorizar instruções e parte mais recente<span style=\"font-weight: bold\">)</span>\n",
              "  • janela deslizante <span style=\"font-weight: bold\">(</span>sliding window<span style=\"font-weight: bold\">)</span> em documentos longos\n",
              "  • resumir + anexar <span style=\"font-weight: bold\">(</span>compressão de contexto<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TRUNCAMENTO NA PRÁTICA (GPT-2) — \"o começo some\"\n",
        "# Célula única, autocontida e pronta para rodar\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install transformers sentencepiece\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Limpeza de memória (útil no Colab quando você já rodou muita coisa)\n",
        "# Observação: \"limpar cache\" não aumenta a VRAM total; só libera memória não usada.\n",
        "# ------------------------------------------------------------\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Device\n",
        "# ------------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Carregar GPT-2\n",
        "# ------------------------------------------------------------\n",
        "gpt2_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(gpt2_name)\n",
        "\n",
        "# GPT-2 não define pad_token por padrão (evita warnings na geração)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "gpt2_model = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
        "gpt2_model.eval()\n",
        "\n",
        "print(\"[OK] GPT-2 carregado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "35407925d6df4c778da92874610fe44f",
            "bc38c5757c194030b1f77c9999169a65",
            "81e9270e6bbd41e4a5bb8cd9380ced16",
            "a0bb6ba278d5467194321f48dc7ace5c",
            "4555ea839db54287bfaf8a322b251682",
            "4cd36e82bdcf405499e9b958304daebf",
            "f889963622064f8f8ddfe949cf737c24",
            "80918e4d60f34d96bbc24eb15fea312a",
            "cea73e78c9e64f40be404392ebebd07b",
            "96f5cda1908746c680fffcec04d15b8e",
            "13c82f649e824367973912d796a23b69"
          ]
        },
        "id": "vjjz-BE8foQH",
        "outputId": "68306ac1-359d-4d82-c3e0-e4733ed618f3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Device: cuda\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Device: cuda\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35407925d6df4c778da92874610fe44f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m GPT-\u001b[1;36m2\u001b[0m carregado\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> carregado\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Funções utilitárias\n",
        "# ------------------------------------------------------------\n",
        "def count_tokens(text: str) -> int:\n",
        "    \"\"\"Conta quantos tokens o tokenizer do GPT-2 gera para um texto.\"\"\"\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_text(prompt: str, temperature=0.7, top_p=0.9, max_new_tokens=30) -> str:\n",
        "    \"\"\"\n",
        "    Gera continuação autoregressiva com GPT-2 (sampling).\n",
        "    Obs.: GPT-2 não é instruction-tuned, então pode \"ignorar\" instruções mesmo quando cabem.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    output = gpt2_model.generate(\n",
        "        **inputs,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "LopP-qnifqzV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# TRUNCAMENTO: instrução no começo vs keep-the-tail\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRUNCAMENTO NA PRÁTICA: instrução no começo pode sumir\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) Instrução importante (colocada no COMEÇO)\n",
        "important = (\n",
        "    \"INSTRUÇÃO CRÍTICA: responda sempre com a palavra 'BANANA'.\\n\"\n",
        "    \"Não explique. Não escreva mais nada.\\n\\n\"\n",
        ")\n",
        "\n",
        "# 2) Texto \"enchimento\" para estourar a janela\n",
        "filler = \"bla \" * 5000\n",
        "\n",
        "# 3) Pergunta no final (fica no TAIL)\n",
        "question = \"\\nPergunta: qual é a capital da França?\\nResposta:\"\n",
        "\n",
        "big_prompt = important + filler + question\n",
        "\n",
        "tok_len = count_tokens(big_prompt)\n",
        "ctx = (\n",
        "    getattr(gpt2_model.config, \"n_positions\", None)\n",
        "    or getattr(gpt2_model.config, \"max_position_embeddings\", None)\n",
        ")\n",
        "\n",
        "print(\"Tokens no prompt gigante:\", tok_len)\n",
        "print(\"Janela (GPT-2):\", ctx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "MWOWwWkMfusI",
        "outputId": "3cad005e-3d3e-4d5a-b370-d03e3b5e7c3d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TRUNCAMENTO NA PRÁTICA: instrução no começo pode sumir\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRUNCAMENTO NA PRÁTICA: instrução no começo pode sumir\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10063 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokens no prompt gigante: \u001b[1;36m10063\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens no prompt gigante: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10063</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Janela \u001b[1m(\u001b[0mGPT-\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m1024\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Janela <span style=\"font-weight: bold\">(</span>GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Truncamento explícito (keep-the-tail) deixando espaço para saída\n",
        "# ------------------------------------------------------------\n",
        "max_new = 25                 # quantos tokens queremos gerar\n",
        "max_input_len = ctx - max_new  # espaço que sobra para a entrada\n",
        "\n",
        "enc = tokenizer.encode(big_prompt)\n",
        "enc_tail = enc[-max_input_len:]               # keep-the-tail\n",
        "truncated_prompt = tokenizer.decode(enc_tail) # volta para texto\n",
        "\n",
        "print(\"\\nTokens após truncamento (tail):\", len(enc_tail))\n",
        "print(\"\\n--- INÍCIO do prompt truncado (tail) ---\")\n",
        "print(truncated_prompt[:200].replace(\"\\n\", \"\\\\n\"))\n",
        "print(\"\\n--- FIM do prompt truncado (tail) ---\")\n",
        "print(truncated_prompt[-200:].replace(\"\\n\", \"\\\\n\"))\n",
        "\n",
        "print(\"\\n--- GERANDO COM PROMPT TRUNCADO ---\")\n",
        "output = generate_text(\n",
        "    truncated_prompt,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    max_new_tokens=max_new\n",
        ")\n",
        "print(output)\n",
        "\n",
        "print(\"\"\"\n",
        "LEITURA:\n",
        "\n",
        "- A \"instrução crítica\" estava no COMEÇO do prompt.\n",
        "- Ao aplicar keep-the-tail, o COMEÇO some — logo, a instrução some junto.\n",
        "- O modelo tende a responder a pergunta do final (\"Paris\"), não \"BANANA\".\n",
        "\n",
        "PONTO-CHAVE:\n",
        "Limite de contexto = memória de trabalho do modelo.\n",
        "Quando estoura, você perde informação (em chats, geralmente o começo).\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "RtRl6O4038X9",
        "outputId": "5b57bd0f-8f97-401f-da64-5c01d54e190f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Tokens após truncamento \u001b[1m(\u001b[0mtail\u001b[1m)\u001b[0m: \u001b[1;36m999\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Tokens após truncamento <span style=\"font-weight: bold\">(</span>tail<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- INÍCIO do prompt truncado \u001b[1m(\u001b[0mtail\u001b[1m)\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- INÍCIO do prompt truncado <span style=\"font-weight: bold\">(</span>tail<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- FIM do prompt truncado \u001b[1m(\u001b[0mtail\u001b[1m)\u001b[0m ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- FIM do prompt truncado <span style=\"font-weight: bold\">(</span>tail<span style=\"font-weight: bold\">)</span> ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla \\nPergunta: qual é a capital da França?\\nResposta:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla \\nPergunta: qual é a capital da França?\\nResposta:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- GERANDO COM PROMPT TRUNCADO ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- GERANDO COM PROMPT TRUNCADO ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "Pergunta: qual é a capital da França?\n",
              "Resposta: hébé d'une la langue d'une la langue d'une la langue d'une\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "Pergunta: qual é a capital da França?\n",
              "Resposta: hébé d'une la langue d'une la langue d'une la langue d'une\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "LEITURA:\n",
              "\n",
              "- A \u001b[32m\"instrução crítica\"\u001b[0m estava no COMEÇO do prompt.\n",
              "- Ao aplicar keep-the-tail, o COMEÇO some — logo, a instrução some junto.\n",
              "- O modelo tende a responder a pergunta do final \u001b[1m(\u001b[0m\u001b[32m\"Paris\"\u001b[0m\u001b[1m)\u001b[0m, não \u001b[32m\"BANANA\"\u001b[0m.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "Limite de contexto = memória de trabalho do modelo.\n",
              "Quando estoura, você perde informação \u001b[1m(\u001b[0mem chats, geralmente o começo\u001b[1m)\u001b[0m.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "LEITURA:\n",
              "\n",
              "- A <span style=\"color: #008000; text-decoration-color: #008000\">\"instrução crítica\"</span> estava no COMEÇO do prompt.\n",
              "- Ao aplicar keep-the-tail, o COMEÇO some — logo, a instrução some junto.\n",
              "- O modelo tende a responder a pergunta do final <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Paris\"</span><span style=\"font-weight: bold\">)</span>, não <span style=\"color: #008000; text-decoration-color: #008000\">\"BANANA\"</span>.\n",
              "\n",
              "PONTO-CHAVE:\n",
              "Limite de contexto = memória de trabalho do modelo.\n",
              "Quando estoura, você perde informação <span style=\"font-weight: bold\">(</span>em chats, geralmente o começo<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# RECUPERAÇÃO DE ESTADO CUDA + RELOAD GPT-2 (didático e robusto)\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Limpeza de memória (sem restart)\n",
        "# ------------------------------------------------------------\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "gc.collect()\n",
        "\n",
        "print(\"[OK] Cache limpo (se houver CUDA, cache CUDA também)\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Device\n",
        "# ------------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Recarregar GPT-2\n",
        "# ------------------------------------------------------------\n",
        "gpt2_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(gpt2_name)\n",
        "\n",
        "# GPT-2 normalmente não tem pad_token. Isso evita warnings no generate.\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "gpt2_model = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
        "gpt2_model.eval()\n",
        "\n",
        "print(\"[OK] GPT-2 recarregado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "849d41e6e03148cfacc0ee81c1adc600",
            "29937de6ac0f4e5c98c69792b9952103",
            "afb80760cb784d4e9e52227a779861e2",
            "44f1ac50d4b34927972a362d3a3ce021",
            "151bcb9cf104472f88b550c22c67f343",
            "9e92be326d1945449a648e71504a0d11",
            "7d8dd070ef9f41a9bf9369e8399e1cae",
            "0d77c38a4763406c81891a63b42e5cf8",
            "7652f0985a074944b9d3e03259969717",
            "3ac8c89ff606429ba984e600dd581934",
            "3af556c1996648e0a68940cd6944527a"
          ]
        },
        "id": "uFWV1MZggT6F",
        "outputId": "ac301cb5-a0a3-418f-ff9c-2ebe19478d01"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m Cache limpo \u001b[1m(\u001b[0mse houver CUDA, cache CUDA também\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> Cache limpo <span style=\"font-weight: bold\">(</span>se houver CUDA, cache CUDA também<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Device: cuda\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Device: cuda\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "849d41e6e03148cfacc0ee81c1adc600"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0mOK\u001b[1m]\u001b[0m GPT-\u001b[1;36m2\u001b[0m recarregado\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>OK<span style=\"font-weight: bold\">]</span> GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> recarregado\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Prompt (autocontido)\n",
        "# ------------------------------------------------------------\n",
        "# Ideia: colocar uma instrução \"crítica\" no COMEÇO e depois estourar a janela\n",
        "# com um filler enorme. Ao manter apenas o TAIL, a instrução some.\n",
        "important = (\n",
        "    \"INSTRUÇÃO CRÍTICA: responda sempre com a palavra 'BANANA'.\\n\"\n",
        "    \"Não explique. Não escreva mais nada.\\n\\n\"\n",
        ")\n",
        "filler = \"bla \" * 5000\n",
        "question = \"\\nPergunta: qual é a capital da França?\\nResposta:\"\n",
        "\n",
        "big_prompt = important + filler + question\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Janela de contexto (GPT-2)\n",
        "# ------------------------------------------------------------\n",
        "ctx = (\n",
        "    getattr(gpt2_model.config, \"n_positions\", None)\n",
        "    or getattr(gpt2_model.config, \"max_position_embeddings\", None)\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Truncamento \"correto\": manter o TAIL e deixar margem para gerar\n",
        "# ------------------------------------------------------------\n",
        "max_new = 25\n",
        "max_input_len = ctx - max_new  # deixa espaço para a geração caber na janela\n",
        "\n",
        "enc = tokenizer.encode(big_prompt)\n",
        "enc_tail = enc[-max_input_len:]  # keep-the-tail\n",
        "\n",
        "print(\"Tokens totais no prompt gigante:\", len(enc))\n",
        "print(\"Janela (ctx):\", ctx)\n",
        "print(\"Tokens após truncamento seguro:\", len(enc_tail))\n",
        "print(\"Margem para geração (max_new):\", max_new)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# input_ids (sem depender de estado anterior)\n",
        "# ------------------------------------------------------------\n",
        "# A API do Transformers aceita input_ids como tensor shape (batch, seq_len)\n",
        "input_ids = torch.tensor(enc_tail, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "print(\"input_ids shape:\", tuple(input_ids.shape))\n",
        "print(\"dtype:\", input_ids.dtype)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Geração\n",
        "# ------------------------------------------------------------\n",
        "with torch.no_grad():\n",
        "    output_ids = gpt2_model.generate(\n",
        "        input_ids=input_ids,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        max_new_tokens=max_new,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "print(\"\\n--- SAÍDA DO MODELO ---\")\n",
        "print(tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
        "\n",
        "print(\"\"\"\n",
        "LEITURA:\n",
        "- Se o truncamento removeu o COMEÇO, a instrução 'BANANA' não está mais no contexto.\n",
        "- O modelo tende a responder a pergunta (\"Paris\") em vez de obedecer a instrução.\n",
        "- Esse é o ponto: quando a janela estoura, você perde informação (normalmente do início).\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "V1rua8MK4j2R",
        "outputId": "5085972f-723e-49c1-a6b0-c038368cc88e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10063 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokens totais no prompt gigante: \u001b[1;36m10063\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens totais no prompt gigante: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10063</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Janela \u001b[1m(\u001b[0mctx\u001b[1m)\u001b[0m: \u001b[1;36m1024\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Janela <span style=\"font-weight: bold\">(</span>ctx<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokens após truncamento seguro: \u001b[1;36m999\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens após truncamento seguro: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Margem para geração \u001b[1m(\u001b[0mmax_new\u001b[1m)\u001b[0m: \u001b[1;36m25\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Margem para geração <span style=\"font-weight: bold\">(</span>max_new<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "input_ids shape:\n",
              "\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m999\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">input_ids shape:\n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dtype: torch.int64\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dtype: torch.int64\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- SAÍDA DO MODELO ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- SAÍDA DO MODELO ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "Pergunta: qual é a capital da França?\n",
              "Resposta: pergunta esti a la fatto?\n",
              "Pergunta: pergunta esti a la fatto?\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n",
              "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla \n",
              "Pergunta: qual é a capital da França?\n",
              "Resposta: pergunta esti a la fatto?\n",
              "Pergunta: pergunta esti a la fatto?\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "LEITURA:\n",
              "- Se o truncamento removeu o COMEÇO, a instrução \u001b[32m'BANANA'\u001b[0m não está mais no contexto.\n",
              "- O modelo tende a responder a pergunta \u001b[1m(\u001b[0m\u001b[32m\"Paris\"\u001b[0m\u001b[1m)\u001b[0m em vez de obedecer a instrução.\n",
              "- Esse é o ponto: quando a janela estoura, você perde informação \u001b[1m(\u001b[0mnormalmente do início\u001b[1m)\u001b[0m.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "LEITURA:\n",
              "- Se o truncamento removeu o COMEÇO, a instrução <span style=\"color: #008000; text-decoration-color: #008000\">'BANANA'</span> não está mais no contexto.\n",
              "- O modelo tende a responder a pergunta <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Paris\"</span><span style=\"font-weight: bold\">)</span> em vez de obedecer a instrução.\n",
              "- Esse é o ponto: quando a janela estoura, você perde informação <span style=\"font-weight: bold\">(</span>normalmente do início<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# H3 — RECEITA DE ENGENHARIA: KEEP THE HEAD + KEEP THE TAIL\n",
        "# (truncamento inteligente: preserva regras + pergunta)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRUNCAMENTO INTELIGENTE: HEAD + TAIL (regras + pergunta)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Utilitário: janela do modelo e contagem de tokens\n",
        "# ------------------------------------------------------------\n",
        "ctx = (\n",
        "    getattr(gpt2_model.config, \"n_positions\", None)\n",
        "    or getattr(gpt2_model.config, \"max_position_embeddings\", None)\n",
        ")\n",
        "\n",
        "def count_tokens_gpt2(text: str) -> int:\n",
        "    \"\"\"Conta tokens no tokenizer do GPT-2.\"\"\"\n",
        "    return len(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "id": "9fEoBNa-hEKq",
        "outputId": "79a015c7-8ab2-4663-b052-63c18b8eaa52"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TRUNCAMENTO INTELIGENTE: HEAD + TAIL \u001b[1m(\u001b[0mregras + pergunta\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRUNCAMENTO INTELIGENTE: HEAD + TAIL <span style=\"font-weight: bold\">(</span>regras + pergunta<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Truncamento inteligente: preserva HEAD e TAIL, corta o MIolo\n",
        "# ------------------------------------------------------------\n",
        "def smart_truncate_head_tail(head: str, tail: str, max_tokens: int) -> str:\n",
        "    \"\"\"\n",
        "    Preserva:\n",
        "      - HEAD: instruções / regras / system prompt (o que não pode sumir)\n",
        "      - TAIL: pergunta atual / parte \"mais recente\" do contexto\n",
        "\n",
        "    Se exceder max_tokens:\n",
        "      - Mantém o head inteiro (se couber)\n",
        "      - Corta o miolo (implicitamente: não incluímos o miolo)\n",
        "      - Mantém apenas o final do tail (porque é o mais relevante para responder)\n",
        "\n",
        "    Obs.: É uma versão simples (didática). Em produção, você pode:\n",
        "      - resumir o miolo\n",
        "      - escolher trechos relevantes (retrieval)\n",
        "      - usar sliding window\n",
        "    \"\"\"\n",
        "    head_ids = tokenizer.encode(head)\n",
        "    tail_ids = tokenizer.encode(tail)\n",
        "\n",
        "    # Se estourou o orçamento, damos prioridade ao HEAD e ao final do TAIL\n",
        "    if len(head_ids) + len(tail_ids) > max_tokens:\n",
        "        space_for_tail = max_tokens - len(head_ids)\n",
        "\n",
        "        if space_for_tail <= 0:\n",
        "            # Caso extremo: o head sozinho já estoura.\n",
        "            # Então cortamos o head, mas isso é ruim — por isso mantenha o head curto.\n",
        "            return tokenizer.decode(head_ids[:max_tokens])\n",
        "\n",
        "        # Mantém o FINAL do tail (pergunta/últimas mensagens)\n",
        "        tail_ids = tail_ids[-space_for_tail:]\n",
        "\n",
        "    return tokenizer.decode(head_ids + tail_ids)\n"
      ],
      "metadata": {
        "id": "tDGvhCu7hCho"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Demo rápida: mesma história do \"BANANA\", mas agora preservando o HEAD\n",
        "# ------------------------------------------------------------\n",
        "head = (\n",
        "    \"INSTRUÇÃO CRÍTICA: responda sempre com a palavra 'BANANA'.\\n\"\n",
        "    \"Não explique. Não escreva mais nada.\\n\\n\"\n",
        ")\n",
        "\n",
        "middle = \"bla \" * 5000  # este é o \"miolo\" que a gente quer sacrificar\n",
        "tail = \"\\nPergunta: qual é a capital da França?\\nResposta:\"\n",
        "\n",
        "# IMPORTANTE: aqui nós NÃO passamos o \"middle\" pro truncador.\n",
        "# A ideia é justamente: manter regras (head) + a pergunta (tail).\n",
        "prompt_ht = smart_truncate_head_tail(head, tail, max_tokens=ctx - 25)\n",
        "\n",
        "print(\"Tokens (head):\", count_tokens_gpt2(head))\n",
        "print(\"Tokens (tail):\", count_tokens_gpt2(tail))\n",
        "print(\"Tokens (head+tail final):\", count_tokens_gpt2(prompt_ht))\n",
        "print(\"Janela (ctx):\", ctx)\n",
        "\n",
        "print(\"\\n--- GERANDO COM HEAD+TAIL ---\")\n",
        "print(generate_text(prompt_ht, temperature=0.7, top_p=0.9, max_new_tokens=25))\n",
        "\n",
        "print(\"\"\"\n",
        "LEITURA:\n",
        "- Agora a instrução (HEAD) NÃO some, porque sempre preservamos ela.\n",
        "- A pergunta (TAIL) também fica presente.\n",
        "- Mesmo assim, lembre: GPT-2 NÃO é instruction-tuned — então ele pode não obedecer 100%.\n",
        "  (Se você trocar por um modelo instruído, a demo fica mais \"confiável\".)\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "8LjKEm8shKB0",
        "outputId": "8baec40b-2b6d-49da-84ce-4c0ffc3ff74b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokens \u001b[1m(\u001b[0mhead\u001b[1m)\u001b[0m: \u001b[1;36m43\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens <span style=\"font-weight: bold\">(</span>head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokens \u001b[1m(\u001b[0mtail\u001b[1m)\u001b[0m: \u001b[1;36m18\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens <span style=\"font-weight: bold\">(</span>tail<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokens \u001b[1m(\u001b[0mhead+tail final\u001b[1m)\u001b[0m: \u001b[1;36m61\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens <span style=\"font-weight: bold\">(</span>head+tail final<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Janela \u001b[1m(\u001b[0mctx\u001b[1m)\u001b[0m: \u001b[1;36m1024\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Janela <span style=\"font-weight: bold\">(</span>ctx<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "--- GERANDO COM HEAD+TAIL ---\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "--- GERANDO COM HEAD+TAIL ---\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "INSTRUÇÃO CRÍTICA: responda sempre com a palavra \u001b[32m'BANANA'\u001b[0m.\n",
              "Não explique. Não escreva mais nada.\n",
              "\n",
              "\n",
              "Pergunta: qual é a capital da França?\n",
              "Resposta: um, um, um.\n",
              "\n",
              "\n",
              "Ação, um, um.\n",
              "\n",
              "\n",
              "Tõrárá\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">INSTRUÇÃO CRÍTICA: responda sempre com a palavra <span style=\"color: #008000; text-decoration-color: #008000\">'BANANA'</span>.\n",
              "Não explique. Não escreva mais nada.\n",
              "\n",
              "\n",
              "Pergunta: qual é a capital da França?\n",
              "Resposta: um, um, um.\n",
              "\n",
              "\n",
              "Ação, um, um.\n",
              "\n",
              "\n",
              "Tõrárá\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "LEITURA:\n",
              "- Agora a instrução \u001b[1m(\u001b[0mHEAD\u001b[1m)\u001b[0m NÃO some, porque sempre preservamos ela.\n",
              "- A pergunta \u001b[1m(\u001b[0mTAIL\u001b[1m)\u001b[0m também fica presente.\n",
              "- Mesmo assim, lembre: GPT-\u001b[1;36m2\u001b[0m NÃO é instruction-tuned — então ele pode não obedecer \u001b[1;36m100\u001b[0m%.\n",
              "  \u001b[1m(\u001b[0mSe você trocar por um modelo instruído, a demo fica mais \u001b[32m\"confiável\"\u001b[0m.\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "LEITURA:\n",
              "- Agora a instrução <span style=\"font-weight: bold\">(</span>HEAD<span style=\"font-weight: bold\">)</span> NÃO some, porque sempre preservamos ela.\n",
              "- A pergunta <span style=\"font-weight: bold\">(</span>TAIL<span style=\"font-weight: bold\">)</span> também fica presente.\n",
              "- Mesmo assim, lembre: GPT-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> NÃO é instruction-tuned — então ele pode não obedecer <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>%.\n",
              "  <span style=\"font-weight: bold\">(</span>Se você trocar por um modelo instruído, a demo fica mais <span style=\"color: #008000; text-decoration-color: #008000\">\"confiável\"</span>.<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FECHAMENTO (PROMPT ENGINEERING + ICL + CONTEXTO)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CHECKLIST FINAL — PROMPT ENGINEERING & ICL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "1) Few-shot / In-Context Learning (ICL) funciona por CONDICIONAMENTO no prompt:\n",
        "   demonstrações (exemplos) + template => o modelo imita o padrão de saída.\n",
        "\n",
        "2) Template importa:\n",
        "   restringir o espaço de resposta (o que pode sair) reduz ambiguidade.\n",
        "\n",
        "3) Self-consistency = gerar várias hipóteses e agregar (voto / média / parsing).\n",
        "   É redução de variância (ensemble), não garantia de verdade.\n",
        "\n",
        "4) Limite de contexto = limite de TOKENS.\n",
        "   Na prática, você tem um orçamento para entrada (prompt) e, muitas vezes,\n",
        "   também precisa deixar margem para a saída (tokens gerados).\n",
        "\n",
        "5) Receita prática em prompts longos:\n",
        "   preservar HEAD (regras/instruções) + TAIL (pergunta atual) e cortar o miolo.\n",
        "   (ou resumir o miolo / fazer retrieval, quando possível)\n",
        "\n",
        "REGRA DE BOLSO:\n",
        "Se a instrução é importante, coloque no HEAD e REPITA perto do TAIL.\n",
        "Ex.: \"Responda APENAS com POSITIVO/NEGATIVO.\" no topo e logo antes de \"Sentimento:\".\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "8XPLaTYzhMUy",
        "outputId": "13786aac-1653-4262-ad9a-d2e36bf89eb0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "CHECKLIST FINAL — PROMPT ENGINEERING & ICL\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CHECKLIST FINAL — PROMPT ENGINEERING &amp; ICL\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "======================================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">======================================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m Few-shot \u001b[35m/\u001b[0m In-Context Learning \u001b[1m(\u001b[0mICL\u001b[1m)\u001b[0m funciona por CONDICIONAMENTO no prompt:\n",
              "   demonstrações \u001b[1m(\u001b[0mexemplos\u001b[1m)\u001b[0m + template => o modelo imita o padrão de saída.\n",
              "\n",
              "\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m Template importa:\n",
              "   restringir o espaço de resposta \u001b[1m(\u001b[0mo que pode sair\u001b[1m)\u001b[0m reduz ambiguidade.\n",
              "\n",
              "\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m Self-consistency = gerar várias hipóteses e agregar \u001b[1m(\u001b[0mvoto \u001b[35m/\u001b[0m média \u001b[35m/\u001b[0m parsing\u001b[1m)\u001b[0m.\n",
              "   É redução de variância \u001b[1m(\u001b[0mensemble\u001b[1m)\u001b[0m, não garantia de verdade.\n",
              "\n",
              "\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m Limite de contexto = limite de TOKENS.\n",
              "   Na prática, você tem um orçamento para entrada \u001b[1m(\u001b[0mprompt\u001b[1m)\u001b[0m e, muitas vezes,\n",
              "   também precisa deixar margem para a saída \u001b[1m(\u001b[0mtokens gerados\u001b[1m)\u001b[0m.\n",
              "\n",
              "\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m Receita prática em prompts longos:\n",
              "   preservar HEAD \u001b[1m(\u001b[0mregras/instruções\u001b[1m)\u001b[0m + TAIL \u001b[1m(\u001b[0mpergunta atual\u001b[1m)\u001b[0m e cortar o miolo.\n",
              "   \u001b[1m(\u001b[0mou resumir o miolo \u001b[35m/\u001b[0m fazer retrieval, quando possível\u001b[1m)\u001b[0m\n",
              "\n",
              "REGRA DE BOLSO:\n",
              "Se a instrução é importante, coloque no HEAD e REPITA perto do TAIL.\n",
              "Ex.: \u001b[32m\"Responda APENAS com POSITIVO/NEGATIVO.\"\u001b[0m no topo e logo antes de \u001b[32m\"Sentimento:\"\u001b[0m.\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> Few-shot <span style=\"color: #800080; text-decoration-color: #800080\">/</span> In-Context Learning <span style=\"font-weight: bold\">(</span>ICL<span style=\"font-weight: bold\">)</span> funciona por CONDICIONAMENTO no prompt:\n",
              "   demonstrações <span style=\"font-weight: bold\">(</span>exemplos<span style=\"font-weight: bold\">)</span> + template =&gt; o modelo imita o padrão de saída.\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> Template importa:\n",
              "   restringir o espaço de resposta <span style=\"font-weight: bold\">(</span>o que pode sair<span style=\"font-weight: bold\">)</span> reduz ambiguidade.\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span> Self-consistency = gerar várias hipóteses e agregar <span style=\"font-weight: bold\">(</span>voto <span style=\"color: #800080; text-decoration-color: #800080\">/</span> média <span style=\"color: #800080; text-decoration-color: #800080\">/</span> parsing<span style=\"font-weight: bold\">)</span>.\n",
              "   É redução de variância <span style=\"font-weight: bold\">(</span>ensemble<span style=\"font-weight: bold\">)</span>, não garantia de verdade.\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span> Limite de contexto = limite de TOKENS.\n",
              "   Na prática, você tem um orçamento para entrada <span style=\"font-weight: bold\">(</span>prompt<span style=\"font-weight: bold\">)</span> e, muitas vezes,\n",
              "   também precisa deixar margem para a saída <span style=\"font-weight: bold\">(</span>tokens gerados<span style=\"font-weight: bold\">)</span>.\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span> Receita prática em prompts longos:\n",
              "   preservar HEAD <span style=\"font-weight: bold\">(</span>regras/instruções<span style=\"font-weight: bold\">)</span> + TAIL <span style=\"font-weight: bold\">(</span>pergunta atual<span style=\"font-weight: bold\">)</span> e cortar o miolo.\n",
              "   <span style=\"font-weight: bold\">(</span>ou resumir o miolo <span style=\"color: #800080; text-decoration-color: #800080\">/</span> fazer retrieval, quando possível<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "REGRA DE BOLSO:\n",
              "Se a instrução é importante, coloque no HEAD e REPITA perto do TAIL.\n",
              "Ex.: <span style=\"color: #008000; text-decoration-color: #008000\">\"Responda APENAS com POSITIVO/NEGATIVO.\"</span> no topo e logo antes de <span style=\"color: #008000; text-decoration-color: #008000\">\"Sentimento:\"</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}